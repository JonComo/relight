{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful reference: https://www.cs.toronto.edu/~lczhang/360/lec/w05/autoencoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "img_dir = '../dataset'\n",
    "n_epochs = 100\n",
    "batch_size = 20\n",
    "lr = 0.0002\n",
    "b1 = .5\n",
    "b2 = .999\n",
    "n_cpu = 8\n",
    "latent_dim = 2\n",
    "img_size = 256\n",
    "channels = 3\n",
    "sample_interval = 25\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Generator, self).__init__()\n",
    "\n",
    "#         self.init_size = img_size // 4\n",
    "#         self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "#         self.conv_blocks = nn.Sequential(\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(128, 0.8),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "#             nn.BatchNorm2d(64, 0.8),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "#             nn.Tanh(),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, z):\n",
    "#         out = self.l1(z)\n",
    "#         out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "#         img = self.conv_blocks(out)\n",
    "#         return img\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, channels*img_size**2),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        img = out.view(out.shape[0], channels, img_size, img_size)\n",
    "        return img\n",
    "\n",
    "# Loss function\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "# Initialize generator\n",
    "generator = Generator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    mse_loss.cuda()\n",
    "\n",
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "\n",
    "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        return super(ImageFolderWithPaths, self).__getitem__(index) + (self.imgs[index][0],)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5, ), std=(0.5, 0.5, 0.5, )),\n",
    "    ])\n",
    "    \n",
    "train_dataset = ImageFolderWithPaths(\n",
    "    root=img_dir,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# split it up to see how we generalize\n",
    "#path, dirs, files = next(os.walk(img_dir))\n",
    "#file_count = len(files)\n",
    "#num_train = int(0.7 * file_count)\n",
    "#num_val = file_count - num_train\n",
    "\n",
    "#train_dataset, val_dataset = torch.utils.data.random_split(dataset, [num_train, num_val])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=n_cpu,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/100] [Batch 0/6] [G loss: 0.200375]\n",
      "[Epoch 0/100] [Batch 1/6] [G loss: 0.194708]\n",
      "[Epoch 0/100] [Batch 2/6] [G loss: 0.185402]\n",
      "[Epoch 0/100] [Batch 3/6] [G loss: 0.161506]\n",
      "[Epoch 0/100] [Batch 4/6] [G loss: 0.154032]\n",
      "[Epoch 0/100] [Batch 5/6] [G loss: 0.137365]\n",
      "[Epoch 1/100] [Batch 0/6] [G loss: 0.132911]\n",
      "[Epoch 1/100] [Batch 1/6] [G loss: 0.116047]\n",
      "[Epoch 1/100] [Batch 2/6] [G loss: 0.108565]\n",
      "[Epoch 1/100] [Batch 3/6] [G loss: 0.107540]\n",
      "[Epoch 1/100] [Batch 4/6] [G loss: 0.096627]\n",
      "[Epoch 1/100] [Batch 5/6] [G loss: 0.087328]\n",
      "[Epoch 2/100] [Batch 0/6] [G loss: 0.079151]\n",
      "[Epoch 2/100] [Batch 1/6] [G loss: 0.073386]\n",
      "[Epoch 2/100] [Batch 2/6] [G loss: 0.068953]\n",
      "[Epoch 2/100] [Batch 3/6] [G loss: 0.062020]\n",
      "[Epoch 2/100] [Batch 4/6] [G loss: 0.054590]\n",
      "[Epoch 2/100] [Batch 5/6] [G loss: 0.057345]\n",
      "[Epoch 3/100] [Batch 0/6] [G loss: 0.050842]\n",
      "[Epoch 3/100] [Batch 1/6] [G loss: 0.044288]\n",
      "[Epoch 3/100] [Batch 2/6] [G loss: 0.041242]\n",
      "[Epoch 3/100] [Batch 3/6] [G loss: 0.039246]\n",
      "[Epoch 3/100] [Batch 4/6] [G loss: 0.034558]\n",
      "[Epoch 3/100] [Batch 5/6] [G loss: 0.033360]\n",
      "[Epoch 4/100] [Batch 0/6] [G loss: 0.029593]\n",
      "[Epoch 4/100] [Batch 1/6] [G loss: 0.027890]\n",
      "[Epoch 4/100] [Batch 2/6] [G loss: 0.025639]\n",
      "[Epoch 4/100] [Batch 3/6] [G loss: 0.025854]\n",
      "[Epoch 4/100] [Batch 4/6] [G loss: 0.024448]\n",
      "[Epoch 4/100] [Batch 5/6] [G loss: 0.020556]\n",
      "[Epoch 5/100] [Batch 0/6] [G loss: 0.018666]\n",
      "[Epoch 5/100] [Batch 1/6] [G loss: 0.019834]\n",
      "[Epoch 5/100] [Batch 2/6] [G loss: 0.017703]\n",
      "[Epoch 5/100] [Batch 3/6] [G loss: 0.017689]\n",
      "[Epoch 5/100] [Batch 4/6] [G loss: 0.015579]\n",
      "[Epoch 5/100] [Batch 5/6] [G loss: 0.013344]\n",
      "[Epoch 6/100] [Batch 0/6] [G loss: 0.014541]\n",
      "[Epoch 6/100] [Batch 1/6] [G loss: 0.013592]\n",
      "[Epoch 6/100] [Batch 2/6] [G loss: 0.012335]\n",
      "[Epoch 6/100] [Batch 3/6] [G loss: 0.012358]\n",
      "[Epoch 6/100] [Batch 4/6] [G loss: 0.010167]\n",
      "[Epoch 6/100] [Batch 5/6] [G loss: 0.010663]\n",
      "[Epoch 7/100] [Batch 0/6] [G loss: 0.010320]\n",
      "[Epoch 7/100] [Batch 1/6] [G loss: 0.010215]\n",
      "[Epoch 7/100] [Batch 2/6] [G loss: 0.009022]\n",
      "[Epoch 7/100] [Batch 3/6] [G loss: 0.008078]\n",
      "[Epoch 7/100] [Batch 4/6] [G loss: 0.010667]\n",
      "[Epoch 7/100] [Batch 5/6] [G loss: 0.008378]\n",
      "[Epoch 8/100] [Batch 0/6] [G loss: 0.009704]\n",
      "[Epoch 8/100] [Batch 1/6] [G loss: 0.007460]\n",
      "[Epoch 8/100] [Batch 2/6] [G loss: 0.009179]\n",
      "[Epoch 8/100] [Batch 3/6] [G loss: 0.007172]\n",
      "[Epoch 8/100] [Batch 4/6] [G loss: 0.006762]\n",
      "[Epoch 8/100] [Batch 5/6] [G loss: 0.006239]\n",
      "[Epoch 9/100] [Batch 0/6] [G loss: 0.007307]\n",
      "[Epoch 9/100] [Batch 1/6] [G loss: 0.006045]\n",
      "[Epoch 9/100] [Batch 2/6] [G loss: 0.005236]\n",
      "[Epoch 9/100] [Batch 3/6] [G loss: 0.007992]\n",
      "[Epoch 9/100] [Batch 4/6] [G loss: 0.006749]\n",
      "[Epoch 9/100] [Batch 5/6] [G loss: 0.007114]\n",
      "[Epoch 10/100] [Batch 0/6] [G loss: 0.005426]\n",
      "[Epoch 10/100] [Batch 1/6] [G loss: 0.005792]\n",
      "[Epoch 10/100] [Batch 2/6] [G loss: 0.005099]\n",
      "[Epoch 10/100] [Batch 3/6] [G loss: 0.006127]\n",
      "[Epoch 10/100] [Batch 4/6] [G loss: 0.007630]\n",
      "[Epoch 10/100] [Batch 5/6] [G loss: 0.006069]\n",
      "[Epoch 11/100] [Batch 0/6] [G loss: 0.006312]\n",
      "[Epoch 11/100] [Batch 1/6] [G loss: 0.005924]\n",
      "[Epoch 11/100] [Batch 2/6] [G loss: 0.004004]\n",
      "[Epoch 11/100] [Batch 3/6] [G loss: 0.006739]\n",
      "[Epoch 11/100] [Batch 4/6] [G loss: 0.005661]\n",
      "[Epoch 11/100] [Batch 5/6] [G loss: 0.004869]\n",
      "[Epoch 12/100] [Batch 0/6] [G loss: 0.005735]\n",
      "[Epoch 12/100] [Batch 1/6] [G loss: 0.006138]\n",
      "[Epoch 12/100] [Batch 2/6] [G loss: 0.004115]\n",
      "[Epoch 12/100] [Batch 3/6] [G loss: 0.004331]\n",
      "[Epoch 12/100] [Batch 4/6] [G loss: 0.005208]\n",
      "[Epoch 12/100] [Batch 5/6] [G loss: 0.005538]\n",
      "[Epoch 13/100] [Batch 0/6] [G loss: 0.004512]\n",
      "[Epoch 13/100] [Batch 1/6] [G loss: 0.005032]\n",
      "[Epoch 13/100] [Batch 2/6] [G loss: 0.004581]\n",
      "[Epoch 13/100] [Batch 3/6] [G loss: 0.005278]\n",
      "[Epoch 13/100] [Batch 4/6] [G loss: 0.004748]\n",
      "[Epoch 13/100] [Batch 5/6] [G loss: 0.005633]\n",
      "[Epoch 14/100] [Batch 0/6] [G loss: 0.004483]\n",
      "[Epoch 14/100] [Batch 1/6] [G loss: 0.004498]\n",
      "[Epoch 14/100] [Batch 2/6] [G loss: 0.004058]\n",
      "[Epoch 14/100] [Batch 3/6] [G loss: 0.004404]\n",
      "[Epoch 14/100] [Batch 4/6] [G loss: 0.004959]\n",
      "[Epoch 14/100] [Batch 5/6] [G loss: 0.006023]\n",
      "[Epoch 15/100] [Batch 0/6] [G loss: 0.004140]\n",
      "[Epoch 15/100] [Batch 1/6] [G loss: 0.004636]\n",
      "[Epoch 15/100] [Batch 2/6] [G loss: 0.004604]\n",
      "[Epoch 15/100] [Batch 3/6] [G loss: 0.004194]\n",
      "[Epoch 15/100] [Batch 4/6] [G loss: 0.004476]\n",
      "[Epoch 15/100] [Batch 5/6] [G loss: 0.005254]\n",
      "[Epoch 16/100] [Batch 0/6] [G loss: 0.003371]\n",
      "[Epoch 16/100] [Batch 1/6] [G loss: 0.004548]\n",
      "[Epoch 16/100] [Batch 2/6] [G loss: 0.004741]\n",
      "[Epoch 16/100] [Batch 3/6] [G loss: 0.005085]\n",
      "[Epoch 16/100] [Batch 4/6] [G loss: 0.004812]\n",
      "[Epoch 16/100] [Batch 5/6] [G loss: 0.003772]\n",
      "[Epoch 17/100] [Batch 0/6] [G loss: 0.004694]\n",
      "[Epoch 17/100] [Batch 1/6] [G loss: 0.004044]\n",
      "[Epoch 17/100] [Batch 2/6] [G loss: 0.002867]\n",
      "[Epoch 17/100] [Batch 3/6] [G loss: 0.003224]\n",
      "[Epoch 17/100] [Batch 4/6] [G loss: 0.004844]\n",
      "[Epoch 17/100] [Batch 5/6] [G loss: 0.005861]\n",
      "[Epoch 18/100] [Batch 0/6] [G loss: 0.006142]\n",
      "[Epoch 18/100] [Batch 1/6] [G loss: 0.004210]\n",
      "[Epoch 18/100] [Batch 2/6] [G loss: 0.003068]\n",
      "[Epoch 18/100] [Batch 3/6] [G loss: 0.003046]\n",
      "[Epoch 18/100] [Batch 4/6] [G loss: 0.003520]\n",
      "[Epoch 18/100] [Batch 5/6] [G loss: 0.004347]\n",
      "[Epoch 19/100] [Batch 0/6] [G loss: 0.004028]\n",
      "[Epoch 19/100] [Batch 1/6] [G loss: 0.004377]\n",
      "[Epoch 19/100] [Batch 2/6] [G loss: 0.003686]\n",
      "[Epoch 19/100] [Batch 3/6] [G loss: 0.003709]\n",
      "[Epoch 19/100] [Batch 4/6] [G loss: 0.004042]\n",
      "[Epoch 19/100] [Batch 5/6] [G loss: 0.003996]\n",
      "[Epoch 20/100] [Batch 0/6] [G loss: 0.004530]\n",
      "[Epoch 20/100] [Batch 1/6] [G loss: 0.002771]\n",
      "[Epoch 20/100] [Batch 2/6] [G loss: 0.003886]\n",
      "[Epoch 20/100] [Batch 3/6] [G loss: 0.003650]\n",
      "[Epoch 20/100] [Batch 4/6] [G loss: 0.004962]\n",
      "[Epoch 20/100] [Batch 5/6] [G loss: 0.003161]\n",
      "[Epoch 21/100] [Batch 0/6] [G loss: 0.002760]\n",
      "[Epoch 21/100] [Batch 1/6] [G loss: 0.004107]\n",
      "[Epoch 21/100] [Batch 2/6] [G loss: 0.004493]\n",
      "[Epoch 21/100] [Batch 3/6] [G loss: 0.003141]\n",
      "[Epoch 21/100] [Batch 4/6] [G loss: 0.004547]\n",
      "[Epoch 21/100] [Batch 5/6] [G loss: 0.003343]\n",
      "[Epoch 22/100] [Batch 0/6] [G loss: 0.003954]\n",
      "[Epoch 22/100] [Batch 1/6] [G loss: 0.003575]\n",
      "[Epoch 22/100] [Batch 2/6] [G loss: 0.004276]\n",
      "[Epoch 22/100] [Batch 3/6] [G loss: 0.003292]\n",
      "[Epoch 22/100] [Batch 4/6] [G loss: 0.003049]\n",
      "[Epoch 22/100] [Batch 5/6] [G loss: 0.003428]\n",
      "[Epoch 23/100] [Batch 0/6] [G loss: 0.004588]\n",
      "[Epoch 23/100] [Batch 1/6] [G loss: 0.002668]\n",
      "[Epoch 23/100] [Batch 2/6] [G loss: 0.003429]\n",
      "[Epoch 23/100] [Batch 3/6] [G loss: 0.003770]\n",
      "[Epoch 23/100] [Batch 4/6] [G loss: 0.003990]\n",
      "[Epoch 23/100] [Batch 5/6] [G loss: 0.002636]\n",
      "[Epoch 24/100] [Batch 0/6] [G loss: 0.003300]\n",
      "[Epoch 24/100] [Batch 1/6] [G loss: 0.004163]\n",
      "[Epoch 24/100] [Batch 2/6] [G loss: 0.003066]\n",
      "[Epoch 24/100] [Batch 3/6] [G loss: 0.003285]\n",
      "[Epoch 24/100] [Batch 4/6] [G loss: 0.003690]\n",
      "[Epoch 24/100] [Batch 5/6] [G loss: 0.002906]\n",
      "[Epoch 25/100] [Batch 0/6] [G loss: 0.003553]\n",
      "[Epoch 25/100] [Batch 1/6] [G loss: 0.002901]\n",
      "[Epoch 25/100] [Batch 2/6] [G loss: 0.003128]\n",
      "[Epoch 25/100] [Batch 3/6] [G loss: 0.003584]\n",
      "[Epoch 25/100] [Batch 4/6] [G loss: 0.003901]\n",
      "[Epoch 25/100] [Batch 5/6] [G loss: 0.002816]\n",
      "[Epoch 26/100] [Batch 0/6] [G loss: 0.003393]\n",
      "[Epoch 26/100] [Batch 1/6] [G loss: 0.002711]\n",
      "[Epoch 26/100] [Batch 2/6] [G loss: 0.004030]\n",
      "[Epoch 26/100] [Batch 3/6] [G loss: 0.002921]\n",
      "[Epoch 26/100] [Batch 4/6] [G loss: 0.003343]\n",
      "[Epoch 26/100] [Batch 5/6] [G loss: 0.002943]\n",
      "[Epoch 27/100] [Batch 0/6] [G loss: 0.003025]\n",
      "[Epoch 27/100] [Batch 1/6] [G loss: 0.001910]\n",
      "[Epoch 27/100] [Batch 2/6] [G loss: 0.003633]\n",
      "[Epoch 27/100] [Batch 3/6] [G loss: 0.003449]\n",
      "[Epoch 27/100] [Batch 4/6] [G loss: 0.003523]\n",
      "[Epoch 27/100] [Batch 5/6] [G loss: 0.003139]\n",
      "[Epoch 28/100] [Batch 0/6] [G loss: 0.002869]\n",
      "[Epoch 28/100] [Batch 1/6] [G loss: 0.002738]\n",
      "[Epoch 28/100] [Batch 2/6] [G loss: 0.003195]\n",
      "[Epoch 28/100] [Batch 3/6] [G loss: 0.002913]\n",
      "[Epoch 28/100] [Batch 4/6] [G loss: 0.003896]\n",
      "[Epoch 28/100] [Batch 5/6] [G loss: 0.002602]\n",
      "[Epoch 29/100] [Batch 0/6] [G loss: 0.002488]\n",
      "[Epoch 29/100] [Batch 1/6] [G loss: 0.002332]\n",
      "[Epoch 29/100] [Batch 2/6] [G loss: 0.003365]\n",
      "[Epoch 29/100] [Batch 3/6] [G loss: 0.002643]\n",
      "[Epoch 29/100] [Batch 4/6] [G loss: 0.002965]\n",
      "[Epoch 29/100] [Batch 5/6] [G loss: 0.003680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/100] [Batch 0/6] [G loss: 0.002899]\n",
      "[Epoch 30/100] [Batch 1/6] [G loss: 0.002872]\n",
      "[Epoch 30/100] [Batch 2/6] [G loss: 0.002278]\n",
      "[Epoch 30/100] [Batch 3/6] [G loss: 0.004270]\n",
      "[Epoch 30/100] [Batch 4/6] [G loss: 0.003107]\n",
      "[Epoch 30/100] [Batch 5/6] [G loss: 0.001778]\n",
      "[Epoch 31/100] [Batch 0/6] [G loss: 0.002499]\n",
      "[Epoch 31/100] [Batch 1/6] [G loss: 0.003248]\n",
      "[Epoch 31/100] [Batch 2/6] [G loss: 0.002423]\n",
      "[Epoch 31/100] [Batch 3/6] [G loss: 0.002154]\n",
      "[Epoch 31/100] [Batch 4/6] [G loss: 0.002972]\n",
      "[Epoch 31/100] [Batch 5/6] [G loss: 0.003467]\n",
      "[Epoch 32/100] [Batch 0/6] [G loss: 0.003422]\n",
      "[Epoch 32/100] [Batch 1/6] [G loss: 0.002878]\n",
      "[Epoch 32/100] [Batch 2/6] [G loss: 0.002960]\n",
      "[Epoch 32/100] [Batch 3/6] [G loss: 0.002697]\n",
      "[Epoch 32/100] [Batch 4/6] [G loss: 0.002605]\n",
      "[Epoch 32/100] [Batch 5/6] [G loss: 0.001757]\n",
      "[Epoch 33/100] [Batch 0/6] [G loss: 0.002518]\n",
      "[Epoch 33/100] [Batch 1/6] [G loss: 0.002283]\n",
      "[Epoch 33/100] [Batch 2/6] [G loss: 0.002305]\n",
      "[Epoch 33/100] [Batch 3/6] [G loss: 0.003297]\n",
      "[Epoch 33/100] [Batch 4/6] [G loss: 0.002634]\n",
      "[Epoch 33/100] [Batch 5/6] [G loss: 0.002879]\n",
      "[Epoch 34/100] [Batch 0/6] [G loss: 0.002372]\n",
      "[Epoch 34/100] [Batch 1/6] [G loss: 0.003457]\n",
      "[Epoch 34/100] [Batch 2/6] [G loss: 0.002482]\n",
      "[Epoch 34/100] [Batch 3/6] [G loss: 0.002209]\n",
      "[Epoch 34/100] [Batch 4/6] [G loss: 0.002738]\n",
      "[Epoch 34/100] [Batch 5/6] [G loss: 0.002104]\n",
      "[Epoch 35/100] [Batch 0/6] [G loss: 0.001968]\n",
      "[Epoch 35/100] [Batch 1/6] [G loss: 0.001981]\n",
      "[Epoch 35/100] [Batch 2/6] [G loss: 0.002521]\n",
      "[Epoch 35/100] [Batch 3/6] [G loss: 0.002691]\n",
      "[Epoch 35/100] [Batch 4/6] [G loss: 0.002997]\n",
      "[Epoch 35/100] [Batch 5/6] [G loss: 0.002903]\n",
      "[Epoch 36/100] [Batch 0/6] [G loss: 0.002171]\n",
      "[Epoch 36/100] [Batch 1/6] [G loss: 0.002599]\n",
      "[Epoch 36/100] [Batch 2/6] [G loss: 0.003233]\n",
      "[Epoch 36/100] [Batch 3/6] [G loss: 0.001726]\n",
      "[Epoch 36/100] [Batch 4/6] [G loss: 0.002209]\n",
      "[Epoch 36/100] [Batch 5/6] [G loss: 0.002822]\n",
      "[Epoch 37/100] [Batch 0/6] [G loss: 0.002666]\n",
      "[Epoch 37/100] [Batch 1/6] [G loss: 0.002097]\n",
      "[Epoch 37/100] [Batch 2/6] [G loss: 0.002676]\n",
      "[Epoch 37/100] [Batch 3/6] [G loss: 0.002051]\n",
      "[Epoch 37/100] [Batch 4/6] [G loss: 0.002580]\n",
      "[Epoch 37/100] [Batch 5/6] [G loss: 0.002178]\n",
      "[Epoch 38/100] [Batch 0/6] [G loss: 0.001884]\n",
      "[Epoch 38/100] [Batch 1/6] [G loss: 0.002842]\n",
      "[Epoch 38/100] [Batch 2/6] [G loss: 0.002528]\n",
      "[Epoch 38/100] [Batch 3/6] [G loss: 0.002750]\n",
      "[Epoch 38/100] [Batch 4/6] [G loss: 0.001730]\n",
      "[Epoch 38/100] [Batch 5/6] [G loss: 0.002165]\n",
      "[Epoch 39/100] [Batch 0/6] [G loss: 0.002017]\n",
      "[Epoch 39/100] [Batch 1/6] [G loss: 0.002207]\n",
      "[Epoch 39/100] [Batch 2/6] [G loss: 0.002788]\n",
      "[Epoch 39/100] [Batch 3/6] [G loss: 0.002184]\n",
      "[Epoch 39/100] [Batch 4/6] [G loss: 0.002842]\n",
      "[Epoch 39/100] [Batch 5/6] [G loss: 0.001553]\n",
      "[Epoch 40/100] [Batch 0/6] [G loss: 0.001976]\n",
      "[Epoch 40/100] [Batch 1/6] [G loss: 0.002473]\n",
      "[Epoch 40/100] [Batch 2/6] [G loss: 0.002037]\n",
      "[Epoch 40/100] [Batch 3/6] [G loss: 0.002717]\n",
      "[Epoch 40/100] [Batch 4/6] [G loss: 0.002475]\n",
      "[Epoch 40/100] [Batch 5/6] [G loss: 0.001579]\n",
      "[Epoch 41/100] [Batch 0/6] [G loss: 0.002357]\n",
      "[Epoch 41/100] [Batch 1/6] [G loss: 0.001703]\n",
      "[Epoch 41/100] [Batch 2/6] [G loss: 0.002273]\n",
      "[Epoch 41/100] [Batch 3/6] [G loss: 0.002327]\n",
      "[Epoch 41/100] [Batch 4/6] [G loss: 0.001882]\n",
      "[Epoch 41/100] [Batch 5/6] [G loss: 0.002409]\n",
      "[Epoch 42/100] [Batch 0/6] [G loss: 0.001899]\n",
      "[Epoch 42/100] [Batch 1/6] [G loss: 0.001788]\n",
      "[Epoch 42/100] [Batch 2/6] [G loss: 0.002247]\n",
      "[Epoch 42/100] [Batch 3/6] [G loss: 0.002888]\n",
      "[Epoch 42/100] [Batch 4/6] [G loss: 0.001632]\n",
      "[Epoch 42/100] [Batch 5/6] [G loss: 0.002221]\n",
      "[Epoch 43/100] [Batch 0/6] [G loss: 0.001961]\n",
      "[Epoch 43/100] [Batch 1/6] [G loss: 0.002453]\n",
      "[Epoch 43/100] [Batch 2/6] [G loss: 0.001631]\n",
      "[Epoch 43/100] [Batch 3/6] [G loss: 0.002535]\n",
      "[Epoch 43/100] [Batch 4/6] [G loss: 0.002091]\n",
      "[Epoch 43/100] [Batch 5/6] [G loss: 0.001678]\n",
      "[Epoch 44/100] [Batch 0/6] [G loss: 0.001838]\n",
      "[Epoch 44/100] [Batch 1/6] [G loss: 0.002351]\n",
      "[Epoch 44/100] [Batch 2/6] [G loss: 0.002264]\n",
      "[Epoch 44/100] [Batch 3/6] [G loss: 0.001826]\n",
      "[Epoch 44/100] [Batch 4/6] [G loss: 0.002080]\n",
      "[Epoch 44/100] [Batch 5/6] [G loss: 0.001865]\n",
      "[Epoch 45/100] [Batch 0/6] [G loss: 0.001887]\n",
      "[Epoch 45/100] [Batch 1/6] [G loss: 0.001612]\n",
      "[Epoch 45/100] [Batch 2/6] [G loss: 0.001919]\n",
      "[Epoch 45/100] [Batch 3/6] [G loss: 0.002306]\n",
      "[Epoch 45/100] [Batch 4/6] [G loss: 0.001833]\n",
      "[Epoch 45/100] [Batch 5/6] [G loss: 0.002327]\n",
      "[Epoch 46/100] [Batch 0/6] [G loss: 0.001670]\n",
      "[Epoch 46/100] [Batch 1/6] [G loss: 0.001443]\n",
      "[Epoch 46/100] [Batch 2/6] [G loss: 0.002267]\n",
      "[Epoch 46/100] [Batch 3/6] [G loss: 0.002287]\n",
      "[Epoch 46/100] [Batch 4/6] [G loss: 0.001839]\n",
      "[Epoch 46/100] [Batch 5/6] [G loss: 0.001819]\n",
      "[Epoch 47/100] [Batch 0/6] [G loss: 0.001638]\n",
      "[Epoch 47/100] [Batch 1/6] [G loss: 0.001485]\n",
      "[Epoch 47/100] [Batch 2/6] [G loss: 0.001913]\n",
      "[Epoch 47/100] [Batch 3/6] [G loss: 0.001941]\n",
      "[Epoch 47/100] [Batch 4/6] [G loss: 0.002414]\n",
      "[Epoch 47/100] [Batch 5/6] [G loss: 0.001954]\n",
      "[Epoch 48/100] [Batch 0/6] [G loss: 0.002241]\n",
      "[Epoch 48/100] [Batch 1/6] [G loss: 0.001454]\n",
      "[Epoch 48/100] [Batch 2/6] [G loss: 0.001749]\n",
      "[Epoch 48/100] [Batch 3/6] [G loss: 0.001655]\n",
      "[Epoch 48/100] [Batch 4/6] [G loss: 0.002250]\n",
      "[Epoch 48/100] [Batch 5/6] [G loss: 0.001716]\n",
      "[Epoch 49/100] [Batch 0/6] [G loss: 0.002125]\n",
      "[Epoch 49/100] [Batch 1/6] [G loss: 0.002295]\n",
      "[Epoch 49/100] [Batch 2/6] [G loss: 0.001420]\n",
      "[Epoch 49/100] [Batch 3/6] [G loss: 0.001862]\n",
      "[Epoch 49/100] [Batch 4/6] [G loss: 0.001837]\n",
      "[Epoch 49/100] [Batch 5/6] [G loss: 0.001289]\n",
      "[Epoch 50/100] [Batch 0/6] [G loss: 0.001637]\n",
      "[Epoch 50/100] [Batch 1/6] [G loss: 0.001760]\n",
      "[Epoch 50/100] [Batch 2/6] [G loss: 0.001587]\n",
      "[Epoch 50/100] [Batch 3/6] [G loss: 0.001519]\n",
      "[Epoch 50/100] [Batch 4/6] [G loss: 0.002635]\n",
      "[Epoch 50/100] [Batch 5/6] [G loss: 0.001545]\n",
      "[Epoch 51/100] [Batch 0/6] [G loss: 0.001803]\n",
      "[Epoch 51/100] [Batch 1/6] [G loss: 0.001714]\n",
      "[Epoch 51/100] [Batch 2/6] [G loss: 0.001887]\n",
      "[Epoch 51/100] [Batch 3/6] [G loss: 0.001639]\n",
      "[Epoch 51/100] [Batch 4/6] [G loss: 0.001709]\n",
      "[Epoch 51/100] [Batch 5/6] [G loss: 0.001745]\n",
      "[Epoch 52/100] [Batch 0/6] [G loss: 0.001304]\n",
      "[Epoch 52/100] [Batch 1/6] [G loss: 0.002078]\n",
      "[Epoch 52/100] [Batch 2/6] [G loss: 0.002280]\n",
      "[Epoch 52/100] [Batch 3/6] [G loss: 0.001630]\n",
      "[Epoch 52/100] [Batch 4/6] [G loss: 0.001413]\n",
      "[Epoch 52/100] [Batch 5/6] [G loss: 0.001572]\n",
      "[Epoch 53/100] [Batch 0/6] [G loss: 0.001948]\n",
      "[Epoch 53/100] [Batch 1/6] [G loss: 0.002366]\n",
      "[Epoch 53/100] [Batch 2/6] [G loss: 0.001615]\n",
      "[Epoch 53/100] [Batch 3/6] [G loss: 0.001329]\n",
      "[Epoch 53/100] [Batch 4/6] [G loss: 0.001066]\n",
      "[Epoch 53/100] [Batch 5/6] [G loss: 0.001655]\n",
      "[Epoch 54/100] [Batch 0/6] [G loss: 0.001777]\n",
      "[Epoch 54/100] [Batch 1/6] [G loss: 0.001942]\n",
      "[Epoch 54/100] [Batch 2/6] [G loss: 0.002046]\n",
      "[Epoch 54/100] [Batch 3/6] [G loss: 0.001690]\n",
      "[Epoch 54/100] [Batch 4/6] [G loss: 0.001300]\n",
      "[Epoch 54/100] [Batch 5/6] [G loss: 0.001267]\n",
      "[Epoch 55/100] [Batch 0/6] [G loss: 0.001133]\n",
      "[Epoch 55/100] [Batch 1/6] [G loss: 0.001824]\n",
      "[Epoch 55/100] [Batch 2/6] [G loss: 0.001790]\n",
      "[Epoch 55/100] [Batch 3/6] [G loss: 0.001636]\n",
      "[Epoch 55/100] [Batch 4/6] [G loss: 0.001969]\n",
      "[Epoch 55/100] [Batch 5/6] [G loss: 0.001395]\n",
      "[Epoch 56/100] [Batch 0/6] [G loss: 0.001594]\n",
      "[Epoch 56/100] [Batch 1/6] [G loss: 0.001263]\n",
      "[Epoch 56/100] [Batch 2/6] [G loss: 0.001417]\n",
      "[Epoch 56/100] [Batch 3/6] [G loss: 0.001512]\n",
      "[Epoch 56/100] [Batch 4/6] [G loss: 0.001528]\n",
      "[Epoch 56/100] [Batch 5/6] [G loss: 0.002371]\n",
      "[Epoch 57/100] [Batch 0/6] [G loss: 0.001181]\n",
      "[Epoch 57/100] [Batch 1/6] [G loss: 0.001808]\n",
      "[Epoch 57/100] [Batch 2/6] [G loss: 0.001504]\n",
      "[Epoch 57/100] [Batch 3/6] [G loss: 0.001287]\n",
      "[Epoch 57/100] [Batch 4/6] [G loss: 0.001834]\n",
      "[Epoch 57/100] [Batch 5/6] [G loss: 0.001842]\n",
      "[Epoch 58/100] [Batch 0/6] [G loss: 0.001240]\n",
      "[Epoch 58/100] [Batch 1/6] [G loss: 0.001447]\n",
      "[Epoch 58/100] [Batch 2/6] [G loss: 0.001220]\n",
      "[Epoch 58/100] [Batch 3/6] [G loss: 0.001701]\n",
      "[Epoch 58/100] [Batch 4/6] [G loss: 0.001970]\n",
      "[Epoch 58/100] [Batch 5/6] [G loss: 0.001390]\n",
      "[Epoch 59/100] [Batch 0/6] [G loss: 0.001191]\n",
      "[Epoch 59/100] [Batch 1/6] [G loss: 0.001459]\n",
      "[Epoch 59/100] [Batch 2/6] [G loss: 0.001593]\n",
      "[Epoch 59/100] [Batch 3/6] [G loss: 0.001632]\n",
      "[Epoch 59/100] [Batch 4/6] [G loss: 0.001701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 59/100] [Batch 5/6] [G loss: 0.001452]\n",
      "[Epoch 60/100] [Batch 0/6] [G loss: 0.002004]\n",
      "[Epoch 60/100] [Batch 1/6] [G loss: 0.001379]\n",
      "[Epoch 60/100] [Batch 2/6] [G loss: 0.001177]\n",
      "[Epoch 60/100] [Batch 3/6] [G loss: 0.001630]\n",
      "[Epoch 60/100] [Batch 4/6] [G loss: 0.001462]\n",
      "[Epoch 60/100] [Batch 5/6] [G loss: 0.001366]\n",
      "[Epoch 61/100] [Batch 0/6] [G loss: 0.000990]\n",
      "[Epoch 61/100] [Batch 1/6] [G loss: 0.001573]\n",
      "[Epoch 61/100] [Batch 2/6] [G loss: 0.001424]\n",
      "[Epoch 61/100] [Batch 3/6] [G loss: 0.001465]\n",
      "[Epoch 61/100] [Batch 4/6] [G loss: 0.001789]\n",
      "[Epoch 61/100] [Batch 5/6] [G loss: 0.001559]\n",
      "[Epoch 62/100] [Batch 0/6] [G loss: 0.001514]\n",
      "[Epoch 62/100] [Batch 1/6] [G loss: 0.001362]\n",
      "[Epoch 62/100] [Batch 2/6] [G loss: 0.001380]\n",
      "[Epoch 62/100] [Batch 3/6] [G loss: 0.001517]\n",
      "[Epoch 62/100] [Batch 4/6] [G loss: 0.001490]\n",
      "[Epoch 62/100] [Batch 5/6] [G loss: 0.001470]\n",
      "[Epoch 63/100] [Batch 0/6] [G loss: 0.001538]\n",
      "[Epoch 63/100] [Batch 1/6] [G loss: 0.001426]\n",
      "[Epoch 63/100] [Batch 2/6] [G loss: 0.001355]\n",
      "[Epoch 63/100] [Batch 3/6] [G loss: 0.001497]\n",
      "[Epoch 63/100] [Batch 4/6] [G loss: 0.001764]\n",
      "[Epoch 63/100] [Batch 5/6] [G loss: 0.000995]\n",
      "[Epoch 64/100] [Batch 0/6] [G loss: 0.001399]\n",
      "[Epoch 64/100] [Batch 1/6] [G loss: 0.001540]\n",
      "[Epoch 64/100] [Batch 2/6] [G loss: 0.001497]\n",
      "[Epoch 64/100] [Batch 3/6] [G loss: 0.001402]\n",
      "[Epoch 64/100] [Batch 4/6] [G loss: 0.001315]\n",
      "[Epoch 64/100] [Batch 5/6] [G loss: 0.001429]\n",
      "[Epoch 65/100] [Batch 0/6] [G loss: 0.001297]\n",
      "[Epoch 65/100] [Batch 1/6] [G loss: 0.001984]\n",
      "[Epoch 65/100] [Batch 2/6] [G loss: 0.001224]\n",
      "[Epoch 65/100] [Batch 3/6] [G loss: 0.000950]\n",
      "[Epoch 65/100] [Batch 4/6] [G loss: 0.001664]\n",
      "[Epoch 65/100] [Batch 5/6] [G loss: 0.001206]\n",
      "[Epoch 66/100] [Batch 0/6] [G loss: 0.001445]\n",
      "[Epoch 66/100] [Batch 1/6] [G loss: 0.001394]\n",
      "[Epoch 66/100] [Batch 2/6] [G loss: 0.001092]\n",
      "[Epoch 66/100] [Batch 3/6] [G loss: 0.001063]\n",
      "[Epoch 66/100] [Batch 4/6] [G loss: 0.001802]\n",
      "[Epoch 66/100] [Batch 5/6] [G loss: 0.001426]\n",
      "[Epoch 67/100] [Batch 0/6] [G loss: 0.001345]\n",
      "[Epoch 67/100] [Batch 1/6] [G loss: 0.001290]\n",
      "[Epoch 67/100] [Batch 2/6] [G loss: 0.001459]\n",
      "[Epoch 67/100] [Batch 3/6] [G loss: 0.001150]\n",
      "[Epoch 67/100] [Batch 4/6] [G loss: 0.000970]\n",
      "[Epoch 67/100] [Batch 5/6] [G loss: 0.001939]\n",
      "[Epoch 68/100] [Batch 0/6] [G loss: 0.001176]\n",
      "[Epoch 68/100] [Batch 1/6] [G loss: 0.001311]\n",
      "[Epoch 68/100] [Batch 2/6] [G loss: 0.001505]\n",
      "[Epoch 68/100] [Batch 3/6] [G loss: 0.001187]\n",
      "[Epoch 68/100] [Batch 4/6] [G loss: 0.001292]\n",
      "[Epoch 68/100] [Batch 5/6] [G loss: 0.001511]\n",
      "[Epoch 69/100] [Batch 0/6] [G loss: 0.001169]\n",
      "[Epoch 69/100] [Batch 1/6] [G loss: 0.001360]\n",
      "[Epoch 69/100] [Batch 2/6] [G loss: 0.001112]\n",
      "[Epoch 69/100] [Batch 3/6] [G loss: 0.001693]\n",
      "[Epoch 69/100] [Batch 4/6] [G loss: 0.001018]\n",
      "[Epoch 69/100] [Batch 5/6] [G loss: 0.001404]\n",
      "[Epoch 70/100] [Batch 0/6] [G loss: 0.001215]\n",
      "[Epoch 70/100] [Batch 1/6] [G loss: 0.001514]\n",
      "[Epoch 70/100] [Batch 2/6] [G loss: 0.001582]\n",
      "[Epoch 70/100] [Batch 3/6] [G loss: 0.001421]\n",
      "[Epoch 70/100] [Batch 4/6] [G loss: 0.001052]\n",
      "[Epoch 70/100] [Batch 5/6] [G loss: 0.001142]\n",
      "[Epoch 71/100] [Batch 0/6] [G loss: 0.001739]\n",
      "[Epoch 71/100] [Batch 1/6] [G loss: 0.001373]\n",
      "[Epoch 71/100] [Batch 2/6] [G loss: 0.000794]\n",
      "[Epoch 71/100] [Batch 3/6] [G loss: 0.001136]\n",
      "[Epoch 71/100] [Batch 4/6] [G loss: 0.001544]\n",
      "[Epoch 71/100] [Batch 5/6] [G loss: 0.001219]\n",
      "[Epoch 72/100] [Batch 0/6] [G loss: 0.001175]\n",
      "[Epoch 72/100] [Batch 1/6] [G loss: 0.001427]\n",
      "[Epoch 72/100] [Batch 2/6] [G loss: 0.001407]\n",
      "[Epoch 72/100] [Batch 3/6] [G loss: 0.001328]\n",
      "[Epoch 72/100] [Batch 4/6] [G loss: 0.001038]\n",
      "[Epoch 72/100] [Batch 5/6] [G loss: 0.001228]\n",
      "[Epoch 73/100] [Batch 0/6] [G loss: 0.001277]\n",
      "[Epoch 73/100] [Batch 1/6] [G loss: 0.001595]\n",
      "[Epoch 73/100] [Batch 2/6] [G loss: 0.001110]\n",
      "[Epoch 73/100] [Batch 3/6] [G loss: 0.001174]\n",
      "[Epoch 73/100] [Batch 4/6] [G loss: 0.001318]\n",
      "[Epoch 73/100] [Batch 5/6] [G loss: 0.001045]\n",
      "[Epoch 74/100] [Batch 0/6] [G loss: 0.001127]\n",
      "[Epoch 74/100] [Batch 1/6] [G loss: 0.001000]\n",
      "[Epoch 74/100] [Batch 2/6] [G loss: 0.001283]\n",
      "[Epoch 74/100] [Batch 3/6] [G loss: 0.001613]\n",
      "[Epoch 74/100] [Batch 4/6] [G loss: 0.001262]\n",
      "[Epoch 74/100] [Batch 5/6] [G loss: 0.001132]\n",
      "[Epoch 75/100] [Batch 0/6] [G loss: 0.000893]\n",
      "[Epoch 75/100] [Batch 1/6] [G loss: 0.000919]\n",
      "[Epoch 75/100] [Batch 2/6] [G loss: 0.000950]\n",
      "[Epoch 75/100] [Batch 3/6] [G loss: 0.001361]\n",
      "[Epoch 75/100] [Batch 4/6] [G loss: 0.001984]\n",
      "[Epoch 75/100] [Batch 5/6] [G loss: 0.001293]\n",
      "[Epoch 76/100] [Batch 0/6] [G loss: 0.001215]\n",
      "[Epoch 76/100] [Batch 1/6] [G loss: 0.001136]\n",
      "[Epoch 76/100] [Batch 2/6] [G loss: 0.001539]\n",
      "[Epoch 76/100] [Batch 3/6] [G loss: 0.001318]\n",
      "[Epoch 76/100] [Batch 4/6] [G loss: 0.001149]\n",
      "[Epoch 76/100] [Batch 5/6] [G loss: 0.001062]\n",
      "[Epoch 77/100] [Batch 0/6] [G loss: 0.001194]\n",
      "[Epoch 77/100] [Batch 1/6] [G loss: 0.001345]\n",
      "[Epoch 77/100] [Batch 2/6] [G loss: 0.001248]\n",
      "[Epoch 77/100] [Batch 3/6] [G loss: 0.001160]\n",
      "[Epoch 77/100] [Batch 4/6] [G loss: 0.001180]\n",
      "[Epoch 77/100] [Batch 5/6] [G loss: 0.000944]\n",
      "[Epoch 78/100] [Batch 0/6] [G loss: 0.001257]\n",
      "[Epoch 78/100] [Batch 1/6] [G loss: 0.000979]\n",
      "[Epoch 78/100] [Batch 2/6] [G loss: 0.001115]\n",
      "[Epoch 78/100] [Batch 3/6] [G loss: 0.000940]\n",
      "[Epoch 78/100] [Batch 4/6] [G loss: 0.001219]\n",
      "[Epoch 78/100] [Batch 5/6] [G loss: 0.001583]\n",
      "[Epoch 79/100] [Batch 0/6] [G loss: 0.001091]\n",
      "[Epoch 79/100] [Batch 1/6] [G loss: 0.001149]\n",
      "[Epoch 79/100] [Batch 2/6] [G loss: 0.001301]\n",
      "[Epoch 79/100] [Batch 3/6] [G loss: 0.001395]\n",
      "[Epoch 79/100] [Batch 4/6] [G loss: 0.001153]\n",
      "[Epoch 79/100] [Batch 5/6] [G loss: 0.000978]\n",
      "[Epoch 80/100] [Batch 0/6] [G loss: 0.001481]\n",
      "[Epoch 80/100] [Batch 1/6] [G loss: 0.000868]\n",
      "[Epoch 80/100] [Batch 2/6] [G loss: 0.001333]\n",
      "[Epoch 80/100] [Batch 3/6] [G loss: 0.000982]\n",
      "[Epoch 80/100] [Batch 4/6] [G loss: 0.001248]\n",
      "[Epoch 80/100] [Batch 5/6] [G loss: 0.001157]\n",
      "[Epoch 81/100] [Batch 0/6] [G loss: 0.001084]\n",
      "[Epoch 81/100] [Batch 1/6] [G loss: 0.000919]\n",
      "[Epoch 81/100] [Batch 2/6] [G loss: 0.001326]\n",
      "[Epoch 81/100] [Batch 3/6] [G loss: 0.000988]\n",
      "[Epoch 81/100] [Batch 4/6] [G loss: 0.001014]\n",
      "[Epoch 81/100] [Batch 5/6] [G loss: 0.001595]\n",
      "[Epoch 82/100] [Batch 0/6] [G loss: 0.000736]\n",
      "[Epoch 82/100] [Batch 1/6] [G loss: 0.001520]\n",
      "[Epoch 82/100] [Batch 2/6] [G loss: 0.000921]\n",
      "[Epoch 82/100] [Batch 3/6] [G loss: 0.001325]\n",
      "[Epoch 82/100] [Batch 4/6] [G loss: 0.000980]\n",
      "[Epoch 82/100] [Batch 5/6] [G loss: 0.001459]\n",
      "[Epoch 83/100] [Batch 0/6] [G loss: 0.001006]\n",
      "[Epoch 83/100] [Batch 1/6] [G loss: 0.001124]\n",
      "[Epoch 83/100] [Batch 2/6] [G loss: 0.001147]\n",
      "[Epoch 83/100] [Batch 3/6] [G loss: 0.001194]\n",
      "[Epoch 83/100] [Batch 4/6] [G loss: 0.001026]\n",
      "[Epoch 83/100] [Batch 5/6] [G loss: 0.001158]\n",
      "[Epoch 84/100] [Batch 0/6] [G loss: 0.000968]\n",
      "[Epoch 84/100] [Batch 1/6] [G loss: 0.001365]\n",
      "[Epoch 84/100] [Batch 2/6] [G loss: 0.000986]\n",
      "[Epoch 84/100] [Batch 3/6] [G loss: 0.001074]\n",
      "[Epoch 84/100] [Batch 4/6] [G loss: 0.001287]\n",
      "[Epoch 84/100] [Batch 5/6] [G loss: 0.000946]\n",
      "[Epoch 85/100] [Batch 0/6] [G loss: 0.001067]\n",
      "[Epoch 85/100] [Batch 1/6] [G loss: 0.001154]\n",
      "[Epoch 85/100] [Batch 2/6] [G loss: 0.001011]\n",
      "[Epoch 85/100] [Batch 3/6] [G loss: 0.001131]\n",
      "[Epoch 85/100] [Batch 4/6] [G loss: 0.001079]\n",
      "[Epoch 85/100] [Batch 5/6] [G loss: 0.001259]\n",
      "[Epoch 86/100] [Batch 0/6] [G loss: 0.001143]\n",
      "[Epoch 86/100] [Batch 1/6] [G loss: 0.001185]\n",
      "[Epoch 86/100] [Batch 2/6] [G loss: 0.001436]\n",
      "[Epoch 86/100] [Batch 3/6] [G loss: 0.000991]\n",
      "[Epoch 86/100] [Batch 4/6] [G loss: 0.000918]\n",
      "[Epoch 86/100] [Batch 5/6] [G loss: 0.000923]\n",
      "[Epoch 87/100] [Batch 0/6] [G loss: 0.001649]\n",
      "[Epoch 87/100] [Batch 1/6] [G loss: 0.001049]\n",
      "[Epoch 87/100] [Batch 2/6] [G loss: 0.001083]\n",
      "[Epoch 87/100] [Batch 3/6] [G loss: 0.000854]\n",
      "[Epoch 87/100] [Batch 4/6] [G loss: 0.000977]\n",
      "[Epoch 87/100] [Batch 5/6] [G loss: 0.000919]\n",
      "[Epoch 88/100] [Batch 0/6] [G loss: 0.001112]\n",
      "[Epoch 88/100] [Batch 1/6] [G loss: 0.000839]\n",
      "[Epoch 88/100] [Batch 2/6] [G loss: 0.001049]\n",
      "[Epoch 88/100] [Batch 3/6] [G loss: 0.000955]\n",
      "[Epoch 88/100] [Batch 4/6] [G loss: 0.001483]\n",
      "[Epoch 88/100] [Batch 5/6] [G loss: 0.001104]\n",
      "[Epoch 89/100] [Batch 0/6] [G loss: 0.001417]\n",
      "[Epoch 89/100] [Batch 1/6] [G loss: 0.000900]\n",
      "[Epoch 89/100] [Batch 2/6] [G loss: 0.000988]\n",
      "[Epoch 89/100] [Batch 3/6] [G loss: 0.000921]\n",
      "[Epoch 89/100] [Batch 4/6] [G loss: 0.001135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 89/100] [Batch 5/6] [G loss: 0.001136]\n",
      "[Epoch 90/100] [Batch 0/6] [G loss: 0.001084]\n",
      "[Epoch 90/100] [Batch 1/6] [G loss: 0.001061]\n",
      "[Epoch 90/100] [Batch 2/6] [G loss: 0.001135]\n",
      "[Epoch 90/100] [Batch 3/6] [G loss: 0.000814]\n",
      "[Epoch 90/100] [Batch 4/6] [G loss: 0.001211]\n",
      "[Epoch 90/100] [Batch 5/6] [G loss: 0.001036]\n",
      "[Epoch 91/100] [Batch 0/6] [G loss: 0.001128]\n",
      "[Epoch 91/100] [Batch 1/6] [G loss: 0.001007]\n",
      "[Epoch 91/100] [Batch 2/6] [G loss: 0.000762]\n",
      "[Epoch 91/100] [Batch 3/6] [G loss: 0.000752]\n",
      "[Epoch 91/100] [Batch 4/6] [G loss: 0.001493]\n",
      "[Epoch 91/100] [Batch 5/6] [G loss: 0.000971]\n",
      "[Epoch 92/100] [Batch 0/6] [G loss: 0.001083]\n",
      "[Epoch 92/100] [Batch 1/6] [G loss: 0.001028]\n",
      "[Epoch 92/100] [Batch 2/6] [G loss: 0.001136]\n",
      "[Epoch 92/100] [Batch 3/6] [G loss: 0.000860]\n",
      "[Epoch 92/100] [Batch 4/6] [G loss: 0.001132]\n",
      "[Epoch 92/100] [Batch 5/6] [G loss: 0.001005]\n",
      "[Epoch 93/100] [Batch 0/6] [G loss: 0.001424]\n",
      "[Epoch 93/100] [Batch 1/6] [G loss: 0.001293]\n",
      "[Epoch 93/100] [Batch 2/6] [G loss: 0.000810]\n",
      "[Epoch 93/100] [Batch 3/6] [G loss: 0.000857]\n",
      "[Epoch 93/100] [Batch 4/6] [G loss: 0.000839]\n",
      "[Epoch 93/100] [Batch 5/6] [G loss: 0.000997]\n",
      "[Epoch 94/100] [Batch 0/6] [G loss: 0.001557]\n",
      "[Epoch 94/100] [Batch 1/6] [G loss: 0.000702]\n",
      "[Epoch 94/100] [Batch 2/6] [G loss: 0.001019]\n",
      "[Epoch 94/100] [Batch 3/6] [G loss: 0.000925]\n",
      "[Epoch 94/100] [Batch 4/6] [G loss: 0.001121]\n",
      "[Epoch 94/100] [Batch 5/6] [G loss: 0.000803]\n",
      "[Epoch 95/100] [Batch 0/6] [G loss: 0.001147]\n",
      "[Epoch 95/100] [Batch 1/6] [G loss: 0.001124]\n",
      "[Epoch 95/100] [Batch 2/6] [G loss: 0.000558]\n",
      "[Epoch 95/100] [Batch 3/6] [G loss: 0.001032]\n",
      "[Epoch 95/100] [Batch 4/6] [G loss: 0.001380]\n",
      "[Epoch 95/100] [Batch 5/6] [G loss: 0.000931]\n",
      "[Epoch 96/100] [Batch 0/6] [G loss: 0.001137]\n",
      "[Epoch 96/100] [Batch 1/6] [G loss: 0.001071]\n",
      "[Epoch 96/100] [Batch 2/6] [G loss: 0.001002]\n",
      "[Epoch 96/100] [Batch 3/6] [G loss: 0.001023]\n",
      "[Epoch 96/100] [Batch 4/6] [G loss: 0.000863]\n",
      "[Epoch 96/100] [Batch 5/6] [G loss: 0.000956]\n",
      "[Epoch 97/100] [Batch 0/6] [G loss: 0.001193]\n",
      "[Epoch 97/100] [Batch 1/6] [G loss: 0.000994]\n",
      "[Epoch 97/100] [Batch 2/6] [G loss: 0.001036]\n",
      "[Epoch 97/100] [Batch 3/6] [G loss: 0.001232]\n",
      "[Epoch 97/100] [Batch 4/6] [G loss: 0.001001]\n",
      "[Epoch 97/100] [Batch 5/6] [G loss: 0.000660]\n",
      "[Epoch 98/100] [Batch 0/6] [G loss: 0.001141]\n",
      "[Epoch 98/100] [Batch 1/6] [G loss: 0.001102]\n",
      "[Epoch 98/100] [Batch 2/6] [G loss: 0.000907]\n",
      "[Epoch 98/100] [Batch 3/6] [G loss: 0.000908]\n",
      "[Epoch 98/100] [Batch 4/6] [G loss: 0.000927]\n",
      "[Epoch 98/100] [Batch 5/6] [G loss: 0.000959]\n",
      "[Epoch 99/100] [Batch 0/6] [G loss: 0.001025]\n",
      "[Epoch 99/100] [Batch 1/6] [G loss: 0.001019]\n",
      "[Epoch 99/100] [Batch 2/6] [G loss: 0.000866]\n",
      "[Epoch 99/100] [Batch 3/6] [G loss: 0.000953]\n",
      "[Epoch 99/100] [Batch 4/6] [G loss: 0.000972]\n",
      "[Epoch 99/100] [Batch 5/6] [G loss: 0.000959]\n"
     ]
    }
   ],
   "source": [
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        imgs, labels, paths = data\n",
    "        \n",
    "        # Target value\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Use label as generator input.. not bad\n",
    "        \n",
    "        paths = np.array([path.split('/')[-1][:-4].split('_') for path in paths]).astype(float)\n",
    "        paths[:, 0] /= 50 # -50 50\n",
    "        paths[:, 1] = (paths[:, 1]-50) / 50 # 0 100\n",
    "        positions = torch.from_numpy(paths).to(device)\n",
    "        light_coord = Variable(positions.type(FloatTensor))\n",
    "\n",
    "        z = light_coord #Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        # make z correspond to image labels\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to generate valid looking images\n",
    "        # paired with their labels\n",
    "        g_loss = mse_loss(gen_imgs, real_imgs)\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [G loss: %f]\"\n",
    "            % (epoch, n_epochs, i, len(dataloader), g_loss.item())\n",
    "        )\n",
    "        \n",
    "        if epoch % sample_interval == 0:\n",
    "            save_image(gen_imgs.data[:25], \"images/%d.png\" % epoch, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1f53e846574815b05f5d242c87b3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='z1', max=1.0, min=-1.0), FloatSlider(value=0.0, descâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.sample(z1, z2)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore latent space\n",
    "from ipywidgets import interact\n",
    "\n",
    "def sample(z1, z2):\n",
    "    #z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "    z = np.zeros((1, latent_dim))\n",
    "    z[0,0] = z1\n",
    "    z[0,1] = z2\n",
    "    z = Variable(Tensor(z))\n",
    "    gen_imgs = generator(z)\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    if channels == 1:\n",
    "        plt.imshow(gen_imgs.data[0, 0] * .5 + .5, cmap='gray')\n",
    "    else:\n",
    "        img = np.transpose(gen_imgs.cpu().detach().numpy()[0], (1, 2, 0)) * .5 + .5\n",
    "        plt.imshow(img)\n",
    "    \n",
    "interact(sample, z1=(-1, 1, .1), z2=(-1, 1, .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
