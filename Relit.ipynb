{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = mpimg.imread('./dataset/flower/-6.000000_6.000000.png')\n",
    "# imgplot = plt.imshow(img)\n",
    "# img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# img = cv2.imread('./dataset/sphere/-6.000000_6.000000.png',0)\n",
    "# edges = cv2.Canny(img,60,180)\n",
    "\n",
    "# print(edges.shape)\n",
    "\n",
    "# plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "# plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "# plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "# plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "# plt.imshow(img)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_s = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(im_s),\n",
    "#     transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, ), std=(0.5, )),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    # npimg in (channel, height, width)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add file name to the label, can be iterated as follow:\n",
    "# for i, data in enumerate(train_loader):\n",
    "#     images,labels,paths = data\n",
    "#     paths = [path.split('/')[-1] for path in paths]\n",
    "#     print(paths)\n",
    "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        return super(ImageFolderWithPaths, self).__getitem__(index) + (self.imgs[index][0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolderWithPaths(\n",
    "    root='./dataset/',\n",
    "    transform=transform\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=20,\n",
    "    num_workers=5,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "print(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "quick_images, quick_labels, quick_paths = dataiter.next()\n",
    "\n",
    "print(quick_images.shape)\n",
    "\n",
    "# print(quick_images[0].max())\n",
    "# print(quick_images[0].min())\n",
    "\n",
    "print(quick_images[:, 0:1, :, :].shape)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(quick_images))\n",
    "\n",
    "# Not sure if normalization is good or not as it darkens the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (3, im_s, im_s)\n",
    "cuda = True if torch.cuda.is_available() else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # Pixel Coord + Light Coord + Average Pixel Color\n",
    "            nn.Linear(2 + 2 + 3, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, pixel_coord, light_coord, average_rgb):\n",
    "        d_in = torch.cat((pixel_coord, light_coord, average_rgb), -1)\n",
    "        rgb = self.model(d_in)\n",
    "        return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "DNN = NN()\n",
    "\n",
    "if cuda:\n",
    "    DNN.cuda()\n",
    "    loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer = torch.optim.Adam(DNN.parameters(), lr=0.002, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "CharTensor = torch.cuda.CharTensor if cuda else torch.CharTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute Average Color of All Pixels of All Images\n",
    "def avg_save(path):\n",
    "    dic = dict()\n",
    "    total_image = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        imgs,labels,paths = data\n",
    "        # x, y positions of the light\n",
    "        batch_size = imgs.shape[0]\n",
    "        num_channel = imgs.shape[1]\n",
    "        width = imgs.shape[2]\n",
    "        height = imgs.shape[3]\n",
    "        total_image += batch_size\n",
    "        # print(batch_size, num_channel, width, height)\n",
    "        for k in range(batch_size):\n",
    "            for i in range(width):\n",
    "                for j in range(height):\n",
    "                    key_name = str(i) + '-' + str(j)\n",
    "                    if key_name in dic:\n",
    "                        dic[key_name] = imgs[k, :, i, j] + dic[key_name]\n",
    "                    else:\n",
    "                        dic[key_name] = imgs[k, :, i, j]\n",
    "    avg_img = []\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            key_name = str(i) + '-' + str(j)\n",
    "            avg_img += [dic[key_name] / total_image]\n",
    "    print(total_image)\n",
    "#     print(avg_img)\n",
    "    np.save(path, np.array([pix.detach().cpu().numpy() for pix in avg_img]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_img = avg_save('avg_basketball_128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_avg_img = np.load('./avg/avg_basketball_128.npy')\n",
    "print(loaded_avg_img.shape)\n",
    "# print(loaded_avg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "print(loaded_avg_img.shape)\n",
    "plt.imshow(loaded_avg_img.reshape(img_shape[1],img_shape[2], img_shape[0], order='F') * .5 + .5, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image(n_row, model, loaded_avg_img, lr=0, lc=0):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    width = img_shape[1]\n",
    "    height = img_shape[2]\n",
    "    avg_img = torch.from_numpy(loaded_avg_img).to(device)\n",
    "    avg_img = Variable(avg_img.type(FloatTensor))\n",
    "    img_tensor = torch.FloatTensor().to(device)\n",
    "    for k in range(height):\n",
    "        for j in range(width):\n",
    "            # Pixel Coord + Light Coord + Average Pixel Color\n",
    "            avg_value = Variable(avg_img[j + k * width].repeat(1, n_row).view(n_row, 3).type(FloatTensor))\n",
    "            pixel_coord = Variable(torch.FloatTensor([j/width, k/height])).repeat(1, n_row).view(n_row, 2).to(device)\n",
    "            # Default sample location is the light in the middle\n",
    "            light_coord = Variable(torch.FloatTensor([lr, lc])).repeat(1, n_row).view(n_row, 2).to(device)\n",
    "            generate_pixel = model(pixel_coord, light_coord, avg_value)\n",
    "#             print(generate_pixel.shape)\n",
    "            img_tensor = torch.cat((img_tensor, generate_pixel), 0)\n",
    "    \n",
    "#     print(img_tensor.shape)\n",
    "#     imgs = img_tensor.view(img_tensor.size(0), *img_shape)\n",
    "#     print(img_tensor.cpu().data.detach().numpy().reshape(img_shape[1],img_shape[2],img_shape[0],order='F').shape)\n",
    "    plt.imshow(img_tensor.cpu().data.detach().numpy().reshape(img_shape[1],img_shape[2],img_shape[0],order='F') * .5 + .5, cmap='gray')\n",
    "#     print(img_tensor)\n",
    "#     plt.imshow(loaded_avg_img.reshape(img_shape[1],img_shape[2], img_shape[0], order='F') * .5 + .5, cmap='gray')\n",
    "    #print(np.round(imgs.data * .5 + .5, 2))\n",
    "    #plt.imshow(imgs.data)\n",
    "    #save_image(imgs.data, \"images/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
    "    \n",
    "sample_image(1, DNN, loaded_avg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset params\n",
    "def reset(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "DNN.apply(reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "models = []\n",
    "\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # we are using paths here instead of labels\n",
    "        imgs,labels,paths = data\n",
    "        paths = np.array([path.split('/')[-1][:-4].split('_') for path in paths]).astype(float)\n",
    "        paths[:, 0] /= 5\n",
    "        paths[:, 1] -= 5\n",
    "        paths[:, 1] /= 5\n",
    "        print(paths)\n",
    "        positions = torch.from_numpy(paths).to(device)\n",
    "        avg_img = torch.from_numpy(loaded_avg_img).to(device)\n",
    "        imgs = imgs.to(device)\n",
    "        batch_size = imgs.shape[0]\n",
    "        width = imgs.shape[2]\n",
    "        height = imgs.shape[3]\n",
    "\n",
    "        # Configure input\n",
    "        # Pixel Coord + Light Coord + Average Pixel Color\n",
    "        avg_img = Variable(avg_img.type(FloatTensor))\n",
    "        light_coord = Variable(positions.type(FloatTensor))\n",
    "#         print(avg_img.shape) \n",
    "#         print(light_coord.shape)\n",
    "        total_losses = 0\n",
    "        for k in range(height):\n",
    "            for j in range(width):\n",
    "                # Process the batch at this pixel coord\n",
    "                \n",
    "                pixel_value = Variable(imgs[:, :, j, k].view(20, 3).type(FloatTensor))\n",
    "                \n",
    "#                 pixel_value = Variable(torch.FloatTensor([1.0, -1.0, -1.0])).repeat(1, 20).view(20, 3).to(device)\n",
    "                avg_value = Variable(avg_img[j + k * width].repeat(1, 20).view(20, 3).type(FloatTensor))\n",
    "                #avg_value = Variable(torch.FloatTensor([0.0])).repeat(1, 20).view(20, 1).to(device)\n",
    "                \n",
    "                pixel_coord = Variable(torch.FloatTensor([j/width, k/height])).repeat(1, 20).view(20, 2).to(device)\n",
    "                \n",
    "                generate_pixel = DNN(pixel_coord, light_coord, avg_value)\n",
    "                                \n",
    "                # Image with all lighting conditions\n",
    "                total_loss = loss(generate_pixel, pixel_value)\n",
    "                total_losses += total_loss.item()\n",
    "#                 if j == width/2 or k == width/2:\n",
    "#                     print(\n",
    "#                         \"[Epoch %d/%d] [Batch %d/%d] [Pixel %d-%d] [Loss: %f]\"\n",
    "#                         % (epoch + 1, epochs, i + 1, len(train_loader), j, k, total_loss)\n",
    "#                     )\n",
    "                total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [Total loss: %f]\"\n",
    "            % (epoch + 1, epochs, i + 1, len(train_loader), total_losses)\n",
    "        )\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        sample_image(1, DNN, loaded_avg_img)\n",
    "        plt.show()\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        models += [copy.deepcopy(DNN)]\n",
    "\n",
    "#         batches_done = epoch * len(dataloader) + i\n",
    "#         if batches_done % opt.sample_interval == 0:\n",
    "#             sample_image(n_row=10, batches_done=batches_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def test(lr, lc, index):\n",
    "#     sample_image(1, models[index], lr, lc)\n",
    "    sample_image(1, DNN, loaded_avg_img, lr, lc)\n",
    "    \n",
    "# interact(test, lr=(-1, 1, .1), lc=(-1, 1, .1), index=(0, 3, 1))\n",
    "interact(test, lr=(-1, 1, .1), lc=(-1, 1, .1), index=(0, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    model.eval().to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    checkpoint = {'model': model,\n",
    "          'state_dict': DNN.state_dict(),\n",
    "          'optimizer' : optimizer.state_dict()}\n",
    "    torch.save(checkpoint, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(NN(), './check_pt/trained_basketball.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./check_pt/trained_basketball_128_200.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_save('avg_cube_32')\n",
    "loaded_avg_img = np.load('./avg/avg_basketball_128.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def test(lr, lc):\n",
    "    sample_image(1, model, loaded_avg_img, lr, lc)\n",
    "    \n",
    "interact(test, lr=(-1, 1, .1), lc=(-1, 1, .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
