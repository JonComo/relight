{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            # Pixel Coord + Light Coord + Average Pixel Color\n",
    "            nn.Linear(2 + 2 + 3, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(16, 3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, pixel_coord, light_coord, average_rgb):\n",
    "        d_in = torch.cat((pixel_coord, light_coord, average_rgb), -1)\n",
    "        rgb = self.model(d_in)\n",
    "        return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "#     model.eval().to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./check_pt/trained_basketball_128_200.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_avg_img = np.load('./avg/avg_basketball_128.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_s = 128\n",
    "img_shape = (3, im_s, im_s)\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "CharTensor = torch.cuda.CharTensor if cuda else torch.CharTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image(n_row, model, loaded_avg_img, lr=0, lc=0):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    width = img_shape[1]\n",
    "    height = img_shape[2]\n",
    "    avg_img = torch.from_numpy(loaded_avg_img).to(device)\n",
    "    avg_img = Variable(avg_img.type(FloatTensor))\n",
    "    img_tensor = torch.FloatTensor().to(device)\n",
    "    for k in range(height):\n",
    "        for j in range(width):\n",
    "            # Pixel Coord + Light Coord + Average Pixel Color\n",
    "            avg_value = Variable(avg_img[j + k * width].repeat(1, n_row).view(n_row, 3).type(FloatTensor))\n",
    "            pixel_coord = Variable(torch.FloatTensor([j/width, k/height])).repeat(1, n_row).view(n_row, 2).to(device)\n",
    "            # Default sample location is the light in the middle\n",
    "            light_coord = Variable(torch.FloatTensor([lr, lc])).repeat(1, n_row).view(n_row, 2).to(device)\n",
    "            generate_pixel = model(pixel_coord, light_coord, avg_value)\n",
    "            img_tensor = torch.cat((img_tensor, generate_pixel), 0)\n",
    "    plt.imshow(img_tensor.cpu().data.detach().numpy().reshape(img_shape[1],img_shape[2],img_shape[0],order='F') * .5 + .5, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50c0aa2f4a743a8bdba964039e76ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='lr', max=1.0, min=-1.0), FloatSlider(value=0.0, descâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.test(lr, lc)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def test(lr, lc):\n",
    "    sample_image(1, model, loaded_avg_img, lr, lc)\n",
    "    \n",
    "interact(test, lr=(-1, 1, .1), lc=(-1, 1, .1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix = torch.FloatTensor(1, 2).to(device)\n",
    "light = torch.FloatTensor(1, 2).to(device)\n",
    "avg = torch.FloatTensor(1, 3).to(device)\n",
    "torch.onnx.export(model, (pix, light, avg), 'example.onnx', input_names=['pix', 'light', 'avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graph torch-jit-export (\\n  %pix[FLOAT, 1x2]\\n  %light[FLOAT, 1x2]\\n  %avg[FLOAT, 1x3]\\n) initializers (\\n  %model.0.bias[FLOAT, 16]\\n  %model.0.weight[FLOAT, 16x7]\\n  %model.2.bias[FLOAT, 16]\\n  %model.2.weight[FLOAT, 16x16]\\n  %model.4.bias[FLOAT, 3]\\n  %model.4.weight[FLOAT, 3x16]\\n) {\\n  %9 = Concat[axis = -1](%pix, %light, %avg)\\n  %10 = Gemm[alpha = 1, beta = 1, transB = 1](%9, %model.0.weight, %model.0.bias)\\n  %11 = LeakyRelu[alpha = 0.00999999977648258](%10)\\n  %12 = Gemm[alpha = 1, beta = 1, transB = 1](%11, %model.2.weight, %model.2.bias)\\n  %13 = LeakyRelu[alpha = 0.00999999977648258](%12)\\n  %14 = Gemm[alpha = 1, beta = 1, transB = 1](%13, %model.4.weight, %model.4.bias)\\n  %15 = Tanh(%14)\\n  return %15\\n}'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = onnx.load('example.onnx')\n",
    "onnx.checker.check_model(model)\n",
    "onnx.helper.printable_graph(model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36055586, -0.8710557 ,  0.6011299 ]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_sess = ort.InferenceSession('example.onnx')\n",
    "pix = torch.FloatTensor([[1, 1]]).to(device)\n",
    "light = torch.FloatTensor([[1, 1]]).to(device)\n",
    "avg = torch.FloatTensor([[1, 1, 1]]).to(device)\n",
    "ort_sess.run(None, {'pix': pix.cpu().numpy(), 'light': light.cpu().numpy(), 'avg': avg.cpu().numpy()})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_onnx_image(n_row, model, loaded_avg_img, lr=0, lc=0):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    width = img_shape[1]\n",
    "    height = img_shape[2]\n",
    "    avg_img = torch.from_numpy(loaded_avg_img).to(device)\n",
    "    avg_img = Variable(avg_img.type(FloatTensor))\n",
    "    img_tensor = torch.FloatTensor().to(device)\n",
    "    for k in range(height):\n",
    "        for j in range(width):\n",
    "            # Pixel Coord + Light Coord + Average Pixel Color\n",
    "            avg_value = Variable(avg_img[j + k * width].repeat(1, n_row).view(n_row, 3).type(FloatTensor))\n",
    "            pixel_coord = Variable(torch.FloatTensor([j/width, k/height])).repeat(1, n_row).view(n_row, 2).to(device)\n",
    "            # Default sample location is the light in the middle\n",
    "            light_coord = Variable(torch.FloatTensor([lr, lc])).repeat(1, n_row).view(n_row, 2).to(device)\n",
    "            # This is inefficient because of the to_cpu then to_gpu\n",
    "            generate_pixel = torch.FloatTensor(ort_sess.run(None, {'pix': pixel_coord.cpu().numpy(), 'light': light_coord.cpu().numpy(), 'avg': avg_value.cpu().numpy()})[0]).to(device)\n",
    "            img_tensor = torch.cat((img_tensor, generate_pixel), 0)\n",
    "    plt.imshow(img_tensor.cpu().data.detach().numpy().reshape(img_shape[1],img_shape[2],img_shape[0],order='F') * .5 + .5, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1039a0595332433ab44b121f1031be80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='lr', max=1.0, min=-1.0), FloatSlider(value=0.0, descâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.test(lr, lc)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def test(lr, lc):\n",
    "    sample_onnx_image(1, model, loaded_avg_img, lr, lc)\n",
    "    \n",
    "interact(test, lr=(-1, 1, .1), lc=(-1, 1, .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_onnx_image_cpu(n_row, model, loaded_avg_img, lr=0, lc=0):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    width = img_shape[1]\n",
    "    height = img_shape[2]\n",
    "    avg_img = loaded_avg_img\n",
    "    img_tensor = np.array([]).reshape(-1,3)\n",
    "    for k in range(height):\n",
    "        for j in range(width):\n",
    "            # Pixel Coord + Light Coord + Average Pixel Color\n",
    "            avg_value = np.array(avg_img[j + k * width]).reshape(1, 3)\n",
    "            pixel_coord = np.array([[j/width, k/height]]).reshape(1, 2)\n",
    "            # Default sample location is the light in the middle\n",
    "            light_coord = np.array([[lr, lc]]).reshape(1, 2)\n",
    "            # This is inefficient because of the to_cpu then to_gpu\n",
    "            generate_pixel = ort_sess.run(None, {'pix': pixel_coord.astype(np.float32), 'light': light_coord.astype(np.float32), 'avg': avg_value.astype(np.float32)})[0]\n",
    "            img_tensor = np.append(img_tensor, generate_pixel, axis=0)\n",
    "    plt.imshow(img_tensor.reshape(img_shape[1],img_shape[2],img_shape[0],order='F') * .5 + .5, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc2b4c161a14ade9a293ff941033d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='lr', max=1.0, min=-1.0), FloatSlider(value=0.0, descâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.test(lr, lc)>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def test(lr, lc):\n",
    "    sample_onnx_image_cpu(1, model, loaded_avg_img, lr, lc)\n",
    "    \n",
    "interact(test, lr=(-1, 1, .1), lc=(-1, 1, .1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
