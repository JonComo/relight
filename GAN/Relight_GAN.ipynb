{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful reference: https://www.cs.toronto.edu/~lczhang/360/lec/w05/autoencoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "img_dir = '../dataset'\n",
    "n_epochs = 100\n",
    "batch_size = 20\n",
    "lr = 0.0002\n",
    "b1 = .5\n",
    "b2 = .999\n",
    "n_cpu = 8\n",
    "latent_dim = 2\n",
    "img_size = 256\n",
    "channels = 3\n",
    "sample_interval = 25\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_size = img_size // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = img_size // 2 ** 4\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "\n",
    "        return validity\n",
    "\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "\n",
    "# Initialize weights\n",
    "generator.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)\n",
    "\n",
    "\n",
    "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        return super(ImageFolderWithPaths, self).__getitem__(index) + (self.imgs[index][0],)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5, ), std=(0.5, 0.5, 0.5, )),\n",
    "    ])\n",
    "    \n",
    "train_dataset = ImageFolderWithPaths(\n",
    "    root=img_dir,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=n_cpu,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/6] [D loss: 0.693209] [G loss: 0.691682]\n",
      "[Epoch 0/200] [Batch 1/6] [D loss: 0.692419] [G loss: 0.692087]\n",
      "[Epoch 0/200] [Batch 2/6] [D loss: 0.691384] [G loss: 0.692457]\n",
      "[Epoch 0/200] [Batch 3/6] [D loss: 0.689352] [G loss: 0.692803]\n",
      "[Epoch 0/200] [Batch 4/6] [D loss: 0.687504] [G loss: 0.693199]\n",
      "[Epoch 0/200] [Batch 5/6] [D loss: 0.682552] [G loss: 0.693178]\n",
      "[Epoch 1/200] [Batch 0/6] [D loss: 0.674631] [G loss: 0.691690]\n",
      "[Epoch 1/200] [Batch 1/6] [D loss: 0.657683] [G loss: 0.684936]\n",
      "[Epoch 1/200] [Batch 2/6] [D loss: 0.642764] [G loss: 0.660109]\n",
      "[Epoch 1/200] [Batch 3/6] [D loss: 0.658566] [G loss: 0.599663]\n",
      "[Epoch 1/200] [Batch 4/6] [D loss: 0.691423] [G loss: 0.473432]\n",
      "[Epoch 1/200] [Batch 5/6] [D loss: 0.776700] [G loss: 0.442369]\n",
      "[Epoch 2/200] [Batch 0/6] [D loss: 0.743901] [G loss: 0.517997]\n",
      "[Epoch 2/200] [Batch 1/6] [D loss: 0.706106] [G loss: 0.552059]\n",
      "[Epoch 2/200] [Batch 2/6] [D loss: 0.697030] [G loss: 0.630843]\n",
      "[Epoch 2/200] [Batch 3/6] [D loss: 0.703879] [G loss: 0.665081]\n",
      "[Epoch 2/200] [Batch 4/6] [D loss: 0.700361] [G loss: 0.679155]\n",
      "[Epoch 2/200] [Batch 5/6] [D loss: 0.694590] [G loss: 0.700265]\n",
      "[Epoch 3/200] [Batch 0/6] [D loss: 0.686117] [G loss: 0.714498]\n",
      "[Epoch 3/200] [Batch 1/6] [D loss: 0.686158] [G loss: 0.715806]\n",
      "[Epoch 3/200] [Batch 2/6] [D loss: 0.684685] [G loss: 0.717410]\n",
      "[Epoch 3/200] [Batch 3/6] [D loss: 0.690591] [G loss: 0.717707]\n",
      "[Epoch 3/200] [Batch 4/6] [D loss: 0.686305] [G loss: 0.722095]\n",
      "[Epoch 3/200] [Batch 5/6] [D loss: 0.685695] [G loss: 0.727661]\n",
      "[Epoch 4/200] [Batch 0/6] [D loss: 0.678291] [G loss: 0.730174]\n",
      "[Epoch 4/200] [Batch 1/6] [D loss: 0.674750] [G loss: 0.735514]\n",
      "[Epoch 4/200] [Batch 2/6] [D loss: 0.668491] [G loss: 0.744935]\n",
      "[Epoch 4/200] [Batch 3/6] [D loss: 0.668703] [G loss: 0.755630]\n",
      "[Epoch 4/200] [Batch 4/6] [D loss: 0.646868] [G loss: 0.760097]\n",
      "[Epoch 4/200] [Batch 5/6] [D loss: 0.651133] [G loss: 0.729435]\n",
      "[Epoch 5/200] [Batch 0/6] [D loss: 0.664000] [G loss: 0.732767]\n",
      "[Epoch 5/200] [Batch 1/6] [D loss: 0.660745] [G loss: 0.732380]\n",
      "[Epoch 5/200] [Batch 2/6] [D loss: 0.653056] [G loss: 0.729061]\n",
      "[Epoch 5/200] [Batch 3/6] [D loss: 0.642265] [G loss: 0.684445]\n",
      "[Epoch 5/200] [Batch 4/6] [D loss: 0.654897] [G loss: 0.654810]\n",
      "[Epoch 5/200] [Batch 5/6] [D loss: 0.653511] [G loss: 0.608361]\n",
      "[Epoch 6/200] [Batch 0/6] [D loss: 0.667530] [G loss: 0.611815]\n",
      "[Epoch 6/200] [Batch 1/6] [D loss: 0.626524] [G loss: 0.659561]\n",
      "[Epoch 6/200] [Batch 2/6] [D loss: 0.593929] [G loss: 0.706109]\n",
      "[Epoch 6/200] [Batch 3/6] [D loss: 0.553604] [G loss: 0.685350]\n",
      "[Epoch 6/200] [Batch 4/6] [D loss: 0.550058] [G loss: 0.686305]\n",
      "[Epoch 6/200] [Batch 5/6] [D loss: 0.576651] [G loss: 0.638381]\n",
      "[Epoch 7/200] [Batch 0/6] [D loss: 0.635009] [G loss: 0.650974]\n",
      "[Epoch 7/200] [Batch 1/6] [D loss: 0.608715] [G loss: 0.799051]\n",
      "[Epoch 7/200] [Batch 2/6] [D loss: 0.570485] [G loss: 0.774230]\n",
      "[Epoch 7/200] [Batch 3/6] [D loss: 0.529161] [G loss: 0.892844]\n",
      "[Epoch 7/200] [Batch 4/6] [D loss: 0.508075] [G loss: 1.055685]\n",
      "[Epoch 7/200] [Batch 5/6] [D loss: 0.620094] [G loss: 0.786132]\n",
      "[Epoch 8/200] [Batch 0/6] [D loss: 0.631405] [G loss: 0.906462]\n",
      "[Epoch 8/200] [Batch 1/6] [D loss: 0.781335] [G loss: 0.781073]\n",
      "[Epoch 8/200] [Batch 2/6] [D loss: 0.813880] [G loss: 0.644329]\n",
      "[Epoch 8/200] [Batch 3/6] [D loss: 0.728886] [G loss: 0.668275]\n",
      "[Epoch 8/200] [Batch 4/6] [D loss: 0.657293] [G loss: 0.718641]\n",
      "[Epoch 8/200] [Batch 5/6] [D loss: 0.651269] [G loss: 0.731049]\n",
      "[Epoch 9/200] [Batch 0/6] [D loss: 0.593863] [G loss: 0.617699]\n",
      "[Epoch 9/200] [Batch 1/6] [D loss: 0.630996] [G loss: 0.664628]\n",
      "[Epoch 9/200] [Batch 2/6] [D loss: 0.634175] [G loss: 0.735329]\n",
      "[Epoch 9/200] [Batch 3/6] [D loss: 0.656806] [G loss: 0.630355]\n",
      "[Epoch 9/200] [Batch 4/6] [D loss: 0.653098] [G loss: 0.700070]\n",
      "[Epoch 9/200] [Batch 5/6] [D loss: 0.559959] [G loss: 0.833135]\n",
      "[Epoch 10/200] [Batch 0/6] [D loss: 0.631683] [G loss: 0.706621]\n",
      "[Epoch 10/200] [Batch 1/6] [D loss: 0.679487] [G loss: 0.699359]\n",
      "[Epoch 10/200] [Batch 2/6] [D loss: 0.720260] [G loss: 0.741781]\n",
      "[Epoch 10/200] [Batch 3/6] [D loss: 0.699776] [G loss: 0.765247]\n",
      "[Epoch 10/200] [Batch 4/6] [D loss: 0.655849] [G loss: 0.774563]\n",
      "[Epoch 10/200] [Batch 5/6] [D loss: 0.746095] [G loss: 0.768719]\n",
      "[Epoch 11/200] [Batch 0/6] [D loss: 0.707188] [G loss: 0.766719]\n",
      "[Epoch 11/200] [Batch 1/6] [D loss: 0.629598] [G loss: 0.731846]\n",
      "[Epoch 11/200] [Batch 2/6] [D loss: 0.670891] [G loss: 0.771117]\n",
      "[Epoch 11/200] [Batch 3/6] [D loss: 0.647384] [G loss: 0.691157]\n",
      "[Epoch 11/200] [Batch 4/6] [D loss: 0.615520] [G loss: 0.603831]\n",
      "[Epoch 11/200] [Batch 5/6] [D loss: 0.649056] [G loss: 0.646986]\n",
      "[Epoch 12/200] [Batch 0/6] [D loss: 0.594657] [G loss: 0.715442]\n",
      "[Epoch 12/200] [Batch 1/6] [D loss: 0.571368] [G loss: 0.809667]\n",
      "[Epoch 12/200] [Batch 2/6] [D loss: 0.606948] [G loss: 0.754112]\n",
      "[Epoch 12/200] [Batch 3/6] [D loss: 0.692178] [G loss: 0.658386]\n",
      "[Epoch 12/200] [Batch 4/6] [D loss: 0.577785] [G loss: 0.868002]\n",
      "[Epoch 12/200] [Batch 5/6] [D loss: 0.666895] [G loss: 0.811749]\n",
      "[Epoch 13/200] [Batch 0/6] [D loss: 0.643891] [G loss: 0.532411]\n",
      "[Epoch 13/200] [Batch 1/6] [D loss: 0.748621] [G loss: 0.651010]\n",
      "[Epoch 13/200] [Batch 2/6] [D loss: 0.727642] [G loss: 0.795268]\n",
      "[Epoch 13/200] [Batch 3/6] [D loss: 0.689467] [G loss: 0.939520]\n",
      "[Epoch 13/200] [Batch 4/6] [D loss: 0.739367] [G loss: 0.688589]\n",
      "[Epoch 13/200] [Batch 5/6] [D loss: 0.791060] [G loss: 0.959502]\n",
      "[Epoch 14/200] [Batch 0/6] [D loss: 0.755295] [G loss: 0.842438]\n",
      "[Epoch 14/200] [Batch 1/6] [D loss: 0.762193] [G loss: 0.804913]\n",
      "[Epoch 14/200] [Batch 2/6] [D loss: 0.665910] [G loss: 0.772724]\n",
      "[Epoch 14/200] [Batch 3/6] [D loss: 0.704121] [G loss: 0.792422]\n",
      "[Epoch 14/200] [Batch 4/6] [D loss: 0.780751] [G loss: 0.706100]\n",
      "[Epoch 14/200] [Batch 5/6] [D loss: 0.704284] [G loss: 0.756566]\n",
      "[Epoch 15/200] [Batch 0/6] [D loss: 0.696910] [G loss: 0.871479]\n",
      "[Epoch 15/200] [Batch 1/6] [D loss: 0.688039] [G loss: 0.868321]\n",
      "[Epoch 15/200] [Batch 2/6] [D loss: 0.658849] [G loss: 0.799735]\n",
      "[Epoch 15/200] [Batch 3/6] [D loss: 0.731808] [G loss: 0.678497]\n",
      "[Epoch 15/200] [Batch 4/6] [D loss: 0.685122] [G loss: 0.845743]\n",
      "[Epoch 15/200] [Batch 5/6] [D loss: 0.657321] [G loss: 0.782055]\n",
      "[Epoch 16/200] [Batch 0/6] [D loss: 0.671008] [G loss: 0.669352]\n",
      "[Epoch 16/200] [Batch 1/6] [D loss: 0.743265] [G loss: 0.751308]\n",
      "[Epoch 16/200] [Batch 2/6] [D loss: 0.648937] [G loss: 0.716571]\n",
      "[Epoch 16/200] [Batch 3/6] [D loss: 0.630991] [G loss: 0.683273]\n",
      "[Epoch 16/200] [Batch 4/6] [D loss: 0.662090] [G loss: 0.705776]\n",
      "[Epoch 16/200] [Batch 5/6] [D loss: 0.688662] [G loss: 0.706261]\n",
      "[Epoch 17/200] [Batch 0/6] [D loss: 0.711775] [G loss: 0.700814]\n",
      "[Epoch 17/200] [Batch 1/6] [D loss: 0.677238] [G loss: 0.825917]\n",
      "[Epoch 17/200] [Batch 2/6] [D loss: 0.740865] [G loss: 0.771190]\n",
      "[Epoch 17/200] [Batch 3/6] [D loss: 0.720413] [G loss: 0.875690]\n",
      "[Epoch 17/200] [Batch 4/6] [D loss: 0.747808] [G loss: 0.782372]\n",
      "[Epoch 17/200] [Batch 5/6] [D loss: 0.699511] [G loss: 0.698296]\n",
      "[Epoch 18/200] [Batch 0/6] [D loss: 0.666531] [G loss: 0.726049]\n",
      "[Epoch 18/200] [Batch 1/6] [D loss: 0.704185] [G loss: 0.790823]\n",
      "[Epoch 18/200] [Batch 2/6] [D loss: 0.648049] [G loss: 0.815176]\n",
      "[Epoch 18/200] [Batch 3/6] [D loss: 0.658949] [G loss: 0.740262]\n",
      "[Epoch 18/200] [Batch 4/6] [D loss: 0.667333] [G loss: 0.790693]\n",
      "[Epoch 18/200] [Batch 5/6] [D loss: 0.629588] [G loss: 0.674080]\n",
      "[Epoch 19/200] [Batch 0/6] [D loss: 0.728212] [G loss: 0.587078]\n",
      "[Epoch 19/200] [Batch 1/6] [D loss: 0.711648] [G loss: 0.607221]\n",
      "[Epoch 19/200] [Batch 2/6] [D loss: 0.789521] [G loss: 0.688428]\n",
      "[Epoch 19/200] [Batch 3/6] [D loss: 0.757085] [G loss: 0.697553]\n",
      "[Epoch 19/200] [Batch 4/6] [D loss: 0.766823] [G loss: 0.781353]\n",
      "[Epoch 19/200] [Batch 5/6] [D loss: 0.725209] [G loss: 0.720935]\n",
      "[Epoch 20/200] [Batch 0/6] [D loss: 0.760388] [G loss: 0.754041]\n",
      "[Epoch 20/200] [Batch 1/6] [D loss: 0.702282] [G loss: 0.762428]\n",
      "[Epoch 20/200] [Batch 2/6] [D loss: 0.687958] [G loss: 0.765002]\n",
      "[Epoch 20/200] [Batch 3/6] [D loss: 0.631642] [G loss: 0.766458]\n",
      "[Epoch 20/200] [Batch 4/6] [D loss: 0.652337] [G loss: 0.779459]\n",
      "[Epoch 20/200] [Batch 5/6] [D loss: 0.682650] [G loss: 0.725257]\n",
      "[Epoch 21/200] [Batch 0/6] [D loss: 0.596518] [G loss: 0.778050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/200] [Batch 1/6] [D loss: 0.621979] [G loss: 0.814500]\n",
      "[Epoch 21/200] [Batch 2/6] [D loss: 0.728016] [G loss: 0.689179]\n",
      "[Epoch 21/200] [Batch 3/6] [D loss: 0.615353] [G loss: 0.666093]\n",
      "[Epoch 21/200] [Batch 4/6] [D loss: 0.685234] [G loss: 0.555764]\n",
      "[Epoch 21/200] [Batch 5/6] [D loss: 0.705958] [G loss: 0.619468]\n",
      "[Epoch 22/200] [Batch 0/6] [D loss: 0.711321] [G loss: 0.598957]\n",
      "[Epoch 22/200] [Batch 1/6] [D loss: 0.680507] [G loss: 0.654149]\n",
      "[Epoch 22/200] [Batch 2/6] [D loss: 0.719054] [G loss: 0.609707]\n",
      "[Epoch 22/200] [Batch 3/6] [D loss: 0.725845] [G loss: 0.677982]\n",
      "[Epoch 22/200] [Batch 4/6] [D loss: 0.740699] [G loss: 0.690626]\n",
      "[Epoch 22/200] [Batch 5/6] [D loss: 0.748055] [G loss: 0.638531]\n",
      "[Epoch 23/200] [Batch 0/6] [D loss: 0.758780] [G loss: 0.700709]\n",
      "[Epoch 23/200] [Batch 1/6] [D loss: 0.689735] [G loss: 0.750688]\n",
      "[Epoch 23/200] [Batch 2/6] [D loss: 0.720902] [G loss: 0.720737]\n",
      "[Epoch 23/200] [Batch 3/6] [D loss: 0.716493] [G loss: 0.674857]\n",
      "[Epoch 23/200] [Batch 4/6] [D loss: 0.720584] [G loss: 0.669820]\n",
      "[Epoch 23/200] [Batch 5/6] [D loss: 0.721522] [G loss: 0.710689]\n",
      "[Epoch 24/200] [Batch 0/6] [D loss: 0.678658] [G loss: 0.700672]\n",
      "[Epoch 24/200] [Batch 1/6] [D loss: 0.686414] [G loss: 0.753336]\n",
      "[Epoch 24/200] [Batch 2/6] [D loss: 0.697869] [G loss: 0.714356]\n",
      "[Epoch 24/200] [Batch 3/6] [D loss: 0.725026] [G loss: 0.678679]\n",
      "[Epoch 24/200] [Batch 4/6] [D loss: 0.706489] [G loss: 0.709472]\n",
      "[Epoch 24/200] [Batch 5/6] [D loss: 0.745568] [G loss: 0.649282]\n",
      "[Epoch 25/200] [Batch 0/6] [D loss: 0.713083] [G loss: 0.751195]\n",
      "[Epoch 25/200] [Batch 1/6] [D loss: 0.692331] [G loss: 0.707433]\n",
      "[Epoch 25/200] [Batch 2/6] [D loss: 0.665066] [G loss: 0.736802]\n",
      "[Epoch 25/200] [Batch 3/6] [D loss: 0.653717] [G loss: 0.762142]\n",
      "[Epoch 25/200] [Batch 4/6] [D loss: 0.675385] [G loss: 0.717015]\n",
      "[Epoch 25/200] [Batch 5/6] [D loss: 0.690202] [G loss: 0.683968]\n",
      "[Epoch 26/200] [Batch 0/6] [D loss: 0.741814] [G loss: 0.712758]\n",
      "[Epoch 26/200] [Batch 1/6] [D loss: 0.694103] [G loss: 0.778470]\n",
      "[Epoch 26/200] [Batch 2/6] [D loss: 0.698990] [G loss: 0.689105]\n",
      "[Epoch 26/200] [Batch 3/6] [D loss: 0.676823] [G loss: 0.702216]\n",
      "[Epoch 26/200] [Batch 4/6] [D loss: 0.709240] [G loss: 0.745029]\n",
      "[Epoch 26/200] [Batch 5/6] [D loss: 0.660867] [G loss: 0.748553]\n",
      "[Epoch 27/200] [Batch 0/6] [D loss: 0.728190] [G loss: 0.696737]\n",
      "[Epoch 27/200] [Batch 1/6] [D loss: 0.688892] [G loss: 0.681724]\n",
      "[Epoch 27/200] [Batch 2/6] [D loss: 0.662131] [G loss: 0.704003]\n",
      "[Epoch 27/200] [Batch 3/6] [D loss: 0.700198] [G loss: 0.772056]\n",
      "[Epoch 27/200] [Batch 4/6] [D loss: 0.745608] [G loss: 0.692911]\n",
      "[Epoch 27/200] [Batch 5/6] [D loss: 0.695705] [G loss: 0.712382]\n",
      "[Epoch 28/200] [Batch 0/6] [D loss: 0.723803] [G loss: 0.757479]\n",
      "[Epoch 28/200] [Batch 1/6] [D loss: 0.701538] [G loss: 0.766069]\n",
      "[Epoch 28/200] [Batch 2/6] [D loss: 0.686466] [G loss: 0.757635]\n",
      "[Epoch 28/200] [Batch 3/6] [D loss: 0.715086] [G loss: 0.730003]\n",
      "[Epoch 28/200] [Batch 4/6] [D loss: 0.715699] [G loss: 0.663949]\n",
      "[Epoch 28/200] [Batch 5/6] [D loss: 0.676039] [G loss: 0.755360]\n",
      "[Epoch 29/200] [Batch 0/6] [D loss: 0.707605] [G loss: 0.719705]\n",
      "[Epoch 29/200] [Batch 1/6] [D loss: 0.719512] [G loss: 0.697718]\n",
      "[Epoch 29/200] [Batch 2/6] [D loss: 0.700308] [G loss: 0.681574]\n",
      "[Epoch 29/200] [Batch 3/6] [D loss: 0.686323] [G loss: 0.690398]\n",
      "[Epoch 29/200] [Batch 4/6] [D loss: 0.687635] [G loss: 0.668231]\n",
      "[Epoch 29/200] [Batch 5/6] [D loss: 0.679559] [G loss: 0.619209]\n",
      "[Epoch 30/200] [Batch 0/6] [D loss: 0.714455] [G loss: 0.681894]\n",
      "[Epoch 30/200] [Batch 1/6] [D loss: 0.685738] [G loss: 0.704966]\n",
      "[Epoch 30/200] [Batch 2/6] [D loss: 0.697454] [G loss: 0.686883]\n",
      "[Epoch 30/200] [Batch 3/6] [D loss: 0.728663] [G loss: 0.713142]\n",
      "[Epoch 30/200] [Batch 4/6] [D loss: 0.712881] [G loss: 0.660306]\n",
      "[Epoch 30/200] [Batch 5/6] [D loss: 0.703207] [G loss: 0.696100]\n",
      "[Epoch 31/200] [Batch 0/6] [D loss: 0.705559] [G loss: 0.717290]\n",
      "[Epoch 31/200] [Batch 1/6] [D loss: 0.710517] [G loss: 0.690533]\n",
      "[Epoch 31/200] [Batch 2/6] [D loss: 0.682834] [G loss: 0.705668]\n",
      "[Epoch 31/200] [Batch 3/6] [D loss: 0.680058] [G loss: 0.725536]\n",
      "[Epoch 31/200] [Batch 4/6] [D loss: 0.676279] [G loss: 0.721570]\n",
      "[Epoch 31/200] [Batch 5/6] [D loss: 0.676077] [G loss: 0.694951]\n",
      "[Epoch 32/200] [Batch 0/6] [D loss: 0.658783] [G loss: 0.656443]\n",
      "[Epoch 32/200] [Batch 1/6] [D loss: 0.690496] [G loss: 0.683680]\n",
      "[Epoch 32/200] [Batch 2/6] [D loss: 0.677438] [G loss: 0.707640]\n",
      "[Epoch 32/200] [Batch 3/6] [D loss: 0.710241] [G loss: 0.673724]\n",
      "[Epoch 32/200] [Batch 4/6] [D loss: 0.700071] [G loss: 0.753243]\n",
      "[Epoch 32/200] [Batch 5/6] [D loss: 0.653350] [G loss: 0.698875]\n",
      "[Epoch 33/200] [Batch 0/6] [D loss: 0.711858] [G loss: 0.724473]\n",
      "[Epoch 33/200] [Batch 1/6] [D loss: 0.711003] [G loss: 0.696013]\n",
      "[Epoch 33/200] [Batch 2/6] [D loss: 0.697731] [G loss: 0.726685]\n",
      "[Epoch 33/200] [Batch 3/6] [D loss: 0.693343] [G loss: 0.768934]\n",
      "[Epoch 33/200] [Batch 4/6] [D loss: 0.677046] [G loss: 0.754802]\n",
      "[Epoch 33/200] [Batch 5/6] [D loss: 0.689141] [G loss: 0.739254]\n",
      "[Epoch 34/200] [Batch 0/6] [D loss: 0.704368] [G loss: 0.692442]\n",
      "[Epoch 34/200] [Batch 1/6] [D loss: 0.696484] [G loss: 0.713970]\n",
      "[Epoch 34/200] [Batch 2/6] [D loss: 0.696177] [G loss: 0.731388]\n",
      "[Epoch 34/200] [Batch 3/6] [D loss: 0.674575] [G loss: 0.726201]\n",
      "[Epoch 34/200] [Batch 4/6] [D loss: 0.664505] [G loss: 0.750370]\n",
      "[Epoch 34/200] [Batch 5/6] [D loss: 0.677420] [G loss: 0.759749]\n",
      "[Epoch 35/200] [Batch 0/6] [D loss: 0.654718] [G loss: 0.744265]\n",
      "[Epoch 35/200] [Batch 1/6] [D loss: 0.684673] [G loss: 0.683837]\n",
      "[Epoch 35/200] [Batch 2/6] [D loss: 0.714287] [G loss: 0.658102]\n",
      "[Epoch 35/200] [Batch 3/6] [D loss: 0.714503] [G loss: 0.674831]\n",
      "[Epoch 35/200] [Batch 4/6] [D loss: 0.726555] [G loss: 0.686983]\n",
      "[Epoch 35/200] [Batch 5/6] [D loss: 0.712815] [G loss: 0.715438]\n",
      "[Epoch 36/200] [Batch 0/6] [D loss: 0.720359] [G loss: 0.758667]\n",
      "[Epoch 36/200] [Batch 1/6] [D loss: 0.691736] [G loss: 0.709613]\n",
      "[Epoch 36/200] [Batch 2/6] [D loss: 0.713964] [G loss: 0.698413]\n",
      "[Epoch 36/200] [Batch 3/6] [D loss: 0.712391] [G loss: 0.701008]\n",
      "[Epoch 36/200] [Batch 4/6] [D loss: 0.688621] [G loss: 0.672127]\n",
      "[Epoch 36/200] [Batch 5/6] [D loss: 0.715841] [G loss: 0.671241]\n",
      "[Epoch 37/200] [Batch 0/6] [D loss: 0.731398] [G loss: 0.668688]\n",
      "[Epoch 37/200] [Batch 1/6] [D loss: 0.704075] [G loss: 0.677346]\n",
      "[Epoch 37/200] [Batch 2/6] [D loss: 0.692331] [G loss: 0.670885]\n",
      "[Epoch 37/200] [Batch 3/6] [D loss: 0.703617] [G loss: 0.699256]\n",
      "[Epoch 37/200] [Batch 4/6] [D loss: 0.689693] [G loss: 0.692678]\n",
      "[Epoch 37/200] [Batch 5/6] [D loss: 0.691027] [G loss: 0.690967]\n",
      "[Epoch 38/200] [Batch 0/6] [D loss: 0.683239] [G loss: 0.687651]\n",
      "[Epoch 38/200] [Batch 1/6] [D loss: 0.708479] [G loss: 0.631494]\n",
      "[Epoch 38/200] [Batch 2/6] [D loss: 0.704620] [G loss: 0.678080]\n",
      "[Epoch 38/200] [Batch 3/6] [D loss: 0.713223] [G loss: 0.676075]\n",
      "[Epoch 38/200] [Batch 4/6] [D loss: 0.705029] [G loss: 0.726113]\n",
      "[Epoch 38/200] [Batch 5/6] [D loss: 0.690262] [G loss: 0.717438]\n",
      "[Epoch 39/200] [Batch 0/6] [D loss: 0.703927] [G loss: 0.703852]\n",
      "[Epoch 39/200] [Batch 1/6] [D loss: 0.693977] [G loss: 0.740453]\n",
      "[Epoch 39/200] [Batch 2/6] [D loss: 0.701536] [G loss: 0.747765]\n",
      "[Epoch 39/200] [Batch 3/6] [D loss: 0.703921] [G loss: 0.722846]\n",
      "[Epoch 39/200] [Batch 4/6] [D loss: 0.680114] [G loss: 0.747216]\n",
      "[Epoch 39/200] [Batch 5/6] [D loss: 0.684711] [G loss: 0.724477]\n",
      "[Epoch 40/200] [Batch 0/6] [D loss: 0.694105] [G loss: 0.757110]\n",
      "[Epoch 40/200] [Batch 1/6] [D loss: 0.698787] [G loss: 0.719498]\n",
      "[Epoch 40/200] [Batch 2/6] [D loss: 0.682307] [G loss: 0.719816]\n",
      "[Epoch 40/200] [Batch 3/6] [D loss: 0.687606] [G loss: 0.699477]\n",
      "[Epoch 40/200] [Batch 4/6] [D loss: 0.684248] [G loss: 0.701524]\n",
      "[Epoch 40/200] [Batch 5/6] [D loss: 0.686994] [G loss: 0.691080]\n",
      "[Epoch 41/200] [Batch 0/6] [D loss: 0.688449] [G loss: 0.697972]\n",
      "[Epoch 41/200] [Batch 1/6] [D loss: 0.692673] [G loss: 0.644193]\n",
      "[Epoch 41/200] [Batch 2/6] [D loss: 0.687601] [G loss: 0.661328]\n",
      "[Epoch 41/200] [Batch 3/6] [D loss: 0.706438] [G loss: 0.680657]\n",
      "[Epoch 41/200] [Batch 4/6] [D loss: 0.693221] [G loss: 0.687804]\n",
      "[Epoch 41/200] [Batch 5/6] [D loss: 0.701695] [G loss: 0.720224]\n",
      "[Epoch 42/200] [Batch 0/6] [D loss: 0.700987] [G loss: 0.709492]\n",
      "[Epoch 42/200] [Batch 1/6] [D loss: 0.690621] [G loss: 0.725442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42/200] [Batch 2/6] [D loss: 0.690417] [G loss: 0.707697]\n",
      "[Epoch 42/200] [Batch 3/6] [D loss: 0.694563] [G loss: 0.715728]\n",
      "[Epoch 42/200] [Batch 4/6] [D loss: 0.703983] [G loss: 0.737373]\n",
      "[Epoch 42/200] [Batch 5/6] [D loss: 0.682843] [G loss: 0.697803]\n",
      "[Epoch 43/200] [Batch 0/6] [D loss: 0.686903] [G loss: 0.710279]\n",
      "[Epoch 43/200] [Batch 1/6] [D loss: 0.695777] [G loss: 0.702707]\n",
      "[Epoch 43/200] [Batch 2/6] [D loss: 0.702898] [G loss: 0.692184]\n",
      "[Epoch 43/200] [Batch 3/6] [D loss: 0.710948] [G loss: 0.706478]\n",
      "[Epoch 43/200] [Batch 4/6] [D loss: 0.715878] [G loss: 0.704295]\n",
      "[Epoch 43/200] [Batch 5/6] [D loss: 0.699112] [G loss: 0.734653]\n",
      "[Epoch 44/200] [Batch 0/6] [D loss: 0.705099] [G loss: 0.689840]\n",
      "[Epoch 44/200] [Batch 1/6] [D loss: 0.695533] [G loss: 0.716887]\n",
      "[Epoch 44/200] [Batch 2/6] [D loss: 0.695812] [G loss: 0.694710]\n",
      "[Epoch 44/200] [Batch 3/6] [D loss: 0.697530] [G loss: 0.685388]\n",
      "[Epoch 44/200] [Batch 4/6] [D loss: 0.699271] [G loss: 0.695562]\n",
      "[Epoch 44/200] [Batch 5/6] [D loss: 0.697132] [G loss: 0.682963]\n",
      "[Epoch 45/200] [Batch 0/6] [D loss: 0.682857] [G loss: 0.685133]\n",
      "[Epoch 45/200] [Batch 1/6] [D loss: 0.701755] [G loss: 0.681630]\n",
      "[Epoch 45/200] [Batch 2/6] [D loss: 0.684912] [G loss: 0.666535]\n",
      "[Epoch 45/200] [Batch 3/6] [D loss: 0.696624] [G loss: 0.684392]\n",
      "[Epoch 45/200] [Batch 4/6] [D loss: 0.690053] [G loss: 0.671283]\n",
      "[Epoch 45/200] [Batch 5/6] [D loss: 0.698907] [G loss: 0.683621]\n",
      "[Epoch 46/200] [Batch 0/6] [D loss: 0.697592] [G loss: 0.695903]\n",
      "[Epoch 46/200] [Batch 1/6] [D loss: 0.688990] [G loss: 0.689858]\n",
      "[Epoch 46/200] [Batch 2/6] [D loss: 0.684240] [G loss: 0.684656]\n",
      "[Epoch 46/200] [Batch 3/6] [D loss: 0.696782] [G loss: 0.650637]\n",
      "[Epoch 46/200] [Batch 4/6] [D loss: 0.694522] [G loss: 0.687587]\n",
      "[Epoch 46/200] [Batch 5/6] [D loss: 0.689822] [G loss: 0.687029]\n",
      "[Epoch 47/200] [Batch 0/6] [D loss: 0.700770] [G loss: 0.671766]\n",
      "[Epoch 47/200] [Batch 1/6] [D loss: 0.697418] [G loss: 0.663456]\n",
      "[Epoch 47/200] [Batch 2/6] [D loss: 0.694105] [G loss: 0.669346]\n",
      "[Epoch 47/200] [Batch 3/6] [D loss: 0.708256] [G loss: 0.679118]\n",
      "[Epoch 47/200] [Batch 4/6] [D loss: 0.688763] [G loss: 0.702105]\n",
      "[Epoch 47/200] [Batch 5/6] [D loss: 0.682220] [G loss: 0.702199]\n",
      "[Epoch 48/200] [Batch 0/6] [D loss: 0.702743] [G loss: 0.708348]\n",
      "[Epoch 48/200] [Batch 1/6] [D loss: 0.694239] [G loss: 0.709481]\n",
      "[Epoch 48/200] [Batch 2/6] [D loss: 0.681998] [G loss: 0.670240]\n",
      "[Epoch 48/200] [Batch 3/6] [D loss: 0.689042] [G loss: 0.703795]\n",
      "[Epoch 48/200] [Batch 4/6] [D loss: 0.671527] [G loss: 0.671896]\n",
      "[Epoch 48/200] [Batch 5/6] [D loss: 0.691248] [G loss: 0.682121]\n",
      "[Epoch 49/200] [Batch 0/6] [D loss: 0.696840] [G loss: 0.704611]\n",
      "[Epoch 49/200] [Batch 1/6] [D loss: 0.678133] [G loss: 0.671951]\n",
      "[Epoch 49/200] [Batch 2/6] [D loss: 0.702437] [G loss: 0.683274]\n",
      "[Epoch 49/200] [Batch 3/6] [D loss: 0.680518] [G loss: 0.680867]\n",
      "[Epoch 49/200] [Batch 4/6] [D loss: 0.695983] [G loss: 0.688377]\n",
      "[Epoch 49/200] [Batch 5/6] [D loss: 0.688429] [G loss: 0.691882]\n",
      "[Epoch 50/200] [Batch 0/6] [D loss: 0.708993] [G loss: 0.684234]\n",
      "[Epoch 50/200] [Batch 1/6] [D loss: 0.690128] [G loss: 0.707515]\n",
      "[Epoch 50/200] [Batch 2/6] [D loss: 0.710914] [G loss: 0.700046]\n",
      "[Epoch 50/200] [Batch 3/6] [D loss: 0.700900] [G loss: 0.703017]\n",
      "[Epoch 50/200] [Batch 4/6] [D loss: 0.708029] [G loss: 0.712227]\n",
      "[Epoch 50/200] [Batch 5/6] [D loss: 0.685964] [G loss: 0.691232]\n",
      "[Epoch 51/200] [Batch 0/6] [D loss: 0.700701] [G loss: 0.697740]\n",
      "[Epoch 51/200] [Batch 1/6] [D loss: 0.687449] [G loss: 0.701916]\n",
      "[Epoch 51/200] [Batch 2/6] [D loss: 0.703832] [G loss: 0.685489]\n",
      "[Epoch 51/200] [Batch 3/6] [D loss: 0.699395] [G loss: 0.694581]\n",
      "[Epoch 51/200] [Batch 4/6] [D loss: 0.691252] [G loss: 0.690643]\n",
      "[Epoch 51/200] [Batch 5/6] [D loss: 0.707609] [G loss: 0.688902]\n",
      "[Epoch 52/200] [Batch 0/6] [D loss: 0.689700] [G loss: 0.690745]\n",
      "[Epoch 52/200] [Batch 1/6] [D loss: 0.691218] [G loss: 0.669093]\n",
      "[Epoch 52/200] [Batch 2/6] [D loss: 0.703042] [G loss: 0.673025]\n",
      "[Epoch 52/200] [Batch 3/6] [D loss: 0.698105] [G loss: 0.697695]\n",
      "[Epoch 52/200] [Batch 4/6] [D loss: 0.698604] [G loss: 0.701512]\n",
      "[Epoch 52/200] [Batch 5/6] [D loss: 0.696632] [G loss: 0.704714]\n",
      "[Epoch 53/200] [Batch 0/6] [D loss: 0.699870] [G loss: 0.688671]\n",
      "[Epoch 53/200] [Batch 1/6] [D loss: 0.696732] [G loss: 0.704192]\n",
      "[Epoch 53/200] [Batch 2/6] [D loss: 0.688158] [G loss: 0.694372]\n",
      "[Epoch 53/200] [Batch 3/6] [D loss: 0.687876] [G loss: 0.703420]\n",
      "[Epoch 53/200] [Batch 4/6] [D loss: 0.699006] [G loss: 0.684598]\n",
      "[Epoch 53/200] [Batch 5/6] [D loss: 0.692673] [G loss: 0.689573]\n",
      "[Epoch 54/200] [Batch 0/6] [D loss: 0.690885] [G loss: 0.704557]\n",
      "[Epoch 54/200] [Batch 1/6] [D loss: 0.704751] [G loss: 0.707358]\n",
      "[Epoch 54/200] [Batch 2/6] [D loss: 0.693823] [G loss: 0.696825]\n",
      "[Epoch 54/200] [Batch 3/6] [D loss: 0.691999] [G loss: 0.691895]\n",
      "[Epoch 54/200] [Batch 4/6] [D loss: 0.708312] [G loss: 0.674819]\n",
      "[Epoch 54/200] [Batch 5/6] [D loss: 0.691708] [G loss: 0.692024]\n",
      "[Epoch 55/200] [Batch 0/6] [D loss: 0.692597] [G loss: 0.689266]\n",
      "[Epoch 55/200] [Batch 1/6] [D loss: 0.690120] [G loss: 0.704236]\n",
      "[Epoch 55/200] [Batch 2/6] [D loss: 0.696188] [G loss: 0.675309]\n",
      "[Epoch 55/200] [Batch 3/6] [D loss: 0.692204] [G loss: 0.693004]\n",
      "[Epoch 55/200] [Batch 4/6] [D loss: 0.691637] [G loss: 0.705521]\n",
      "[Epoch 55/200] [Batch 5/6] [D loss: 0.692446] [G loss: 0.717148]\n",
      "[Epoch 56/200] [Batch 0/6] [D loss: 0.680992] [G loss: 0.704072]\n",
      "[Epoch 56/200] [Batch 1/6] [D loss: 0.682513] [G loss: 0.701870]\n",
      "[Epoch 56/200] [Batch 2/6] [D loss: 0.687019] [G loss: 0.701275]\n",
      "[Epoch 56/200] [Batch 3/6] [D loss: 0.696223] [G loss: 0.700251]\n",
      "[Epoch 56/200] [Batch 4/6] [D loss: 0.689304] [G loss: 0.695053]\n",
      "[Epoch 56/200] [Batch 5/6] [D loss: 0.686280] [G loss: 0.703568]\n",
      "[Epoch 57/200] [Batch 0/6] [D loss: 0.690105] [G loss: 0.710716]\n",
      "[Epoch 57/200] [Batch 1/6] [D loss: 0.687417] [G loss: 0.689733]\n",
      "[Epoch 57/200] [Batch 2/6] [D loss: 0.677117] [G loss: 0.720304]\n",
      "[Epoch 57/200] [Batch 3/6] [D loss: 0.685071] [G loss: 0.705640]\n",
      "[Epoch 57/200] [Batch 4/6] [D loss: 0.684954] [G loss: 0.701844]\n",
      "[Epoch 57/200] [Batch 5/6] [D loss: 0.702295] [G loss: 0.676424]\n",
      "[Epoch 58/200] [Batch 0/6] [D loss: 0.693891] [G loss: 0.681943]\n",
      "[Epoch 58/200] [Batch 1/6] [D loss: 0.707331] [G loss: 0.676257]\n",
      "[Epoch 58/200] [Batch 2/6] [D loss: 0.695277] [G loss: 0.676215]\n",
      "[Epoch 58/200] [Batch 3/6] [D loss: 0.712449] [G loss: 0.662008]\n",
      "[Epoch 58/200] [Batch 4/6] [D loss: 0.715820] [G loss: 0.684042]\n",
      "[Epoch 58/200] [Batch 5/6] [D loss: 0.695421] [G loss: 0.685097]\n",
      "[Epoch 59/200] [Batch 0/6] [D loss: 0.701826] [G loss: 0.702307]\n",
      "[Epoch 59/200] [Batch 1/6] [D loss: 0.702695] [G loss: 0.694916]\n",
      "[Epoch 59/200] [Batch 2/6] [D loss: 0.692677] [G loss: 0.686796]\n",
      "[Epoch 59/200] [Batch 3/6] [D loss: 0.694300] [G loss: 0.676697]\n",
      "[Epoch 59/200] [Batch 4/6] [D loss: 0.689759] [G loss: 0.682633]\n",
      "[Epoch 59/200] [Batch 5/6] [D loss: 0.688836] [G loss: 0.695883]\n",
      "[Epoch 60/200] [Batch 0/6] [D loss: 0.702270] [G loss: 0.697132]\n",
      "[Epoch 60/200] [Batch 1/6] [D loss: 0.686680] [G loss: 0.696920]\n",
      "[Epoch 60/200] [Batch 2/6] [D loss: 0.690895] [G loss: 0.696615]\n",
      "[Epoch 60/200] [Batch 3/6] [D loss: 0.694285] [G loss: 0.699505]\n",
      "[Epoch 60/200] [Batch 4/6] [D loss: 0.680205] [G loss: 0.698526]\n",
      "[Epoch 60/200] [Batch 5/6] [D loss: 0.689993] [G loss: 0.692403]\n",
      "[Epoch 61/200] [Batch 0/6] [D loss: 0.695811] [G loss: 0.699127]\n",
      "[Epoch 61/200] [Batch 1/6] [D loss: 0.696279] [G loss: 0.707292]\n",
      "[Epoch 61/200] [Batch 2/6] [D loss: 0.695920] [G loss: 0.707548]\n",
      "[Epoch 61/200] [Batch 3/6] [D loss: 0.691759] [G loss: 0.712849]\n",
      "[Epoch 61/200] [Batch 4/6] [D loss: 0.691640] [G loss: 0.718900]\n",
      "[Epoch 61/200] [Batch 5/6] [D loss: 0.706756] [G loss: 0.702482]\n",
      "[Epoch 62/200] [Batch 0/6] [D loss: 0.704121] [G loss: 0.700707]\n",
      "[Epoch 62/200] [Batch 1/6] [D loss: 0.692471] [G loss: 0.703313]\n",
      "[Epoch 62/200] [Batch 2/6] [D loss: 0.703478] [G loss: 0.699636]\n",
      "[Epoch 62/200] [Batch 3/6] [D loss: 0.707250] [G loss: 0.682948]\n",
      "[Epoch 62/200] [Batch 4/6] [D loss: 0.707375] [G loss: 0.694035]\n",
      "[Epoch 62/200] [Batch 5/6] [D loss: 0.700864] [G loss: 0.712427]\n",
      "[Epoch 63/200] [Batch 0/6] [D loss: 0.706007] [G loss: 0.698407]\n",
      "[Epoch 63/200] [Batch 1/6] [D loss: 0.699748] [G loss: 0.714160]\n",
      "[Epoch 63/200] [Batch 2/6] [D loss: 0.691028] [G loss: 0.706212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 63/200] [Batch 3/6] [D loss: 0.699474] [G loss: 0.715899]\n",
      "[Epoch 63/200] [Batch 4/6] [D loss: 0.697720] [G loss: 0.718283]\n",
      "[Epoch 63/200] [Batch 5/6] [D loss: 0.692012] [G loss: 0.711821]\n",
      "[Epoch 64/200] [Batch 0/6] [D loss: 0.689568] [G loss: 0.711664]\n",
      "[Epoch 64/200] [Batch 1/6] [D loss: 0.686847] [G loss: 0.703362]\n",
      "[Epoch 64/200] [Batch 2/6] [D loss: 0.688535] [G loss: 0.698752]\n",
      "[Epoch 64/200] [Batch 3/6] [D loss: 0.692824] [G loss: 0.696378]\n",
      "[Epoch 64/200] [Batch 4/6] [D loss: 0.687072] [G loss: 0.701597]\n",
      "[Epoch 64/200] [Batch 5/6] [D loss: 0.689062] [G loss: 0.684824]\n",
      "[Epoch 65/200] [Batch 0/6] [D loss: 0.696504] [G loss: 0.689146]\n",
      "[Epoch 65/200] [Batch 1/6] [D loss: 0.691750] [G loss: 0.692474]\n",
      "[Epoch 65/200] [Batch 2/6] [D loss: 0.694195] [G loss: 0.693440]\n",
      "[Epoch 65/200] [Batch 3/6] [D loss: 0.694324] [G loss: 0.683501]\n",
      "[Epoch 65/200] [Batch 4/6] [D loss: 0.696495] [G loss: 0.690264]\n",
      "[Epoch 65/200] [Batch 5/6] [D loss: 0.700037] [G loss: 0.682920]\n",
      "[Epoch 66/200] [Batch 0/6] [D loss: 0.693822] [G loss: 0.677286]\n",
      "[Epoch 66/200] [Batch 1/6] [D loss: 0.688195] [G loss: 0.689353]\n",
      "[Epoch 66/200] [Batch 2/6] [D loss: 0.696658] [G loss: 0.679266]\n",
      "[Epoch 66/200] [Batch 3/6] [D loss: 0.695237] [G loss: 0.690742]\n",
      "[Epoch 66/200] [Batch 4/6] [D loss: 0.701006] [G loss: 0.684020]\n",
      "[Epoch 66/200] [Batch 5/6] [D loss: 0.702124] [G loss: 0.683534]\n",
      "[Epoch 67/200] [Batch 0/6] [D loss: 0.699627] [G loss: 0.687090]\n",
      "[Epoch 67/200] [Batch 1/6] [D loss: 0.694696] [G loss: 0.686785]\n",
      "[Epoch 67/200] [Batch 2/6] [D loss: 0.686367] [G loss: 0.690183]\n",
      "[Epoch 67/200] [Batch 3/6] [D loss: 0.704116] [G loss: 0.683111]\n",
      "[Epoch 67/200] [Batch 4/6] [D loss: 0.697758] [G loss: 0.704861]\n",
      "[Epoch 67/200] [Batch 5/6] [D loss: 0.697590] [G loss: 0.694664]\n",
      "[Epoch 68/200] [Batch 0/6] [D loss: 0.696575] [G loss: 0.703122]\n",
      "[Epoch 68/200] [Batch 1/6] [D loss: 0.690243] [G loss: 0.697441]\n",
      "[Epoch 68/200] [Batch 2/6] [D loss: 0.688449] [G loss: 0.708783]\n",
      "[Epoch 68/200] [Batch 3/6] [D loss: 0.684290] [G loss: 0.706147]\n",
      "[Epoch 68/200] [Batch 4/6] [D loss: 0.688146] [G loss: 0.690752]\n",
      "[Epoch 68/200] [Batch 5/6] [D loss: 0.689787] [G loss: 0.694310]\n",
      "[Epoch 69/200] [Batch 0/6] [D loss: 0.688530] [G loss: 0.692252]\n",
      "[Epoch 69/200] [Batch 1/6] [D loss: 0.695319] [G loss: 0.693175]\n",
      "[Epoch 69/200] [Batch 2/6] [D loss: 0.687430] [G loss: 0.684467]\n",
      "[Epoch 69/200] [Batch 3/6] [D loss: 0.691870] [G loss: 0.689369]\n",
      "[Epoch 69/200] [Batch 4/6] [D loss: 0.690418] [G loss: 0.691060]\n",
      "[Epoch 69/200] [Batch 5/6] [D loss: 0.692172] [G loss: 0.696331]\n",
      "[Epoch 70/200] [Batch 0/6] [D loss: 0.694547] [G loss: 0.700367]\n",
      "[Epoch 70/200] [Batch 1/6] [D loss: 0.696002] [G loss: 0.687341]\n",
      "[Epoch 70/200] [Batch 2/6] [D loss: 0.692715] [G loss: 0.696256]\n",
      "[Epoch 70/200] [Batch 3/6] [D loss: 0.698215] [G loss: 0.693008]\n",
      "[Epoch 70/200] [Batch 4/6] [D loss: 0.700448] [G loss: 0.691159]\n",
      "[Epoch 70/200] [Batch 5/6] [D loss: 0.692333] [G loss: 0.700186]\n",
      "[Epoch 71/200] [Batch 0/6] [D loss: 0.694351] [G loss: 0.694166]\n",
      "[Epoch 71/200] [Batch 1/6] [D loss: 0.702139] [G loss: 0.704525]\n",
      "[Epoch 71/200] [Batch 2/6] [D loss: 0.690475] [G loss: 0.707649]\n",
      "[Epoch 71/200] [Batch 3/6] [D loss: 0.689341] [G loss: 0.698744]\n",
      "[Epoch 71/200] [Batch 4/6] [D loss: 0.695211] [G loss: 0.705244]\n",
      "[Epoch 71/200] [Batch 5/6] [D loss: 0.691514] [G loss: 0.702546]\n",
      "[Epoch 72/200] [Batch 0/6] [D loss: 0.691685] [G loss: 0.707561]\n",
      "[Epoch 72/200] [Batch 1/6] [D loss: 0.689822] [G loss: 0.706605]\n",
      "[Epoch 72/200] [Batch 2/6] [D loss: 0.687690] [G loss: 0.702747]\n",
      "[Epoch 72/200] [Batch 3/6] [D loss: 0.690865] [G loss: 0.700509]\n",
      "[Epoch 72/200] [Batch 4/6] [D loss: 0.697120] [G loss: 0.708716]\n",
      "[Epoch 72/200] [Batch 5/6] [D loss: 0.694771] [G loss: 0.706797]\n",
      "[Epoch 73/200] [Batch 0/6] [D loss: 0.701525] [G loss: 0.697175]\n",
      "[Epoch 73/200] [Batch 1/6] [D loss: 0.694510] [G loss: 0.705284]\n",
      "[Epoch 73/200] [Batch 2/6] [D loss: 0.694447] [G loss: 0.693960]\n",
      "[Epoch 73/200] [Batch 3/6] [D loss: 0.695902] [G loss: 0.690472]\n",
      "[Epoch 73/200] [Batch 4/6] [D loss: 0.693983] [G loss: 0.685126]\n",
      "[Epoch 73/200] [Batch 5/6] [D loss: 0.697640] [G loss: 0.690567]\n",
      "[Epoch 74/200] [Batch 0/6] [D loss: 0.696202] [G loss: 0.683438]\n",
      "[Epoch 74/200] [Batch 1/6] [D loss: 0.695754] [G loss: 0.684701]\n",
      "[Epoch 74/200] [Batch 2/6] [D loss: 0.701195] [G loss: 0.681889]\n",
      "[Epoch 74/200] [Batch 3/6] [D loss: 0.698438] [G loss: 0.684569]\n",
      "[Epoch 74/200] [Batch 4/6] [D loss: 0.697081] [G loss: 0.688818]\n",
      "[Epoch 74/200] [Batch 5/6] [D loss: 0.695900] [G loss: 0.692124]\n",
      "[Epoch 75/200] [Batch 0/6] [D loss: 0.695994] [G loss: 0.693566]\n",
      "[Epoch 75/200] [Batch 1/6] [D loss: 0.695968] [G loss: 0.696791]\n",
      "[Epoch 75/200] [Batch 2/6] [D loss: 0.697431] [G loss: 0.694487]\n",
      "[Epoch 75/200] [Batch 3/6] [D loss: 0.697343] [G loss: 0.684744]\n",
      "[Epoch 75/200] [Batch 4/6] [D loss: 0.691088] [G loss: 0.703704]\n",
      "[Epoch 75/200] [Batch 5/6] [D loss: 0.691623] [G loss: 0.699936]\n",
      "[Epoch 76/200] [Batch 0/6] [D loss: 0.696204] [G loss: 0.699295]\n",
      "[Epoch 76/200] [Batch 1/6] [D loss: 0.689445] [G loss: 0.694147]\n",
      "[Epoch 76/200] [Batch 2/6] [D loss: 0.695263] [G loss: 0.699342]\n",
      "[Epoch 76/200] [Batch 3/6] [D loss: 0.690387] [G loss: 0.690550]\n",
      "[Epoch 76/200] [Batch 4/6] [D loss: 0.691288] [G loss: 0.687547]\n",
      "[Epoch 76/200] [Batch 5/6] [D loss: 0.694357] [G loss: 0.692879]\n",
      "[Epoch 77/200] [Batch 0/6] [D loss: 0.699352] [G loss: 0.691760]\n",
      "[Epoch 77/200] [Batch 1/6] [D loss: 0.691239] [G loss: 0.698877]\n",
      "[Epoch 77/200] [Batch 2/6] [D loss: 0.693976] [G loss: 0.690678]\n",
      "[Epoch 77/200] [Batch 3/6] [D loss: 0.693763] [G loss: 0.687367]\n",
      "[Epoch 77/200] [Batch 4/6] [D loss: 0.687258] [G loss: 0.696196]\n",
      "[Epoch 77/200] [Batch 5/6] [D loss: 0.697264] [G loss: 0.692352]\n",
      "[Epoch 78/200] [Batch 0/6] [D loss: 0.695997] [G loss: 0.684762]\n",
      "[Epoch 78/200] [Batch 1/6] [D loss: 0.691297] [G loss: 0.693586]\n",
      "[Epoch 78/200] [Batch 2/6] [D loss: 0.699228] [G loss: 0.681531]\n",
      "[Epoch 78/200] [Batch 3/6] [D loss: 0.695953] [G loss: 0.681080]\n",
      "[Epoch 78/200] [Batch 4/6] [D loss: 0.701041] [G loss: 0.691543]\n",
      "[Epoch 78/200] [Batch 5/6] [D loss: 0.696474] [G loss: 0.683461]\n",
      "[Epoch 79/200] [Batch 0/6] [D loss: 0.693918] [G loss: 0.688150]\n",
      "[Epoch 79/200] [Batch 1/6] [D loss: 0.697916] [G loss: 0.695308]\n",
      "[Epoch 79/200] [Batch 2/6] [D loss: 0.695029] [G loss: 0.684984]\n",
      "[Epoch 79/200] [Batch 3/6] [D loss: 0.695414] [G loss: 0.697161]\n",
      "[Epoch 79/200] [Batch 4/6] [D loss: 0.693487] [G loss: 0.697617]\n",
      "[Epoch 79/200] [Batch 5/6] [D loss: 0.700729] [G loss: 0.694250]\n",
      "[Epoch 80/200] [Batch 0/6] [D loss: 0.696566] [G loss: 0.695390]\n",
      "[Epoch 80/200] [Batch 1/6] [D loss: 0.695652] [G loss: 0.694531]\n",
      "[Epoch 80/200] [Batch 2/6] [D loss: 0.691630] [G loss: 0.688580]\n",
      "[Epoch 80/200] [Batch 3/6] [D loss: 0.697231] [G loss: 0.694256]\n",
      "[Epoch 80/200] [Batch 4/6] [D loss: 0.693470] [G loss: 0.693924]\n",
      "[Epoch 80/200] [Batch 5/6] [D loss: 0.690749] [G loss: 0.692037]\n",
      "[Epoch 81/200] [Batch 0/6] [D loss: 0.696771] [G loss: 0.687092]\n",
      "[Epoch 81/200] [Batch 1/6] [D loss: 0.691525] [G loss: 0.692308]\n",
      "[Epoch 81/200] [Batch 2/6] [D loss: 0.696870] [G loss: 0.699149]\n",
      "[Epoch 81/200] [Batch 3/6] [D loss: 0.693263] [G loss: 0.696548]\n",
      "[Epoch 81/200] [Batch 4/6] [D loss: 0.693068] [G loss: 0.688493]\n",
      "[Epoch 81/200] [Batch 5/6] [D loss: 0.693312] [G loss: 0.686726]\n",
      "[Epoch 82/200] [Batch 0/6] [D loss: 0.694062] [G loss: 0.690879]\n",
      "[Epoch 82/200] [Batch 1/6] [D loss: 0.690551] [G loss: 0.694033]\n",
      "[Epoch 82/200] [Batch 2/6] [D loss: 0.688217] [G loss: 0.690892]\n",
      "[Epoch 82/200] [Batch 3/6] [D loss: 0.694943] [G loss: 0.695103]\n",
      "[Epoch 82/200] [Batch 4/6] [D loss: 0.699300] [G loss: 0.688898]\n",
      "[Epoch 82/200] [Batch 5/6] [D loss: 0.697145] [G loss: 0.697076]\n",
      "[Epoch 83/200] [Batch 0/6] [D loss: 0.694811] [G loss: 0.696808]\n",
      "[Epoch 83/200] [Batch 1/6] [D loss: 0.694356] [G loss: 0.698507]\n",
      "[Epoch 83/200] [Batch 2/6] [D loss: 0.693110] [G loss: 0.684278]\n",
      "[Epoch 83/200] [Batch 3/6] [D loss: 0.694276] [G loss: 0.694375]\n",
      "[Epoch 83/200] [Batch 4/6] [D loss: 0.697842] [G loss: 0.686876]\n",
      "[Epoch 83/200] [Batch 5/6] [D loss: 0.693869] [G loss: 0.689220]\n",
      "[Epoch 84/200] [Batch 0/6] [D loss: 0.697408] [G loss: 0.691099]\n",
      "[Epoch 84/200] [Batch 1/6] [D loss: 0.696073] [G loss: 0.699148]\n",
      "[Epoch 84/200] [Batch 2/6] [D loss: 0.692601] [G loss: 0.699421]\n",
      "[Epoch 84/200] [Batch 3/6] [D loss: 0.696598] [G loss: 0.701242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 84/200] [Batch 4/6] [D loss: 0.692273] [G loss: 0.689792]\n",
      "[Epoch 84/200] [Batch 5/6] [D loss: 0.696289] [G loss: 0.693777]\n",
      "[Epoch 85/200] [Batch 0/6] [D loss: 0.691800] [G loss: 0.695257]\n",
      "[Epoch 85/200] [Batch 1/6] [D loss: 0.689656] [G loss: 0.693422]\n",
      "[Epoch 85/200] [Batch 2/6] [D loss: 0.694554] [G loss: 0.688672]\n",
      "[Epoch 85/200] [Batch 3/6] [D loss: 0.692365] [G loss: 0.692883]\n",
      "[Epoch 85/200] [Batch 4/6] [D loss: 0.690809] [G loss: 0.692525]\n",
      "[Epoch 85/200] [Batch 5/6] [D loss: 0.690203] [G loss: 0.682778]\n",
      "[Epoch 86/200] [Batch 0/6] [D loss: 0.692091] [G loss: 0.695071]\n",
      "[Epoch 86/200] [Batch 1/6] [D loss: 0.697698] [G loss: 0.690735]\n",
      "[Epoch 86/200] [Batch 2/6] [D loss: 0.694023] [G loss: 0.692892]\n",
      "[Epoch 86/200] [Batch 3/6] [D loss: 0.694207] [G loss: 0.686378]\n",
      "[Epoch 86/200] [Batch 4/6] [D loss: 0.693411] [G loss: 0.683194]\n",
      "[Epoch 86/200] [Batch 5/6] [D loss: 0.685853] [G loss: 0.695348]\n",
      "[Epoch 87/200] [Batch 0/6] [D loss: 0.690628] [G loss: 0.687362]\n",
      "[Epoch 87/200] [Batch 1/6] [D loss: 0.693995] [G loss: 0.692413]\n",
      "[Epoch 87/200] [Batch 2/6] [D loss: 0.692937] [G loss: 0.692344]\n",
      "[Epoch 87/200] [Batch 3/6] [D loss: 0.695173] [G loss: 0.689573]\n",
      "[Epoch 87/200] [Batch 4/6] [D loss: 0.689324] [G loss: 0.700661]\n",
      "[Epoch 87/200] [Batch 5/6] [D loss: 0.698426] [G loss: 0.695356]\n",
      "[Epoch 88/200] [Batch 0/6] [D loss: 0.701870] [G loss: 0.700292]\n",
      "[Epoch 88/200] [Batch 1/6] [D loss: 0.686484] [G loss: 0.707133]\n",
      "[Epoch 88/200] [Batch 2/6] [D loss: 0.689039] [G loss: 0.700417]\n",
      "[Epoch 88/200] [Batch 3/6] [D loss: 0.692518] [G loss: 0.701349]\n",
      "[Epoch 88/200] [Batch 4/6] [D loss: 0.693798] [G loss: 0.706355]\n",
      "[Epoch 88/200] [Batch 5/6] [D loss: 0.700090] [G loss: 0.696042]\n",
      "[Epoch 89/200] [Batch 0/6] [D loss: 0.689463] [G loss: 0.704124]\n",
      "[Epoch 89/200] [Batch 1/6] [D loss: 0.687011] [G loss: 0.691799]\n",
      "[Epoch 89/200] [Batch 2/6] [D loss: 0.693701] [G loss: 0.688869]\n",
      "[Epoch 89/200] [Batch 3/6] [D loss: 0.698956] [G loss: 0.684342]\n",
      "[Epoch 89/200] [Batch 4/6] [D loss: 0.694615] [G loss: 0.695537]\n",
      "[Epoch 89/200] [Batch 5/6] [D loss: 0.691138] [G loss: 0.693161]\n",
      "[Epoch 90/200] [Batch 0/6] [D loss: 0.695363] [G loss: 0.692148]\n",
      "[Epoch 90/200] [Batch 1/6] [D loss: 0.693601] [G loss: 0.688127]\n",
      "[Epoch 90/200] [Batch 2/6] [D loss: 0.696944] [G loss: 0.689694]\n",
      "[Epoch 90/200] [Batch 3/6] [D loss: 0.698065] [G loss: 0.690659]\n",
      "[Epoch 90/200] [Batch 4/6] [D loss: 0.693679] [G loss: 0.690009]\n",
      "[Epoch 90/200] [Batch 5/6] [D loss: 0.694279] [G loss: 0.693050]\n",
      "[Epoch 91/200] [Batch 0/6] [D loss: 0.689830] [G loss: 0.695393]\n",
      "[Epoch 91/200] [Batch 1/6] [D loss: 0.687946] [G loss: 0.696327]\n",
      "[Epoch 91/200] [Batch 2/6] [D loss: 0.694696] [G loss: 0.694705]\n",
      "[Epoch 91/200] [Batch 3/6] [D loss: 0.691276] [G loss: 0.698125]\n",
      "[Epoch 91/200] [Batch 4/6] [D loss: 0.693597] [G loss: 0.699672]\n",
      "[Epoch 91/200] [Batch 5/6] [D loss: 0.697113] [G loss: 0.686611]\n",
      "[Epoch 92/200] [Batch 0/6] [D loss: 0.689460] [G loss: 0.687131]\n",
      "[Epoch 92/200] [Batch 1/6] [D loss: 0.694739] [G loss: 0.694337]\n",
      "[Epoch 92/200] [Batch 2/6] [D loss: 0.696890] [G loss: 0.700761]\n",
      "[Epoch 92/200] [Batch 3/6] [D loss: 0.693436] [G loss: 0.703460]\n",
      "[Epoch 92/200] [Batch 4/6] [D loss: 0.690832] [G loss: 0.694905]\n",
      "[Epoch 92/200] [Batch 5/6] [D loss: 0.688859] [G loss: 0.695995]\n",
      "[Epoch 93/200] [Batch 0/6] [D loss: 0.682351] [G loss: 0.693808]\n",
      "[Epoch 93/200] [Batch 1/6] [D loss: 0.690479] [G loss: 0.693711]\n",
      "[Epoch 93/200] [Batch 2/6] [D loss: 0.694953] [G loss: 0.684630]\n",
      "[Epoch 93/200] [Batch 3/6] [D loss: 0.687896] [G loss: 0.692208]\n",
      "[Epoch 93/200] [Batch 4/6] [D loss: 0.689698] [G loss: 0.695753]\n",
      "[Epoch 93/200] [Batch 5/6] [D loss: 0.685683] [G loss: 0.692296]\n",
      "[Epoch 94/200] [Batch 0/6] [D loss: 0.695933] [G loss: 0.690401]\n",
      "[Epoch 94/200] [Batch 1/6] [D loss: 0.693238] [G loss: 0.684379]\n",
      "[Epoch 94/200] [Batch 2/6] [D loss: 0.697179] [G loss: 0.697670]\n",
      "[Epoch 94/200] [Batch 3/6] [D loss: 0.691828] [G loss: 0.699557]\n",
      "[Epoch 94/200] [Batch 4/6] [D loss: 0.693394] [G loss: 0.699021]\n",
      "[Epoch 94/200] [Batch 5/6] [D loss: 0.699438] [G loss: 0.694948]\n",
      "[Epoch 95/200] [Batch 0/6] [D loss: 0.691043] [G loss: 0.694563]\n",
      "[Epoch 95/200] [Batch 1/6] [D loss: 0.697125] [G loss: 0.695773]\n",
      "[Epoch 95/200] [Batch 2/6] [D loss: 0.687474] [G loss: 0.696356]\n",
      "[Epoch 95/200] [Batch 3/6] [D loss: 0.690920] [G loss: 0.703043]\n",
      "[Epoch 95/200] [Batch 4/6] [D loss: 0.693939] [G loss: 0.697771]\n",
      "[Epoch 95/200] [Batch 5/6] [D loss: 0.691496] [G loss: 0.694794]\n",
      "[Epoch 96/200] [Batch 0/6] [D loss: 0.694802] [G loss: 0.688939]\n",
      "[Epoch 96/200] [Batch 1/6] [D loss: 0.693070] [G loss: 0.695243]\n",
      "[Epoch 96/200] [Batch 2/6] [D loss: 0.689505] [G loss: 0.693206]\n",
      "[Epoch 96/200] [Batch 3/6] [D loss: 0.692732] [G loss: 0.695245]\n",
      "[Epoch 96/200] [Batch 4/6] [D loss: 0.685363] [G loss: 0.696116]\n",
      "[Epoch 96/200] [Batch 5/6] [D loss: 0.702081] [G loss: 0.687403]\n",
      "[Epoch 97/200] [Batch 0/6] [D loss: 0.698738] [G loss: 0.694823]\n",
      "[Epoch 97/200] [Batch 1/6] [D loss: 0.694670] [G loss: 0.692029]\n",
      "[Epoch 97/200] [Batch 2/6] [D loss: 0.691036] [G loss: 0.693987]\n",
      "[Epoch 97/200] [Batch 3/6] [D loss: 0.693100] [G loss: 0.701251]\n",
      "[Epoch 97/200] [Batch 4/6] [D loss: 0.691991] [G loss: 0.686786]\n",
      "[Epoch 97/200] [Batch 5/6] [D loss: 0.695444] [G loss: 0.693617]\n",
      "[Epoch 98/200] [Batch 0/6] [D loss: 0.701841] [G loss: 0.700689]\n",
      "[Epoch 98/200] [Batch 1/6] [D loss: 0.689692] [G loss: 0.699130]\n",
      "[Epoch 98/200] [Batch 2/6] [D loss: 0.694768] [G loss: 0.696535]\n",
      "[Epoch 98/200] [Batch 3/6] [D loss: 0.689745] [G loss: 0.694018]\n",
      "[Epoch 98/200] [Batch 4/6] [D loss: 0.692736] [G loss: 0.706150]\n",
      "[Epoch 98/200] [Batch 5/6] [D loss: 0.690333] [G loss: 0.700783]\n",
      "[Epoch 99/200] [Batch 0/6] [D loss: 0.686847] [G loss: 0.691444]\n",
      "[Epoch 99/200] [Batch 1/6] [D loss: 0.690799] [G loss: 0.696643]\n",
      "[Epoch 99/200] [Batch 2/6] [D loss: 0.688815] [G loss: 0.698688]\n",
      "[Epoch 99/200] [Batch 3/6] [D loss: 0.682314] [G loss: 0.706346]\n",
      "[Epoch 99/200] [Batch 4/6] [D loss: 0.682299] [G loss: 0.707196]\n",
      "[Epoch 99/200] [Batch 5/6] [D loss: 0.690480] [G loss: 0.701116]\n",
      "[Epoch 100/200] [Batch 0/6] [D loss: 0.687889] [G loss: 0.694792]\n",
      "[Epoch 100/200] [Batch 1/6] [D loss: 0.683650] [G loss: 0.700038]\n",
      "[Epoch 100/200] [Batch 2/6] [D loss: 0.690830] [G loss: 0.702914]\n",
      "[Epoch 100/200] [Batch 3/6] [D loss: 0.677328] [G loss: 0.697543]\n",
      "[Epoch 100/200] [Batch 4/6] [D loss: 0.693521] [G loss: 0.692801]\n",
      "[Epoch 100/200] [Batch 5/6] [D loss: 0.688344] [G loss: 0.689356]\n",
      "[Epoch 101/200] [Batch 0/6] [D loss: 0.687432] [G loss: 0.678477]\n",
      "[Epoch 101/200] [Batch 1/6] [D loss: 0.700878] [G loss: 0.647566]\n",
      "[Epoch 101/200] [Batch 2/6] [D loss: 0.705577] [G loss: 0.654060]\n",
      "[Epoch 101/200] [Batch 3/6] [D loss: 0.719896] [G loss: 0.669508]\n",
      "[Epoch 101/200] [Batch 4/6] [D loss: 0.716343] [G loss: 0.648607]\n",
      "[Epoch 101/200] [Batch 5/6] [D loss: 0.713469] [G loss: 0.678387]\n",
      "[Epoch 102/200] [Batch 0/6] [D loss: 0.713469] [G loss: 0.680101]\n",
      "[Epoch 102/200] [Batch 1/6] [D loss: 0.705597] [G loss: 0.707617]\n",
      "[Epoch 102/200] [Batch 2/6] [D loss: 0.700303] [G loss: 0.703953]\n",
      "[Epoch 102/200] [Batch 3/6] [D loss: 0.694108] [G loss: 0.716178]\n",
      "[Epoch 102/200] [Batch 4/6] [D loss: 0.690799] [G loss: 0.709164]\n",
      "[Epoch 102/200] [Batch 5/6] [D loss: 0.701866] [G loss: 0.703302]\n",
      "[Epoch 103/200] [Batch 0/6] [D loss: 0.692439] [G loss: 0.700097]\n",
      "[Epoch 103/200] [Batch 1/6] [D loss: 0.687508] [G loss: 0.702355]\n",
      "[Epoch 103/200] [Batch 2/6] [D loss: 0.693339] [G loss: 0.707070]\n",
      "[Epoch 103/200] [Batch 3/6] [D loss: 0.690596] [G loss: 0.698927]\n",
      "[Epoch 103/200] [Batch 4/6] [D loss: 0.686991] [G loss: 0.704840]\n",
      "[Epoch 103/200] [Batch 5/6] [D loss: 0.687329] [G loss: 0.694041]\n",
      "[Epoch 104/200] [Batch 0/6] [D loss: 0.680745] [G loss: 0.701786]\n",
      "[Epoch 104/200] [Batch 1/6] [D loss: 0.686422] [G loss: 0.705346]\n",
      "[Epoch 104/200] [Batch 2/6] [D loss: 0.685933] [G loss: 0.708016]\n",
      "[Epoch 104/200] [Batch 3/6] [D loss: 0.681465] [G loss: 0.718062]\n",
      "[Epoch 104/200] [Batch 4/6] [D loss: 0.687644] [G loss: 0.714938]\n",
      "[Epoch 104/200] [Batch 5/6] [D loss: 0.689755] [G loss: 0.704607]\n",
      "[Epoch 105/200] [Batch 0/6] [D loss: 0.689304] [G loss: 0.705713]\n",
      "[Epoch 105/200] [Batch 1/6] [D loss: 0.692753] [G loss: 0.703533]\n",
      "[Epoch 105/200] [Batch 2/6] [D loss: 0.694529] [G loss: 0.689371]\n",
      "[Epoch 105/200] [Batch 3/6] [D loss: 0.699132] [G loss: 0.691466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 105/200] [Batch 4/6] [D loss: 0.700055] [G loss: 0.690871]\n",
      "[Epoch 105/200] [Batch 5/6] [D loss: 0.695119] [G loss: 0.692131]\n",
      "[Epoch 106/200] [Batch 0/6] [D loss: 0.699956] [G loss: 0.690910]\n",
      "[Epoch 106/200] [Batch 1/6] [D loss: 0.697867] [G loss: 0.690899]\n",
      "[Epoch 106/200] [Batch 2/6] [D loss: 0.696175] [G loss: 0.691235]\n",
      "[Epoch 106/200] [Batch 3/6] [D loss: 0.695573] [G loss: 0.693589]\n",
      "[Epoch 106/200] [Batch 4/6] [D loss: 0.700749] [G loss: 0.695839]\n",
      "[Epoch 106/200] [Batch 5/6] [D loss: 0.692638] [G loss: 0.692340]\n",
      "[Epoch 107/200] [Batch 0/6] [D loss: 0.694503] [G loss: 0.685727]\n",
      "[Epoch 107/200] [Batch 1/6] [D loss: 0.694282] [G loss: 0.694322]\n",
      "[Epoch 107/200] [Batch 2/6] [D loss: 0.694913] [G loss: 0.690547]\n",
      "[Epoch 107/200] [Batch 3/6] [D loss: 0.693541] [G loss: 0.688225]\n",
      "[Epoch 107/200] [Batch 4/6] [D loss: 0.690244] [G loss: 0.683562]\n",
      "[Epoch 107/200] [Batch 5/6] [D loss: 0.688061] [G loss: 0.691769]\n",
      "[Epoch 108/200] [Batch 0/6] [D loss: 0.690544] [G loss: 0.689416]\n",
      "[Epoch 108/200] [Batch 1/6] [D loss: 0.691522] [G loss: 0.682899]\n",
      "[Epoch 108/200] [Batch 2/6] [D loss: 0.686501] [G loss: 0.691031]\n",
      "[Epoch 108/200] [Batch 3/6] [D loss: 0.691726] [G loss: 0.680815]\n",
      "[Epoch 108/200] [Batch 4/6] [D loss: 0.681885] [G loss: 0.695631]\n",
      "[Epoch 108/200] [Batch 5/6] [D loss: 0.682520] [G loss: 0.689150]\n",
      "[Epoch 109/200] [Batch 0/6] [D loss: 0.683470] [G loss: 0.698163]\n",
      "[Epoch 109/200] [Batch 1/6] [D loss: 0.682313] [G loss: 0.698081]\n",
      "[Epoch 109/200] [Batch 2/6] [D loss: 0.684932] [G loss: 0.698474]\n",
      "[Epoch 109/200] [Batch 3/6] [D loss: 0.678012] [G loss: 0.690827]\n",
      "[Epoch 109/200] [Batch 4/6] [D loss: 0.673812] [G loss: 0.703275]\n",
      "[Epoch 109/200] [Batch 5/6] [D loss: 0.685031] [G loss: 0.693386]\n",
      "[Epoch 110/200] [Batch 0/6] [D loss: 0.675834] [G loss: 0.700192]\n",
      "[Epoch 110/200] [Batch 1/6] [D loss: 0.674723] [G loss: 0.693224]\n",
      "[Epoch 110/200] [Batch 2/6] [D loss: 0.680713] [G loss: 0.694698]\n",
      "[Epoch 110/200] [Batch 3/6] [D loss: 0.683300] [G loss: 0.667357]\n",
      "[Epoch 110/200] [Batch 4/6] [D loss: 0.692362] [G loss: 0.673408]\n",
      "[Epoch 110/200] [Batch 5/6] [D loss: 0.704791] [G loss: 0.671057]\n",
      "[Epoch 111/200] [Batch 0/6] [D loss: 0.701399] [G loss: 0.638932]\n",
      "[Epoch 111/200] [Batch 1/6] [D loss: 0.702052] [G loss: 0.658450]\n",
      "[Epoch 111/200] [Batch 2/6] [D loss: 0.727392] [G loss: 0.664521]\n",
      "[Epoch 111/200] [Batch 3/6] [D loss: 0.701991] [G loss: 0.708896]\n",
      "[Epoch 111/200] [Batch 4/6] [D loss: 0.704772] [G loss: 0.718109]\n",
      "[Epoch 111/200] [Batch 5/6] [D loss: 0.697508] [G loss: 0.731390]\n",
      "[Epoch 112/200] [Batch 0/6] [D loss: 0.692041] [G loss: 0.743639]\n",
      "[Epoch 112/200] [Batch 1/6] [D loss: 0.688267] [G loss: 0.738425]\n",
      "[Epoch 112/200] [Batch 2/6] [D loss: 0.690628] [G loss: 0.719731]\n",
      "[Epoch 112/200] [Batch 3/6] [D loss: 0.691895] [G loss: 0.717227]\n",
      "[Epoch 112/200] [Batch 4/6] [D loss: 0.688521] [G loss: 0.721538]\n",
      "[Epoch 112/200] [Batch 5/6] [D loss: 0.680760] [G loss: 0.714936]\n",
      "[Epoch 113/200] [Batch 0/6] [D loss: 0.694158] [G loss: 0.699052]\n",
      "[Epoch 113/200] [Batch 1/6] [D loss: 0.684572] [G loss: 0.703622]\n",
      "[Epoch 113/200] [Batch 2/6] [D loss: 0.686628] [G loss: 0.705215]\n",
      "[Epoch 113/200] [Batch 3/6] [D loss: 0.684801] [G loss: 0.709196]\n",
      "[Epoch 113/200] [Batch 4/6] [D loss: 0.684638] [G loss: 0.710036]\n",
      "[Epoch 113/200] [Batch 5/6] [D loss: 0.687491] [G loss: 0.705547]\n",
      "[Epoch 114/200] [Batch 0/6] [D loss: 0.686418] [G loss: 0.697575]\n",
      "[Epoch 114/200] [Batch 1/6] [D loss: 0.689157] [G loss: 0.705886]\n",
      "[Epoch 114/200] [Batch 2/6] [D loss: 0.692978] [G loss: 0.687470]\n",
      "[Epoch 114/200] [Batch 3/6] [D loss: 0.695539] [G loss: 0.678957]\n",
      "[Epoch 114/200] [Batch 4/6] [D loss: 0.704876] [G loss: 0.684419]\n",
      "[Epoch 114/200] [Batch 5/6] [D loss: 0.709891] [G loss: 0.667505]\n",
      "[Epoch 115/200] [Batch 0/6] [D loss: 0.706813] [G loss: 0.671559]\n",
      "[Epoch 115/200] [Batch 1/6] [D loss: 0.708778] [G loss: 0.679115]\n",
      "[Epoch 115/200] [Batch 2/6] [D loss: 0.704437] [G loss: 0.663835]\n",
      "[Epoch 115/200] [Batch 3/6] [D loss: 0.704899] [G loss: 0.691239]\n",
      "[Epoch 115/200] [Batch 4/6] [D loss: 0.699150] [G loss: 0.688246]\n",
      "[Epoch 115/200] [Batch 5/6] [D loss: 0.692779] [G loss: 0.697330]\n",
      "[Epoch 116/200] [Batch 0/6] [D loss: 0.693812] [G loss: 0.694506]\n",
      "[Epoch 116/200] [Batch 1/6] [D loss: 0.689708] [G loss: 0.700320]\n",
      "[Epoch 116/200] [Batch 2/6] [D loss: 0.690612] [G loss: 0.695499]\n",
      "[Epoch 116/200] [Batch 3/6] [D loss: 0.695166] [G loss: 0.698604]\n",
      "[Epoch 116/200] [Batch 4/6] [D loss: 0.684623] [G loss: 0.698089]\n",
      "[Epoch 116/200] [Batch 5/6] [D loss: 0.682273] [G loss: 0.694525]\n",
      "[Epoch 117/200] [Batch 0/6] [D loss: 0.691158] [G loss: 0.681968]\n",
      "[Epoch 117/200] [Batch 1/6] [D loss: 0.688524] [G loss: 0.696042]\n",
      "[Epoch 117/200] [Batch 2/6] [D loss: 0.688885] [G loss: 0.690529]\n",
      "[Epoch 117/200] [Batch 3/6] [D loss: 0.692859] [G loss: 0.687456]\n",
      "[Epoch 117/200] [Batch 4/6] [D loss: 0.685987] [G loss: 0.690583]\n",
      "[Epoch 117/200] [Batch 5/6] [D loss: 0.704520] [G loss: 0.681182]\n",
      "[Epoch 118/200] [Batch 0/6] [D loss: 0.691006] [G loss: 0.699805]\n",
      "[Epoch 118/200] [Batch 1/6] [D loss: 0.690049] [G loss: 0.701042]\n",
      "[Epoch 118/200] [Batch 2/6] [D loss: 0.696652] [G loss: 0.702275]\n",
      "[Epoch 118/200] [Batch 3/6] [D loss: 0.690906] [G loss: 0.703749]\n",
      "[Epoch 118/200] [Batch 4/6] [D loss: 0.690311] [G loss: 0.703249]\n",
      "[Epoch 118/200] [Batch 5/6] [D loss: 0.694417] [G loss: 0.695287]\n",
      "[Epoch 119/200] [Batch 0/6] [D loss: 0.693207] [G loss: 0.709454]\n",
      "[Epoch 119/200] [Batch 1/6] [D loss: 0.697706] [G loss: 0.698167]\n",
      "[Epoch 119/200] [Batch 2/6] [D loss: 0.690938] [G loss: 0.690958]\n",
      "[Epoch 119/200] [Batch 3/6] [D loss: 0.694470] [G loss: 0.704862]\n",
      "[Epoch 119/200] [Batch 4/6] [D loss: 0.694462] [G loss: 0.697242]\n",
      "[Epoch 119/200] [Batch 5/6] [D loss: 0.688321] [G loss: 0.706872]\n",
      "[Epoch 120/200] [Batch 0/6] [D loss: 0.696604] [G loss: 0.699747]\n",
      "[Epoch 120/200] [Batch 1/6] [D loss: 0.701677] [G loss: 0.692053]\n",
      "[Epoch 120/200] [Batch 2/6] [D loss: 0.694083] [G loss: 0.703372]\n",
      "[Epoch 120/200] [Batch 3/6] [D loss: 0.697849] [G loss: 0.707043]\n",
      "[Epoch 120/200] [Batch 4/6] [D loss: 0.691813] [G loss: 0.709594]\n",
      "[Epoch 120/200] [Batch 5/6] [D loss: 0.699257] [G loss: 0.707027]\n",
      "[Epoch 121/200] [Batch 0/6] [D loss: 0.691316] [G loss: 0.713401]\n",
      "[Epoch 121/200] [Batch 1/6] [D loss: 0.694471] [G loss: 0.711383]\n",
      "[Epoch 121/200] [Batch 2/6] [D loss: 0.688737] [G loss: 0.713074]\n",
      "[Epoch 121/200] [Batch 3/6] [D loss: 0.696010] [G loss: 0.701252]\n",
      "[Epoch 121/200] [Batch 4/6] [D loss: 0.694372] [G loss: 0.699205]\n",
      "[Epoch 121/200] [Batch 5/6] [D loss: 0.691986] [G loss: 0.699301]\n",
      "[Epoch 122/200] [Batch 0/6] [D loss: 0.698807] [G loss: 0.698031]\n",
      "[Epoch 122/200] [Batch 1/6] [D loss: 0.697960] [G loss: 0.686301]\n",
      "[Epoch 122/200] [Batch 2/6] [D loss: 0.692915] [G loss: 0.684505]\n",
      "[Epoch 122/200] [Batch 3/6] [D loss: 0.694045] [G loss: 0.691667]\n",
      "[Epoch 122/200] [Batch 4/6] [D loss: 0.696878] [G loss: 0.692086]\n",
      "[Epoch 122/200] [Batch 5/6] [D loss: 0.701816] [G loss: 0.684037]\n",
      "[Epoch 123/200] [Batch 0/6] [D loss: 0.695555] [G loss: 0.692061]\n",
      "[Epoch 123/200] [Batch 1/6] [D loss: 0.695488] [G loss: 0.683555]\n",
      "[Epoch 123/200] [Batch 2/6] [D loss: 0.694945] [G loss: 0.686566]\n",
      "[Epoch 123/200] [Batch 3/6] [D loss: 0.697194] [G loss: 0.691337]\n",
      "[Epoch 123/200] [Batch 4/6] [D loss: 0.691666] [G loss: 0.683297]\n",
      "[Epoch 123/200] [Batch 5/6] [D loss: 0.686824] [G loss: 0.699436]\n",
      "[Epoch 124/200] [Batch 0/6] [D loss: 0.697209] [G loss: 0.683532]\n",
      "[Epoch 124/200] [Batch 1/6] [D loss: 0.694920] [G loss: 0.684017]\n",
      "[Epoch 124/200] [Batch 2/6] [D loss: 0.692446] [G loss: 0.690479]\n",
      "[Epoch 124/200] [Batch 3/6] [D loss: 0.692399] [G loss: 0.689736]\n",
      "[Epoch 124/200] [Batch 4/6] [D loss: 0.692257] [G loss: 0.693841]\n",
      "[Epoch 124/200] [Batch 5/6] [D loss: 0.694602] [G loss: 0.687423]\n",
      "[Epoch 125/200] [Batch 0/6] [D loss: 0.695245] [G loss: 0.688646]\n",
      "[Epoch 125/200] [Batch 1/6] [D loss: 0.683702] [G loss: 0.690874]\n",
      "[Epoch 125/200] [Batch 2/6] [D loss: 0.694509] [G loss: 0.682873]\n",
      "[Epoch 125/200] [Batch 3/6] [D loss: 0.692478] [G loss: 0.682170]\n",
      "[Epoch 125/200] [Batch 4/6] [D loss: 0.689996] [G loss: 0.685463]\n",
      "[Epoch 125/200] [Batch 5/6] [D loss: 0.690549] [G loss: 0.683174]\n",
      "[Epoch 126/200] [Batch 0/6] [D loss: 0.696734] [G loss: 0.688653]\n",
      "[Epoch 126/200] [Batch 1/6] [D loss: 0.690167] [G loss: 0.685285]\n",
      "[Epoch 126/200] [Batch 2/6] [D loss: 0.694602] [G loss: 0.690571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 126/200] [Batch 3/6] [D loss: 0.688419] [G loss: 0.687791]\n",
      "[Epoch 126/200] [Batch 4/6] [D loss: 0.688320] [G loss: 0.692570]\n",
      "[Epoch 126/200] [Batch 5/6] [D loss: 0.697530] [G loss: 0.698441]\n",
      "[Epoch 127/200] [Batch 0/6] [D loss: 0.685710] [G loss: 0.704315]\n",
      "[Epoch 127/200] [Batch 1/6] [D loss: 0.688974] [G loss: 0.712564]\n",
      "[Epoch 127/200] [Batch 2/6] [D loss: 0.690864] [G loss: 0.691143]\n",
      "[Epoch 127/200] [Batch 3/6] [D loss: 0.681373] [G loss: 0.707967]\n",
      "[Epoch 127/200] [Batch 4/6] [D loss: 0.685514] [G loss: 0.703789]\n",
      "[Epoch 127/200] [Batch 5/6] [D loss: 0.692171] [G loss: 0.688739]\n",
      "[Epoch 128/200] [Batch 0/6] [D loss: 0.684465] [G loss: 0.703926]\n",
      "[Epoch 128/200] [Batch 1/6] [D loss: 0.693987] [G loss: 0.692098]\n",
      "[Epoch 128/200] [Batch 2/6] [D loss: 0.685724] [G loss: 0.680393]\n",
      "[Epoch 128/200] [Batch 3/6] [D loss: 0.702328] [G loss: 0.689911]\n",
      "[Epoch 128/200] [Batch 4/6] [D loss: 0.692703] [G loss: 0.673430]\n",
      "[Epoch 128/200] [Batch 5/6] [D loss: 0.692041] [G loss: 0.692898]\n",
      "[Epoch 129/200] [Batch 0/6] [D loss: 0.695910] [G loss: 0.683169]\n",
      "[Epoch 129/200] [Batch 1/6] [D loss: 0.696670] [G loss: 0.690500]\n",
      "[Epoch 129/200] [Batch 2/6] [D loss: 0.695433] [G loss: 0.685339]\n",
      "[Epoch 129/200] [Batch 3/6] [D loss: 0.689775] [G loss: 0.699062]\n",
      "[Epoch 129/200] [Batch 4/6] [D loss: 0.689262] [G loss: 0.696627]\n",
      "[Epoch 129/200] [Batch 5/6] [D loss: 0.691508] [G loss: 0.695178]\n",
      "[Epoch 130/200] [Batch 0/6] [D loss: 0.693484] [G loss: 0.692739]\n",
      "[Epoch 130/200] [Batch 1/6] [D loss: 0.688266] [G loss: 0.696162]\n",
      "[Epoch 130/200] [Batch 2/6] [D loss: 0.680172] [G loss: 0.695063]\n",
      "[Epoch 130/200] [Batch 3/6] [D loss: 0.690104] [G loss: 0.687855]\n",
      "[Epoch 130/200] [Batch 4/6] [D loss: 0.679334] [G loss: 0.717561]\n",
      "[Epoch 130/200] [Batch 5/6] [D loss: 0.676491] [G loss: 0.706867]\n",
      "[Epoch 131/200] [Batch 0/6] [D loss: 0.694628] [G loss: 0.693309]\n",
      "[Epoch 131/200] [Batch 1/6] [D loss: 0.688364] [G loss: 0.697672]\n",
      "[Epoch 131/200] [Batch 2/6] [D loss: 0.682201] [G loss: 0.684547]\n",
      "[Epoch 131/200] [Batch 3/6] [D loss: 0.700149] [G loss: 0.696924]\n",
      "[Epoch 131/200] [Batch 4/6] [D loss: 0.692839] [G loss: 0.680807]\n",
      "[Epoch 131/200] [Batch 5/6] [D loss: 0.700827] [G loss: 0.682042]\n",
      "[Epoch 132/200] [Batch 0/6] [D loss: 0.695144] [G loss: 0.683698]\n",
      "[Epoch 132/200] [Batch 1/6] [D loss: 0.698485] [G loss: 0.676494]\n",
      "[Epoch 132/200] [Batch 2/6] [D loss: 0.703728] [G loss: 0.684292]\n",
      "[Epoch 132/200] [Batch 3/6] [D loss: 0.699841] [G loss: 0.683868]\n",
      "[Epoch 132/200] [Batch 4/6] [D loss: 0.692216] [G loss: 0.698165]\n",
      "[Epoch 132/200] [Batch 5/6] [D loss: 0.688907] [G loss: 0.709734]\n",
      "[Epoch 133/200] [Batch 0/6] [D loss: 0.687258] [G loss: 0.710338]\n",
      "[Epoch 133/200] [Batch 1/6] [D loss: 0.677792] [G loss: 0.700603]\n",
      "[Epoch 133/200] [Batch 2/6] [D loss: 0.691249] [G loss: 0.723069]\n",
      "[Epoch 133/200] [Batch 3/6] [D loss: 0.679703] [G loss: 0.712491]\n",
      "[Epoch 133/200] [Batch 4/6] [D loss: 0.683691] [G loss: 0.723838]\n",
      "[Epoch 133/200] [Batch 5/6] [D loss: 0.692571] [G loss: 0.715387]\n",
      "[Epoch 134/200] [Batch 0/6] [D loss: 0.674908] [G loss: 0.697834]\n",
      "[Epoch 134/200] [Batch 1/6] [D loss: 0.670969] [G loss: 0.712101]\n",
      "[Epoch 134/200] [Batch 2/6] [D loss: 0.706105] [G loss: 0.693506]\n",
      "[Epoch 134/200] [Batch 3/6] [D loss: 0.686076] [G loss: 0.666889]\n",
      "[Epoch 134/200] [Batch 4/6] [D loss: 0.693819] [G loss: 0.680481]\n",
      "[Epoch 134/200] [Batch 5/6] [D loss: 0.695246] [G loss: 0.705372]\n",
      "[Epoch 135/200] [Batch 0/6] [D loss: 0.696518] [G loss: 0.704420]\n",
      "[Epoch 135/200] [Batch 1/6] [D loss: 0.729043] [G loss: 0.684549]\n",
      "[Epoch 135/200] [Batch 2/6] [D loss: 0.723053] [G loss: 0.669064]\n",
      "[Epoch 135/200] [Batch 3/6] [D loss: 0.707494] [G loss: 0.678129]\n",
      "[Epoch 135/200] [Batch 4/6] [D loss: 0.705779] [G loss: 0.681926]\n",
      "[Epoch 135/200] [Batch 5/6] [D loss: 0.699339] [G loss: 0.687205]\n",
      "[Epoch 136/200] [Batch 0/6] [D loss: 0.692402] [G loss: 0.695857]\n",
      "[Epoch 136/200] [Batch 1/6] [D loss: 0.696004] [G loss: 0.708263]\n",
      "[Epoch 136/200] [Batch 2/6] [D loss: 0.695195] [G loss: 0.685149]\n",
      "[Epoch 136/200] [Batch 3/6] [D loss: 0.696286] [G loss: 0.706789]\n",
      "[Epoch 136/200] [Batch 4/6] [D loss: 0.684536] [G loss: 0.732613]\n",
      "[Epoch 136/200] [Batch 5/6] [D loss: 0.702593] [G loss: 0.728054]\n",
      "[Epoch 137/200] [Batch 0/6] [D loss: 0.661075] [G loss: 0.763657]\n",
      "[Epoch 137/200] [Batch 1/6] [D loss: 0.661042] [G loss: 0.738886]\n",
      "[Epoch 137/200] [Batch 2/6] [D loss: 0.670520] [G loss: 0.736837]\n",
      "[Epoch 137/200] [Batch 3/6] [D loss: 0.656033] [G loss: 0.705584]\n",
      "[Epoch 137/200] [Batch 4/6] [D loss: 0.690090] [G loss: 0.638175]\n",
      "[Epoch 137/200] [Batch 5/6] [D loss: 0.706686] [G loss: 0.636091]\n",
      "[Epoch 138/200] [Batch 0/6] [D loss: 0.708197] [G loss: 0.678997]\n",
      "[Epoch 138/200] [Batch 1/6] [D loss: 0.694044] [G loss: 0.698150]\n",
      "[Epoch 138/200] [Batch 2/6] [D loss: 0.706608] [G loss: 0.701513]\n",
      "[Epoch 138/200] [Batch 3/6] [D loss: 0.693990] [G loss: 0.687866]\n",
      "[Epoch 138/200] [Batch 4/6] [D loss: 0.691281] [G loss: 0.673805]\n",
      "[Epoch 138/200] [Batch 5/6] [D loss: 0.691920] [G loss: 0.704934]\n",
      "[Epoch 139/200] [Batch 0/6] [D loss: 0.696230] [G loss: 0.694932]\n",
      "[Epoch 139/200] [Batch 1/6] [D loss: 0.712296] [G loss: 0.683339]\n",
      "[Epoch 139/200] [Batch 2/6] [D loss: 0.700128] [G loss: 0.668842]\n",
      "[Epoch 139/200] [Batch 3/6] [D loss: 0.702448] [G loss: 0.684177]\n",
      "[Epoch 139/200] [Batch 4/6] [D loss: 0.692768] [G loss: 0.707437]\n",
      "[Epoch 139/200] [Batch 5/6] [D loss: 0.683436] [G loss: 0.707084]\n",
      "[Epoch 140/200] [Batch 0/6] [D loss: 0.662168] [G loss: 0.745643]\n",
      "[Epoch 140/200] [Batch 1/6] [D loss: 0.662538] [G loss: 0.770974]\n",
      "[Epoch 140/200] [Batch 2/6] [D loss: 0.677801] [G loss: 0.712729]\n",
      "[Epoch 140/200] [Batch 3/6] [D loss: 0.688019] [G loss: 0.662650]\n",
      "[Epoch 140/200] [Batch 4/6] [D loss: 0.689518] [G loss: 0.660632]\n",
      "[Epoch 140/200] [Batch 5/6] [D loss: 0.677247] [G loss: 0.671621]\n",
      "[Epoch 141/200] [Batch 0/6] [D loss: 0.689650] [G loss: 0.667530]\n",
      "[Epoch 141/200] [Batch 1/6] [D loss: 0.703746] [G loss: 0.682900]\n",
      "[Epoch 141/200] [Batch 2/6] [D loss: 0.710152] [G loss: 0.680189]\n",
      "[Epoch 141/200] [Batch 3/6] [D loss: 0.679423] [G loss: 0.714104]\n",
      "[Epoch 141/200] [Batch 4/6] [D loss: 0.700364] [G loss: 0.738902]\n",
      "[Epoch 141/200] [Batch 5/6] [D loss: 0.686888] [G loss: 0.732596]\n",
      "[Epoch 142/200] [Batch 0/6] [D loss: 0.687984] [G loss: 0.695468]\n",
      "[Epoch 142/200] [Batch 1/6] [D loss: 0.683501] [G loss: 0.707025]\n",
      "[Epoch 142/200] [Batch 2/6] [D loss: 0.684941] [G loss: 0.684500]\n",
      "[Epoch 142/200] [Batch 3/6] [D loss: 0.692351] [G loss: 0.706404]\n",
      "[Epoch 142/200] [Batch 4/6] [D loss: 0.673320] [G loss: 0.685904]\n",
      "[Epoch 142/200] [Batch 5/6] [D loss: 0.702213] [G loss: 0.699387]\n",
      "[Epoch 143/200] [Batch 0/6] [D loss: 0.710805] [G loss: 0.700398]\n",
      "[Epoch 143/200] [Batch 1/6] [D loss: 0.691947] [G loss: 0.686214]\n",
      "[Epoch 143/200] [Batch 2/6] [D loss: 0.693509] [G loss: 0.689675]\n",
      "[Epoch 143/200] [Batch 3/6] [D loss: 0.688951] [G loss: 0.703070]\n",
      "[Epoch 143/200] [Batch 4/6] [D loss: 0.695952] [G loss: 0.694680]\n",
      "[Epoch 143/200] [Batch 5/6] [D loss: 0.703324] [G loss: 0.682810]\n",
      "[Epoch 144/200] [Batch 0/6] [D loss: 0.692534] [G loss: 0.686361]\n",
      "[Epoch 144/200] [Batch 1/6] [D loss: 0.695917] [G loss: 0.694759]\n",
      "[Epoch 144/200] [Batch 2/6] [D loss: 0.706691] [G loss: 0.694986]\n",
      "[Epoch 144/200] [Batch 3/6] [D loss: 0.682793] [G loss: 0.707233]\n",
      "[Epoch 144/200] [Batch 4/6] [D loss: 0.697921] [G loss: 0.715762]\n",
      "[Epoch 144/200] [Batch 5/6] [D loss: 0.693574] [G loss: 0.667099]\n",
      "[Epoch 145/200] [Batch 0/6] [D loss: 0.695227] [G loss: 0.712839]\n",
      "[Epoch 145/200] [Batch 1/6] [D loss: 0.698676] [G loss: 0.693737]\n",
      "[Epoch 145/200] [Batch 2/6] [D loss: 0.680302] [G loss: 0.688823]\n",
      "[Epoch 145/200] [Batch 3/6] [D loss: 0.704583] [G loss: 0.695390]\n",
      "[Epoch 145/200] [Batch 4/6] [D loss: 0.694122] [G loss: 0.714828]\n",
      "[Epoch 145/200] [Batch 5/6] [D loss: 0.713257] [G loss: 0.699501]\n",
      "[Epoch 146/200] [Batch 0/6] [D loss: 0.699562] [G loss: 0.725951]\n",
      "[Epoch 146/200] [Batch 1/6] [D loss: 0.696963] [G loss: 0.700524]\n",
      "[Epoch 146/200] [Batch 2/6] [D loss: 0.691800] [G loss: 0.716473]\n",
      "[Epoch 146/200] [Batch 3/6] [D loss: 0.687827] [G loss: 0.708263]\n",
      "[Epoch 146/200] [Batch 4/6] [D loss: 0.687107] [G loss: 0.707297]\n",
      "[Epoch 146/200] [Batch 5/6] [D loss: 0.688187] [G loss: 0.691365]\n",
      "[Epoch 147/200] [Batch 0/6] [D loss: 0.691852] [G loss: 0.686270]\n",
      "[Epoch 147/200] [Batch 1/6] [D loss: 0.695993] [G loss: 0.689975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 147/200] [Batch 2/6] [D loss: 0.699765] [G loss: 0.690438]\n",
      "[Epoch 147/200] [Batch 3/6] [D loss: 0.693886] [G loss: 0.696560]\n",
      "[Epoch 147/200] [Batch 4/6] [D loss: 0.706342] [G loss: 0.688298]\n",
      "[Epoch 147/200] [Batch 5/6] [D loss: 0.698401] [G loss: 0.703612]\n",
      "[Epoch 148/200] [Batch 0/6] [D loss: 0.698344] [G loss: 0.700962]\n",
      "[Epoch 148/200] [Batch 1/6] [D loss: 0.693815] [G loss: 0.695183]\n",
      "[Epoch 148/200] [Batch 2/6] [D loss: 0.695590] [G loss: 0.715663]\n",
      "[Epoch 148/200] [Batch 3/6] [D loss: 0.690979] [G loss: 0.708139]\n",
      "[Epoch 148/200] [Batch 4/6] [D loss: 0.698185] [G loss: 0.693158]\n",
      "[Epoch 148/200] [Batch 5/6] [D loss: 0.696037] [G loss: 0.701235]\n",
      "[Epoch 149/200] [Batch 0/6] [D loss: 0.692879] [G loss: 0.701669]\n",
      "[Epoch 149/200] [Batch 1/6] [D loss: 0.694200] [G loss: 0.689097]\n",
      "[Epoch 149/200] [Batch 2/6] [D loss: 0.692941] [G loss: 0.708581]\n",
      "[Epoch 149/200] [Batch 3/6] [D loss: 0.694392] [G loss: 0.718811]\n",
      "[Epoch 149/200] [Batch 4/6] [D loss: 0.696906] [G loss: 0.714216]\n",
      "[Epoch 149/200] [Batch 5/6] [D loss: 0.691368] [G loss: 0.710632]\n",
      "[Epoch 150/200] [Batch 0/6] [D loss: 0.695811] [G loss: 0.716561]\n",
      "[Epoch 150/200] [Batch 1/6] [D loss: 0.691512] [G loss: 0.702032]\n",
      "[Epoch 150/200] [Batch 2/6] [D loss: 0.695828] [G loss: 0.705702]\n",
      "[Epoch 150/200] [Batch 3/6] [D loss: 0.700382] [G loss: 0.693219]\n",
      "[Epoch 150/200] [Batch 4/6] [D loss: 0.695039] [G loss: 0.699502]\n",
      "[Epoch 150/200] [Batch 5/6] [D loss: 0.693632] [G loss: 0.699524]\n",
      "[Epoch 151/200] [Batch 0/6] [D loss: 0.691311] [G loss: 0.693317]\n",
      "[Epoch 151/200] [Batch 1/6] [D loss: 0.695910] [G loss: 0.687014]\n",
      "[Epoch 151/200] [Batch 2/6] [D loss: 0.697195] [G loss: 0.688306]\n",
      "[Epoch 151/200] [Batch 3/6] [D loss: 0.692988] [G loss: 0.680992]\n",
      "[Epoch 151/200] [Batch 4/6] [D loss: 0.692757] [G loss: 0.687014]\n",
      "[Epoch 151/200] [Batch 5/6] [D loss: 0.698577] [G loss: 0.683125]\n",
      "[Epoch 152/200] [Batch 0/6] [D loss: 0.683879] [G loss: 0.671993]\n",
      "[Epoch 152/200] [Batch 1/6] [D loss: 0.686095] [G loss: 0.682210]\n",
      "[Epoch 152/200] [Batch 2/6] [D loss: 0.689618] [G loss: 0.671814]\n",
      "[Epoch 152/200] [Batch 3/6] [D loss: 0.693376] [G loss: 0.685864]\n",
      "[Epoch 152/200] [Batch 4/6] [D loss: 0.686798] [G loss: 0.666155]\n",
      "[Epoch 152/200] [Batch 5/6] [D loss: 0.692132] [G loss: 0.681350]\n",
      "[Epoch 153/200] [Batch 0/6] [D loss: 0.687200] [G loss: 0.684221]\n",
      "[Epoch 153/200] [Batch 1/6] [D loss: 0.690691] [G loss: 0.697195]\n",
      "[Epoch 153/200] [Batch 2/6] [D loss: 0.689807] [G loss: 0.699592]\n",
      "[Epoch 153/200] [Batch 3/6] [D loss: 0.687316] [G loss: 0.707038]\n",
      "[Epoch 153/200] [Batch 4/6] [D loss: 0.690160] [G loss: 0.706476]\n",
      "[Epoch 153/200] [Batch 5/6] [D loss: 0.688356] [G loss: 0.698759]\n",
      "[Epoch 154/200] [Batch 0/6] [D loss: 0.688142] [G loss: 0.716953]\n",
      "[Epoch 154/200] [Batch 1/6] [D loss: 0.686373] [G loss: 0.691958]\n",
      "[Epoch 154/200] [Batch 2/6] [D loss: 0.687324] [G loss: 0.699564]\n",
      "[Epoch 154/200] [Batch 3/6] [D loss: 0.694838] [G loss: 0.686091]\n",
      "[Epoch 154/200] [Batch 4/6] [D loss: 0.706772] [G loss: 0.679141]\n",
      "[Epoch 154/200] [Batch 5/6] [D loss: 0.704328] [G loss: 0.661934]\n",
      "[Epoch 155/200] [Batch 0/6] [D loss: 0.705830] [G loss: 0.669788]\n",
      "[Epoch 155/200] [Batch 1/6] [D loss: 0.706813] [G loss: 0.675832]\n",
      "[Epoch 155/200] [Batch 2/6] [D loss: 0.700652] [G loss: 0.699610]\n",
      "[Epoch 155/200] [Batch 3/6] [D loss: 0.700751] [G loss: 0.693720]\n",
      "[Epoch 155/200] [Batch 4/6] [D loss: 0.699137] [G loss: 0.702874]\n",
      "[Epoch 155/200] [Batch 5/6] [D loss: 0.688626] [G loss: 0.721364]\n",
      "[Epoch 156/200] [Batch 0/6] [D loss: 0.691055] [G loss: 0.715930]\n",
      "[Epoch 156/200] [Batch 1/6] [D loss: 0.688963] [G loss: 0.721679]\n",
      "[Epoch 156/200] [Batch 2/6] [D loss: 0.675690] [G loss: 0.710461]\n",
      "[Epoch 156/200] [Batch 3/6] [D loss: 0.679908] [G loss: 0.720470]\n",
      "[Epoch 156/200] [Batch 4/6] [D loss: 0.700485] [G loss: 0.719219]\n",
      "[Epoch 156/200] [Batch 5/6] [D loss: 0.679368] [G loss: 0.714489]\n",
      "[Epoch 157/200] [Batch 0/6] [D loss: 0.699438] [G loss: 0.695133]\n",
      "[Epoch 157/200] [Batch 1/6] [D loss: 0.695748] [G loss: 0.698216]\n",
      "[Epoch 157/200] [Batch 2/6] [D loss: 0.702447] [G loss: 0.696811]\n",
      "[Epoch 157/200] [Batch 3/6] [D loss: 0.699065] [G loss: 0.696267]\n",
      "[Epoch 157/200] [Batch 4/6] [D loss: 0.703405] [G loss: 0.693536]\n",
      "[Epoch 157/200] [Batch 5/6] [D loss: 0.699994] [G loss: 0.703589]\n",
      "[Epoch 158/200] [Batch 0/6] [D loss: 0.699052] [G loss: 0.697323]\n",
      "[Epoch 158/200] [Batch 1/6] [D loss: 0.698236] [G loss: 0.692406]\n",
      "[Epoch 158/200] [Batch 2/6] [D loss: 0.691910] [G loss: 0.700504]\n",
      "[Epoch 158/200] [Batch 3/6] [D loss: 0.693581] [G loss: 0.688832]\n",
      "[Epoch 158/200] [Batch 4/6] [D loss: 0.686243] [G loss: 0.693064]\n",
      "[Epoch 158/200] [Batch 5/6] [D loss: 0.697869] [G loss: 0.693015]\n",
      "[Epoch 159/200] [Batch 0/6] [D loss: 0.697205] [G loss: 0.708368]\n",
      "[Epoch 159/200] [Batch 1/6] [D loss: 0.680491] [G loss: 0.697082]\n",
      "[Epoch 159/200] [Batch 2/6] [D loss: 0.681071] [G loss: 0.703130]\n",
      "[Epoch 159/200] [Batch 3/6] [D loss: 0.677152] [G loss: 0.703861]\n",
      "[Epoch 159/200] [Batch 4/6] [D loss: 0.673885] [G loss: 0.711458]\n",
      "[Epoch 159/200] [Batch 5/6] [D loss: 0.675392] [G loss: 0.716822]\n",
      "[Epoch 160/200] [Batch 0/6] [D loss: 0.681945] [G loss: 0.710564]\n",
      "[Epoch 160/200] [Batch 1/6] [D loss: 0.649442] [G loss: 0.715588]\n",
      "[Epoch 160/200] [Batch 2/6] [D loss: 0.650581] [G loss: 0.725456]\n",
      "[Epoch 160/200] [Batch 3/6] [D loss: 0.659517] [G loss: 0.716590]\n",
      "[Epoch 160/200] [Batch 4/6] [D loss: 0.648134] [G loss: 0.708075]\n",
      "[Epoch 160/200] [Batch 5/6] [D loss: 0.656870] [G loss: 0.712988]\n",
      "[Epoch 161/200] [Batch 0/6] [D loss: 0.674415] [G loss: 0.656160]\n",
      "[Epoch 161/200] [Batch 1/6] [D loss: 0.658168] [G loss: 0.661612]\n",
      "[Epoch 161/200] [Batch 2/6] [D loss: 0.653964] [G loss: 0.627991]\n",
      "[Epoch 161/200] [Batch 3/6] [D loss: 0.786212] [G loss: 0.555124]\n",
      "[Epoch 161/200] [Batch 4/6] [D loss: 0.773563] [G loss: 0.502088]\n",
      "[Epoch 161/200] [Batch 5/6] [D loss: 0.718082] [G loss: 0.674728]\n",
      "[Epoch 162/200] [Batch 0/6] [D loss: 0.694679] [G loss: 0.756925]\n",
      "[Epoch 162/200] [Batch 1/6] [D loss: 0.684670] [G loss: 0.867567]\n",
      "[Epoch 162/200] [Batch 2/6] [D loss: 0.677051] [G loss: 0.865063]\n",
      "[Epoch 162/200] [Batch 3/6] [D loss: 0.633528] [G loss: 0.853713]\n",
      "[Epoch 162/200] [Batch 4/6] [D loss: 0.608668] [G loss: 0.917376]\n",
      "[Epoch 162/200] [Batch 5/6] [D loss: 0.599072] [G loss: 1.025311]\n",
      "[Epoch 163/200] [Batch 0/6] [D loss: 0.619831] [G loss: 0.845797]\n",
      "[Epoch 163/200] [Batch 1/6] [D loss: 0.746649] [G loss: 0.526868]\n",
      "[Epoch 163/200] [Batch 2/6] [D loss: 0.767654] [G loss: 0.566528]\n",
      "[Epoch 163/200] [Batch 3/6] [D loss: 0.735006] [G loss: 0.589061]\n",
      "[Epoch 163/200] [Batch 4/6] [D loss: 0.699412] [G loss: 0.658974]\n",
      "[Epoch 163/200] [Batch 5/6] [D loss: 0.714797] [G loss: 0.658769]\n",
      "[Epoch 164/200] [Batch 0/6] [D loss: 0.687019] [G loss: 0.671067]\n",
      "[Epoch 164/200] [Batch 1/6] [D loss: 0.676562] [G loss: 0.672905]\n",
      "[Epoch 164/200] [Batch 2/6] [D loss: 0.672353] [G loss: 0.691864]\n",
      "[Epoch 164/200] [Batch 3/6] [D loss: 0.683298] [G loss: 0.688511]\n",
      "[Epoch 164/200] [Batch 4/6] [D loss: 0.677418] [G loss: 0.671255]\n",
      "[Epoch 164/200] [Batch 5/6] [D loss: 0.709756] [G loss: 0.654748]\n",
      "[Epoch 165/200] [Batch 0/6] [D loss: 0.701511] [G loss: 0.693750]\n",
      "[Epoch 165/200] [Batch 1/6] [D loss: 0.639113] [G loss: 0.773160]\n",
      "[Epoch 165/200] [Batch 2/6] [D loss: 0.572516] [G loss: 0.939714]\n",
      "[Epoch 165/200] [Batch 3/6] [D loss: 0.578460] [G loss: 0.865928]\n",
      "[Epoch 165/200] [Batch 4/6] [D loss: 0.594053] [G loss: 0.680115]\n",
      "[Epoch 165/200] [Batch 5/6] [D loss: 0.609105] [G loss: 0.775860]\n",
      "[Epoch 166/200] [Batch 0/6] [D loss: 0.594420] [G loss: 1.002308]\n",
      "[Epoch 166/200] [Batch 1/6] [D loss: 0.553966] [G loss: 0.900998]\n",
      "[Epoch 166/200] [Batch 2/6] [D loss: 0.602872] [G loss: 0.814476]\n",
      "[Epoch 166/200] [Batch 3/6] [D loss: 0.604225] [G loss: 0.918207]\n",
      "[Epoch 166/200] [Batch 4/6] [D loss: 0.675608] [G loss: 0.471866]\n",
      "[Epoch 166/200] [Batch 5/6] [D loss: 0.693777] [G loss: 0.560589]\n",
      "[Epoch 167/200] [Batch 0/6] [D loss: 0.600371] [G loss: 0.717744]\n",
      "[Epoch 167/200] [Batch 1/6] [D loss: 0.677239] [G loss: 0.699682]\n",
      "[Epoch 167/200] [Batch 2/6] [D loss: 0.602002] [G loss: 0.570474]\n",
      "[Epoch 167/200] [Batch 3/6] [D loss: 0.591390] [G loss: 0.957675]\n",
      "[Epoch 167/200] [Batch 4/6] [D loss: 0.645984] [G loss: 0.750519]\n",
      "[Epoch 167/200] [Batch 5/6] [D loss: 0.981870] [G loss: 0.348175]\n",
      "[Epoch 168/200] [Batch 0/6] [D loss: 1.641658] [G loss: 0.170319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 168/200] [Batch 1/6] [D loss: 0.652242] [G loss: 1.038153]\n",
      "[Epoch 168/200] [Batch 2/6] [D loss: 0.571082] [G loss: 1.392763]\n",
      "[Epoch 168/200] [Batch 3/6] [D loss: 0.549716] [G loss: 1.271406]\n",
      "[Epoch 168/200] [Batch 4/6] [D loss: 0.459686] [G loss: 1.214958]\n",
      "[Epoch 168/200] [Batch 5/6] [D loss: 0.414729] [G loss: 1.084726]\n",
      "[Epoch 169/200] [Batch 0/6] [D loss: 0.433346] [G loss: 0.776501]\n",
      "[Epoch 169/200] [Batch 1/6] [D loss: 0.626656] [G loss: 0.458999]\n",
      "[Epoch 169/200] [Batch 2/6] [D loss: 0.611728] [G loss: 0.563367]\n",
      "[Epoch 169/200] [Batch 3/6] [D loss: 0.542424] [G loss: 0.737893]\n",
      "[Epoch 169/200] [Batch 4/6] [D loss: 0.614206] [G loss: 0.962968]\n",
      "[Epoch 169/200] [Batch 5/6] [D loss: 0.771790] [G loss: 0.662549]\n",
      "[Epoch 170/200] [Batch 0/6] [D loss: 1.049061] [G loss: 0.503731]\n",
      "[Epoch 170/200] [Batch 1/6] [D loss: 0.828050] [G loss: 0.773536]\n",
      "[Epoch 170/200] [Batch 2/6] [D loss: 0.971503] [G loss: 0.694622]\n",
      "[Epoch 170/200] [Batch 3/6] [D loss: 1.199655] [G loss: 0.438737]\n",
      "[Epoch 170/200] [Batch 4/6] [D loss: 0.776968] [G loss: 1.041881]\n",
      "[Epoch 170/200] [Batch 5/6] [D loss: 0.583278] [G loss: 1.515227]\n",
      "[Epoch 171/200] [Batch 0/6] [D loss: 0.452238] [G loss: 1.313950]\n",
      "[Epoch 171/200] [Batch 1/6] [D loss: 0.536216] [G loss: 0.784054]\n",
      "[Epoch 171/200] [Batch 2/6] [D loss: 0.529583] [G loss: 0.632578]\n",
      "[Epoch 171/200] [Batch 3/6] [D loss: 0.509156] [G loss: 0.836627]\n",
      "[Epoch 171/200] [Batch 4/6] [D loss: 0.488631] [G loss: 0.993152]\n",
      "[Epoch 171/200] [Batch 5/6] [D loss: 0.514438] [G loss: 1.025187]\n",
      "[Epoch 172/200] [Batch 0/6] [D loss: 0.448076] [G loss: 1.239049]\n",
      "[Epoch 172/200] [Batch 1/6] [D loss: 0.425316] [G loss: 1.048152]\n",
      "[Epoch 172/200] [Batch 2/6] [D loss: 0.807850] [G loss: 0.413303]\n",
      "[Epoch 172/200] [Batch 3/6] [D loss: 0.808293] [G loss: 0.616523]\n",
      "[Epoch 172/200] [Batch 4/6] [D loss: 0.898110] [G loss: 0.907292]\n",
      "[Epoch 172/200] [Batch 5/6] [D loss: 0.842400] [G loss: 1.047868]\n",
      "[Epoch 173/200] [Batch 0/6] [D loss: 0.668996] [G loss: 0.980555]\n",
      "[Epoch 173/200] [Batch 1/6] [D loss: 0.648064] [G loss: 0.692991]\n",
      "[Epoch 173/200] [Batch 2/6] [D loss: 0.733928] [G loss: 0.651839]\n",
      "[Epoch 173/200] [Batch 3/6] [D loss: 0.715012] [G loss: 0.850305]\n",
      "[Epoch 173/200] [Batch 4/6] [D loss: 0.827808] [G loss: 0.522087]\n",
      "[Epoch 173/200] [Batch 5/6] [D loss: 0.997932] [G loss: 0.291998]\n",
      "[Epoch 174/200] [Batch 0/6] [D loss: 0.887398] [G loss: 0.538562]\n",
      "[Epoch 174/200] [Batch 1/6] [D loss: 0.595135] [G loss: 0.967762]\n",
      "[Epoch 174/200] [Batch 2/6] [D loss: 0.426327] [G loss: 1.294868]\n",
      "[Epoch 174/200] [Batch 3/6] [D loss: 0.311785] [G loss: 1.394784]\n",
      "[Epoch 174/200] [Batch 4/6] [D loss: 0.285909] [G loss: 1.341362]\n",
      "[Epoch 174/200] [Batch 5/6] [D loss: 0.244542] [G loss: 1.486524]\n",
      "[Epoch 175/200] [Batch 0/6] [D loss: 0.182902] [G loss: 1.740492]\n",
      "[Epoch 175/200] [Batch 1/6] [D loss: 0.348814] [G loss: 1.278264]\n",
      "[Epoch 175/200] [Batch 2/6] [D loss: 0.463281] [G loss: 1.179390]\n",
      "[Epoch 175/200] [Batch 3/6] [D loss: 0.569242] [G loss: 1.923539]\n",
      "[Epoch 175/200] [Batch 4/6] [D loss: 0.753715] [G loss: 0.956017]\n",
      "[Epoch 175/200] [Batch 5/6] [D loss: 0.693787] [G loss: 0.708592]\n",
      "[Epoch 176/200] [Batch 0/6] [D loss: 0.468956] [G loss: 1.368259]\n",
      "[Epoch 176/200] [Batch 1/6] [D loss: 0.364862] [G loss: 1.872241]\n",
      "[Epoch 176/200] [Batch 2/6] [D loss: 0.447890] [G loss: 1.142422]\n",
      "[Epoch 176/200] [Batch 3/6] [D loss: 0.249695] [G loss: 1.742973]\n",
      "[Epoch 176/200] [Batch 4/6] [D loss: 0.802784] [G loss: 0.561592]\n",
      "[Epoch 176/200] [Batch 5/6] [D loss: 0.427127] [G loss: 1.961443]\n",
      "[Epoch 177/200] [Batch 0/6] [D loss: 1.034528] [G loss: 0.609925]\n",
      "[Epoch 177/200] [Batch 1/6] [D loss: 0.919781] [G loss: 0.811219]\n",
      "[Epoch 177/200] [Batch 2/6] [D loss: 0.804674] [G loss: 1.254125]\n",
      "[Epoch 177/200] [Batch 3/6] [D loss: 0.678081] [G loss: 1.103325]\n",
      "[Epoch 177/200] [Batch 4/6] [D loss: 0.484512] [G loss: 1.322317]\n",
      "[Epoch 177/200] [Batch 5/6] [D loss: 0.257360] [G loss: 2.088336]\n",
      "[Epoch 178/200] [Batch 0/6] [D loss: 0.249609] [G loss: 2.102543]\n",
      "[Epoch 178/200] [Batch 1/6] [D loss: 0.302510] [G loss: 1.570314]\n",
      "[Epoch 178/200] [Batch 2/6] [D loss: 0.285881] [G loss: 1.531401]\n",
      "[Epoch 178/200] [Batch 3/6] [D loss: 0.214745] [G loss: 1.703241]\n",
      "[Epoch 178/200] [Batch 4/6] [D loss: 0.203494] [G loss: 1.317205]\n",
      "[Epoch 178/200] [Batch 5/6] [D loss: 0.384502] [G loss: 0.784120]\n",
      "[Epoch 179/200] [Batch 0/6] [D loss: 0.436201] [G loss: 0.787872]\n",
      "[Epoch 179/200] [Batch 1/6] [D loss: 0.446570] [G loss: 0.949400]\n",
      "[Epoch 179/200] [Batch 2/6] [D loss: 0.426449] [G loss: 1.562338]\n",
      "[Epoch 179/200] [Batch 3/6] [D loss: 0.765598] [G loss: 0.830838]\n",
      "[Epoch 179/200] [Batch 4/6] [D loss: 0.975751] [G loss: 0.445229]\n",
      "[Epoch 179/200] [Batch 5/6] [D loss: 0.642603] [G loss: 0.762038]\n",
      "[Epoch 180/200] [Batch 0/6] [D loss: 0.716344] [G loss: 1.756821]\n",
      "[Epoch 180/200] [Batch 1/6] [D loss: 0.560698] [G loss: 1.746765]\n",
      "[Epoch 180/200] [Batch 2/6] [D loss: 0.899306] [G loss: 0.733129]\n",
      "[Epoch 180/200] [Batch 3/6] [D loss: 0.605886] [G loss: 1.441355]\n",
      "[Epoch 180/200] [Batch 4/6] [D loss: 0.600219] [G loss: 1.082792]\n",
      "[Epoch 180/200] [Batch 5/6] [D loss: 0.815733] [G loss: 0.597907]\n",
      "[Epoch 181/200] [Batch 0/6] [D loss: 0.632755] [G loss: 0.720115]\n",
      "[Epoch 181/200] [Batch 1/6] [D loss: 0.528338] [G loss: 1.494820]\n",
      "[Epoch 181/200] [Batch 2/6] [D loss: 0.372706] [G loss: 1.556462]\n",
      "[Epoch 181/200] [Batch 3/6] [D loss: 0.513738] [G loss: 1.006490]\n",
      "[Epoch 181/200] [Batch 4/6] [D loss: 0.514716] [G loss: 1.286053]\n",
      "[Epoch 181/200] [Batch 5/6] [D loss: 0.704623] [G loss: 1.349807]\n",
      "[Epoch 182/200] [Batch 0/6] [D loss: 0.626453] [G loss: 0.743561]\n",
      "[Epoch 182/200] [Batch 1/6] [D loss: 0.580374] [G loss: 0.905314]\n",
      "[Epoch 182/200] [Batch 2/6] [D loss: 0.366910] [G loss: 1.548339]\n",
      "[Epoch 182/200] [Batch 3/6] [D loss: 0.273347] [G loss: 1.870977]\n",
      "[Epoch 182/200] [Batch 4/6] [D loss: 0.232674] [G loss: 1.833145]\n",
      "[Epoch 182/200] [Batch 5/6] [D loss: 0.332023] [G loss: 1.185026]\n",
      "[Epoch 183/200] [Batch 0/6] [D loss: 0.304724] [G loss: 0.994043]\n",
      "[Epoch 183/200] [Batch 1/6] [D loss: 0.304819] [G loss: 2.163582]\n",
      "[Epoch 183/200] [Batch 2/6] [D loss: 0.596085] [G loss: 1.154696]\n",
      "[Epoch 183/200] [Batch 3/6] [D loss: 0.514183] [G loss: 1.312653]\n",
      "[Epoch 183/200] [Batch 4/6] [D loss: 0.582754] [G loss: 0.887829]\n",
      "[Epoch 183/200] [Batch 5/6] [D loss: 0.851832] [G loss: 1.152323]\n",
      "[Epoch 184/200] [Batch 0/6] [D loss: 0.577373] [G loss: 1.172040]\n",
      "[Epoch 184/200] [Batch 1/6] [D loss: 0.433537] [G loss: 1.217204]\n",
      "[Epoch 184/200] [Batch 2/6] [D loss: 0.508739] [G loss: 0.887756]\n",
      "[Epoch 184/200] [Batch 3/6] [D loss: 0.384047] [G loss: 1.166007]\n",
      "[Epoch 184/200] [Batch 4/6] [D loss: 0.410063] [G loss: 0.976389]\n",
      "[Epoch 184/200] [Batch 5/6] [D loss: 0.401830] [G loss: 1.284475]\n",
      "[Epoch 185/200] [Batch 0/6] [D loss: 0.449685] [G loss: 1.084249]\n",
      "[Epoch 185/200] [Batch 1/6] [D loss: 0.438049] [G loss: 1.065496]\n",
      "[Epoch 185/200] [Batch 2/6] [D loss: 0.396416] [G loss: 1.780684]\n",
      "[Epoch 185/200] [Batch 3/6] [D loss: 0.340162] [G loss: 1.383098]\n",
      "[Epoch 185/200] [Batch 4/6] [D loss: 0.303875] [G loss: 1.196512]\n",
      "[Epoch 185/200] [Batch 5/6] [D loss: 0.419979] [G loss: 1.425769]\n",
      "[Epoch 186/200] [Batch 0/6] [D loss: 0.378993] [G loss: 1.181652]\n",
      "[Epoch 186/200] [Batch 1/6] [D loss: 0.352273] [G loss: 1.293520]\n",
      "[Epoch 186/200] [Batch 2/6] [D loss: 0.300334] [G loss: 2.366699]\n",
      "[Epoch 186/200] [Batch 3/6] [D loss: 0.259009] [G loss: 2.032121]\n",
      "[Epoch 186/200] [Batch 4/6] [D loss: 0.492210] [G loss: 0.829823]\n",
      "[Epoch 186/200] [Batch 5/6] [D loss: 0.884114] [G loss: 1.728981]\n",
      "[Epoch 187/200] [Batch 0/6] [D loss: 0.686294] [G loss: 1.107887]\n",
      "[Epoch 187/200] [Batch 1/6] [D loss: 0.801483] [G loss: 0.670535]\n",
      "[Epoch 187/200] [Batch 2/6] [D loss: 0.856814] [G loss: 1.150467]\n",
      "[Epoch 187/200] [Batch 3/6] [D loss: 0.782822] [G loss: 0.959042]\n",
      "[Epoch 187/200] [Batch 4/6] [D loss: 0.709541] [G loss: 0.872141]\n",
      "[Epoch 187/200] [Batch 5/6] [D loss: 0.580761] [G loss: 1.117362]\n",
      "[Epoch 188/200] [Batch 0/6] [D loss: 0.703041] [G loss: 1.431314]\n",
      "[Epoch 188/200] [Batch 1/6] [D loss: 0.640988] [G loss: 0.847420]\n",
      "[Epoch 188/200] [Batch 2/6] [D loss: 0.565319] [G loss: 0.762133]\n",
      "[Epoch 188/200] [Batch 3/6] [D loss: 0.555890] [G loss: 1.580944]\n",
      "[Epoch 188/200] [Batch 4/6] [D loss: 0.551319] [G loss: 0.732603]\n",
      "[Epoch 188/200] [Batch 5/6] [D loss: 0.370576] [G loss: 1.420732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 189/200] [Batch 0/6] [D loss: 0.349656] [G loss: 1.450049]\n",
      "[Epoch 189/200] [Batch 1/6] [D loss: 0.563122] [G loss: 0.866496]\n",
      "[Epoch 189/200] [Batch 2/6] [D loss: 0.744121] [G loss: 0.695884]\n",
      "[Epoch 189/200] [Batch 3/6] [D loss: 0.635363] [G loss: 2.308929]\n",
      "[Epoch 189/200] [Batch 4/6] [D loss: 0.774921] [G loss: 0.484427]\n",
      "[Epoch 189/200] [Batch 5/6] [D loss: 0.732974] [G loss: 1.083977]\n",
      "[Epoch 190/200] [Batch 0/6] [D loss: 0.564276] [G loss: 1.148520]\n",
      "[Epoch 190/200] [Batch 1/6] [D loss: 0.748715] [G loss: 0.274506]\n",
      "[Epoch 190/200] [Batch 2/6] [D loss: 0.754760] [G loss: 1.681927]\n",
      "[Epoch 190/200] [Batch 3/6] [D loss: 0.834144] [G loss: 1.618726]\n",
      "[Epoch 190/200] [Batch 4/6] [D loss: 0.686828] [G loss: 0.450847]\n",
      "[Epoch 190/200] [Batch 5/6] [D loss: 0.647730] [G loss: 0.525481]\n",
      "[Epoch 191/200] [Batch 0/6] [D loss: 0.781273] [G loss: 0.953063]\n",
      "[Epoch 191/200] [Batch 1/6] [D loss: 0.635535] [G loss: 0.782223]\n",
      "[Epoch 191/200] [Batch 2/6] [D loss: 0.895526] [G loss: 0.629325]\n",
      "[Epoch 191/200] [Batch 3/6] [D loss: 0.640150] [G loss: 0.809941]\n",
      "[Epoch 191/200] [Batch 4/6] [D loss: 0.832698] [G loss: 0.734855]\n",
      "[Epoch 191/200] [Batch 5/6] [D loss: 0.777258] [G loss: 1.318510]\n",
      "[Epoch 192/200] [Batch 0/6] [D loss: 0.746346] [G loss: 1.442377]\n",
      "[Epoch 192/200] [Batch 1/6] [D loss: 0.723014] [G loss: 0.925290]\n",
      "[Epoch 192/200] [Batch 2/6] [D loss: 0.538273] [G loss: 1.046916]\n",
      "[Epoch 192/200] [Batch 3/6] [D loss: 0.661751] [G loss: 1.090770]\n",
      "[Epoch 192/200] [Batch 4/6] [D loss: 0.718567] [G loss: 0.858116]\n",
      "[Epoch 192/200] [Batch 5/6] [D loss: 0.541852] [G loss: 0.499141]\n",
      "[Epoch 193/200] [Batch 0/6] [D loss: 0.557445] [G loss: 0.863448]\n",
      "[Epoch 193/200] [Batch 1/6] [D loss: 0.689192] [G loss: 0.802896]\n",
      "[Epoch 193/200] [Batch 2/6] [D loss: 0.557061] [G loss: 0.725741]\n",
      "[Epoch 193/200] [Batch 3/6] [D loss: 0.550294] [G loss: 0.525204]\n",
      "[Epoch 193/200] [Batch 4/6] [D loss: 0.658130] [G loss: 1.172518]\n",
      "[Epoch 193/200] [Batch 5/6] [D loss: 0.544537] [G loss: 1.069550]\n",
      "[Epoch 194/200] [Batch 0/6] [D loss: 0.663217] [G loss: 0.978689]\n",
      "[Epoch 194/200] [Batch 1/6] [D loss: 0.622418] [G loss: 0.553100]\n",
      "[Epoch 194/200] [Batch 2/6] [D loss: 0.988461] [G loss: 0.500629]\n",
      "[Epoch 194/200] [Batch 3/6] [D loss: 0.806759] [G loss: 0.417696]\n",
      "[Epoch 194/200] [Batch 4/6] [D loss: 0.827691] [G loss: 0.668525]\n",
      "[Epoch 194/200] [Batch 5/6] [D loss: 0.778895] [G loss: 0.796225]\n",
      "[Epoch 195/200] [Batch 0/6] [D loss: 0.732736] [G loss: 0.527818]\n",
      "[Epoch 195/200] [Batch 1/6] [D loss: 0.723106] [G loss: 0.722708]\n",
      "[Epoch 195/200] [Batch 2/6] [D loss: 0.681823] [G loss: 0.876204]\n",
      "[Epoch 195/200] [Batch 3/6] [D loss: 0.743533] [G loss: 0.733686]\n",
      "[Epoch 195/200] [Batch 4/6] [D loss: 0.696785] [G loss: 1.030648]\n",
      "[Epoch 195/200] [Batch 5/6] [D loss: 0.600689] [G loss: 1.139661]\n",
      "[Epoch 196/200] [Batch 0/6] [D loss: 0.619716] [G loss: 0.520600]\n",
      "[Epoch 196/200] [Batch 1/6] [D loss: 0.603133] [G loss: 1.096332]\n",
      "[Epoch 196/200] [Batch 2/6] [D loss: 0.680624] [G loss: 0.801885]\n",
      "[Epoch 196/200] [Batch 3/6] [D loss: 0.730901] [G loss: 1.159588]\n",
      "[Epoch 196/200] [Batch 4/6] [D loss: 0.663910] [G loss: 1.272822]\n",
      "[Epoch 196/200] [Batch 5/6] [D loss: 0.639376] [G loss: 0.841781]\n",
      "[Epoch 197/200] [Batch 0/6] [D loss: 0.636138] [G loss: 1.045660]\n",
      "[Epoch 197/200] [Batch 1/6] [D loss: 0.742657] [G loss: 0.921045]\n",
      "[Epoch 197/200] [Batch 2/6] [D loss: 0.773287] [G loss: 1.001655]\n",
      "[Epoch 197/200] [Batch 3/6] [D loss: 0.704676] [G loss: 0.594406]\n",
      "[Epoch 197/200] [Batch 4/6] [D loss: 0.758205] [G loss: 0.694916]\n",
      "[Epoch 197/200] [Batch 5/6] [D loss: 0.700121] [G loss: 0.642712]\n",
      "[Epoch 198/200] [Batch 0/6] [D loss: 0.757112] [G loss: 0.874820]\n",
      "[Epoch 198/200] [Batch 1/6] [D loss: 0.807190] [G loss: 0.597733]\n",
      "[Epoch 198/200] [Batch 2/6] [D loss: 0.771888] [G loss: 0.699276]\n",
      "[Epoch 198/200] [Batch 3/6] [D loss: 0.790550] [G loss: 0.792756]\n",
      "[Epoch 198/200] [Batch 4/6] [D loss: 0.794149] [G loss: 0.846877]\n",
      "[Epoch 198/200] [Batch 5/6] [D loss: 1.016901] [G loss: 0.714588]\n",
      "[Epoch 199/200] [Batch 0/6] [D loss: 0.793406] [G loss: 0.832130]\n",
      "[Epoch 199/200] [Batch 1/6] [D loss: 0.771271] [G loss: 0.666407]\n",
      "[Epoch 199/200] [Batch 2/6] [D loss: 0.902877] [G loss: 0.604438]\n",
      "[Epoch 199/200] [Batch 3/6] [D loss: 0.637095] [G loss: 0.593248]\n",
      "[Epoch 199/200] [Batch 4/6] [D loss: 0.738505] [G loss: 0.613945]\n",
      "[Epoch 199/200] [Batch 5/6] [D loss: 0.760941] [G loss: 0.740730]\n"
     ]
    }
   ],
   "source": [
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, _, _) in enumerate(dataloader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "        )\n",
    "        \n",
    "        if epoch % sample_interval == 0:\n",
    "            save_image(gen_imgs.data[:25], \"images/%d.png\" % epoch, nrow=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be60ad916d1406a848d604cdbc23595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='z1', max=1.0, min=-1.0), FloatSlider(value=0.0, desc"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.sample(z1, z2)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore latent space\n",
    "from ipywidgets import interact\n",
    "\n",
    "def sample(z1, z2):\n",
    "    #z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "    z = np.zeros((1, latent_dim))\n",
    "    z[0,0] = z1\n",
    "    z[0,1] = z2\n",
    "    z = Variable(Tensor(z))\n",
    "    gen_imgs = generator(z)\n",
    "    \n",
    "    if channels == 1:\n",
    "        plt.imshow(gen_imgs.data[0, 0] * .5 + .5, cmap='gray')\n",
    "    else:\n",
    "        img = np.transpose(gen_imgs.cpu().detach().numpy()[0], (1, 2, 0)) * .5 + .5\n",
    "        plt.imshow(img)\n",
    "    \n",
    "interact(sample, z1=(-1, 1, .1), z2=(-1, 1, .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
